{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756fac9b",
   "metadata": {},
   "source": [
    "# Lecture 13 - De novo Molecule Generation\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    ":depth: 1\n",
    "```\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Connect **unsupervised learning** ideas to **molecular generation**.\n",
    "- Explain what an **encoder** and a **decoder** are.\n",
    "- Build a tiny **Autoencoder (AE)** for SMILES and discuss its limits for generation.\n",
    "- Understand the **Variational Autoencoder (VAE)** idea and why it helps sampling.\n",
    "- Train a small **VAE on SMILES** and generate new molecules.\n",
    "- Inspect what **encode** outputs look like and how sampling works in latent space.\n",
    "\n",
    "[![Colab](https://img.shields.io/badge/Open-Colab-orange)]()\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup and data\n",
    "\n",
    "We will use two small datasets.\n",
    "\n",
    "- A subset of **C-H oxidation** molecules (~500). Good for a warm up AE demo.\n",
    "- A small **QM9**-like set of ~1000 SMILES for a VAE practice run.\n",
    "\n",
    "If a download fails, the notebook will create a tiny fallback set so you can still run the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1147dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import os, io, sys, math, random, json, textwrap, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML (CPU friendly)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Cheminformatics\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors, Crippen, rdMolDescriptors, Draw\n",
    "    RD = True\n",
    "except Exception:\n",
    "    RD = False\n",
    "    print(\"RDKit not found. Please install rdkit for full functionality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b52cb1",
   "metadata": {},
   "source": [
    "We load the C-H oxidation dataset from the same source used in earlier lectures and show a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcf5ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound Name</th>\n",
       "      <th>CAS</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility_mol_per_L</th>\n",
       "      <th>pKa</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Melting Point</th>\n",
       "      <th>Reactivity</th>\n",
       "      <th>Oxidation Site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isobutylbenzene</td>\n",
       "      <td>538-92-2</td>\n",
       "      <td>CC(C)Cc1ccccc1</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>6.26</td>\n",
       "      <td>toxic</td>\n",
       "      <td>89.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-methylquinoline</td>\n",
       "      <td>612-58-8</td>\n",
       "      <td>Cc1cnc2ccccc2c1</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>5.77</td>\n",
       "      <td>toxic</td>\n",
       "      <td>90.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>methyl 3-hydroxythiophene-2-carboxylate</td>\n",
       "      <td>6/9/5118</td>\n",
       "      <td>COC(=O)c1sccc1O</td>\n",
       "      <td>0.135246</td>\n",
       "      <td>5.90</td>\n",
       "      <td>non_toxic</td>\n",
       "      <td>78.4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Compound Name       CAS           SMILES  \\\n",
       "0                          Isobutylbenzene  538-92-2   CC(C)Cc1ccccc1   \n",
       "1                        3-methylquinoline  612-58-8  Cc1cnc2ccccc2c1   \n",
       "2  methyl 3-hydroxythiophene-2-carboxylate  6/9/5118  COC(=O)c1sccc1O   \n",
       "\n",
       "   Solubility_mol_per_L   pKa   Toxicity  Melting Point  Reactivity  \\\n",
       "0              0.021527  6.26      toxic           89.8           1   \n",
       "1              0.046610  5.77      toxic           90.8           1   \n",
       "2              0.135246  5.90  non_toxic           78.4          -1   \n",
       "\n",
       "  Oxidation Site  \n",
       "0              4  \n",
       "1              1  \n",
       "2             -1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C-H oxidation dataset\n",
    "try:\n",
    "    url_ch = \"https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/C_H_oxidation_dataset.csv\"\n",
    "    df_ch = pd.read_csv(url_ch)\n",
    "    # some datasets have text columns; we only keep what we need\n",
    "    df_ch = df_ch.rename(columns={c:c.strip() for c in df_ch.columns})\n",
    "    df_ch = df_ch.dropna(subset=[\"SMILES\"]).reset_index(drop=True)\n",
    "    df_ch_small = df_ch.sample(n=min(500, len(df_ch)), random_state=0).reset_index(drop=True)\n",
    "except Exception as e:\n",
    "    print(\"C-H dataset download failed, making a tiny fallback set:\", e)\n",
    "    # fallback: a handful of small hydrocarbons and heterocycles\n",
    "    smiles_fallback = [\n",
    "        \"CC\", \"CCC\", \"CCCC\", \"c1ccccc1\", \"OCCO\", \"CCO\", \"CCN\", \"CCCl\", \"CCBr\",\n",
    "        \"CC(=O)O\", \"C1CCCCC1\", \"c1ccncc1\", \"CCOC\", \"CCS\", \"CCF\", \"C=C\", \"C#N\"\n",
    "    ] * 40\n",
    "    df_ch_small = pd.DataFrame({\"SMILES\": smiles_fallback[:500], \"Compound Name\": [f\"M{i}\" for i in range(500)]})\n",
    "\n",
    "df_ch_small.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd949f94",
   "metadata": {},
   "source": [
    "Next we try to load 1k SMILES for a QM9 mini set. If it fails, we synthesize a small set by perturbing simple scaffolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4160cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM9 mini download failed, making fallback set: HTTP Error 404: Not Found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1ccccc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SMILES\n",
       "0       CCCN\n",
       "1       CCNC\n",
       "2  Cc1ccccc1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_qm9_fallback(n=1000):\n",
    "    base = [\"CCO\", \"CCN\", \"CCC\", \"C=O\", \"COC\", \"c1ccccc1\", \"CCCl\", \"CC=O\", \"OCCO\", \"CC#N\"]\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        s = random.choice(base)\n",
    "        # simple random concat or methyl add\n",
    "        if random.random() < 0.5:\n",
    "            s = \"C\" + s\n",
    "        if random.random() < 0.3:\n",
    "            s = s + \"C\"\n",
    "        out.append(s)\n",
    "    return pd.DataFrame({\"SMILES\": out})\n",
    "\n",
    "try:\n",
    "    url_qm = \"https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/qm9_1k.csv\"\n",
    "    df_qm9 = pd.read_csv(url_qm)\n",
    "    df_qm9 = df_qm9.dropna(subset=[\"SMILES\"]).reset_index(drop=True)\n",
    "    if len(df_qm9) > 1000:\n",
    "        df_qm9 = df_qm9.sample(1000, random_state=0).reset_index(drop=True)\n",
    "except Exception as e:\n",
    "    print(\"QM9 mini download failed, making fallback set:\", e)\n",
    "    df_qm9 = make_qm9_fallback(1000)\n",
    "\n",
    "df_qm9.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9822050b",
   "metadata": {},
   "source": [
    "We will need a tiny tokenizer for SMILES. For beginners, we use **character level** to keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7870e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_charset(smiles_list, extra_tokens=(\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\")):\n",
    "    chars = set()\n",
    "    for s in smiles_list:\n",
    "        chars.update(list(s))\n",
    "    vocab = list(sorted(chars))\n",
    "    vocab = list(extra_tokens) + vocab\n",
    "    stoi = {c:i for i,c in enumerate(vocab)}\n",
    "    itos = {i:c for c,i in stoi.items()}\n",
    "    return vocab, stoi, itos\n",
    "\n",
    "def encode_smiles(s, stoi, max_len):\n",
    "    ids = [stoi.get(\"<bos>\")]\n",
    "    for ch in s:\n",
    "        ids.append(stoi.get(ch, stoi[\"<unk>\"]))\n",
    "    ids.append(stoi.get(\"<eos>\"))\n",
    "    # pad or truncate\n",
    "    ids = ids[:max_len]\n",
    "    ids += [stoi[\"<pad>\"]] * (max_len - len(ids))\n",
    "    return np.array(ids, dtype=np.int64)\n",
    "\n",
    "def decode_ids(ids, itos):\n",
    "    toks = []\n",
    "    for i in ids:\n",
    "        ch = itos[int(i)]\n",
    "        if ch in (\"<pad>\", \"<bos>\"): \n",
    "            continue\n",
    "        if ch == \"<eos>\":\n",
    "            break\n",
    "        toks.append(ch)\n",
    "    return \"\".join(toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b190f",
   "metadata": {},
   "source": [
    "**Exercise A1**\n",
    "\n",
    "1) Print the vocabulary size for the C-H subset.  \n",
    "2) Change `max_len` to a smaller value and see what happens to truncation count.  \n",
    "3) Add a new token to the vocabulary manually and reprint size.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "We now build tokenizers for both datasets and show an example of encode and decode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3140bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-H vocab size: 37 max_len: 64\n",
      "QM9 vocab size: 12 max_len: 12\n",
      "Encoded shape: (64,) first 12 ids: [ 1 19 19  5 19  6 19 30 10 30 30 30]\n",
      "Decoded: CC(C)Cc1ccccc1\n"
     ]
    }
   ],
   "source": [
    "ch_smiles = df_ch_small[\"SMILES\"].astype(str).tolist()\n",
    "qm_smiles = df_qm9[\"SMILES\"].astype(str).tolist()\n",
    "\n",
    "vocab_ch, stoi_ch, itos_ch = build_charset(ch_smiles)\n",
    "vocab_qm, stoi_qm, itos_qm = build_charset(qm_smiles)\n",
    "\n",
    "max_len_ch = min(64, max(len(s)+2 for s in ch_smiles))  # +2 for <bos>, <eos>\n",
    "max_len_qm = min(64, max(len(s)+2 for s in qm_smiles))\n",
    "\n",
    "print(\"C-H vocab size:\", len(vocab_ch), \"max_len:\", max_len_ch)\n",
    "print(\"QM9 vocab size:\", len(vocab_qm), \"max_len:\", max_len_qm)\n",
    "\n",
    "# demo\n",
    "demo = ch_smiles[0]\n",
    "ids = encode_smiles(demo, stoi_ch, max_len_ch)\n",
    "print(\"Encoded shape:\", ids.shape, \"first 12 ids:\", ids[:12])\n",
    "print(\"Decoded:\", decode_ids(ids, itos_ch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b5d78",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Encoder and decoder by example\n",
    "\n",
    "We start with minimal building blocks: an **embedding** for tokens, a small **GRU** encoder to get a single vector, and a **GRU** decoder that tries to reconstruct the input. This is the plain **Autoencoder (AE)**.\n",
    "\n",
    "Concepts:\n",
    "\n",
    "- **Encoder** maps tokens to a latent vector: $z = f_\\phi(x)$.\n",
    "- **Decoder** maps the latent vector back to tokens: $\\hat x = g_\\theta(z)$.\n",
    "- Training uses **reconstruction loss**. For sequences we use token cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4709b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=64, hid=128):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.encoder = nn.GRU(emb_dim, hid, batch_first=True)\n",
    "        self.decoder = nn.GRU(emb_dim + hid, hid, batch_first=True)\n",
    "        self.out = nn.Linear(hid, vocab_size)\n",
    "        self.hid = hid\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T]\n",
    "        emb = self.emb(x)                      # [B, T, E]\n",
    "        _, h = self.encoder(emb)               # h: [1, B, H]\n",
    "        h = h.squeeze(0)                       # [B, H]\n",
    "        # teacher forcing: feed <bos> + previous target tokens during training\n",
    "        # Build decoder input: concat token embedding with repeated h\n",
    "        bos = x[:, :1]                         # first token is <bos>\n",
    "        dec_in_tokens = torch.cat([bos, x[:, :-1]], dim=1)  # shift right\n",
    "        dec_emb = self.emb(dec_in_tokens)      # [B, T, E]\n",
    "        h_rep = h.unsqueeze(1).repeat(1, x.size(1), 1)   # [B, T, H]\n",
    "        dec_cat = torch.cat([dec_emb, h_rep], dim=2)     # [B, T, E+H]\n",
    "        dec_out, _ = self.decoder(dec_cat)\n",
    "        logits = self.out(dec_out)             # [B, T, V]\n",
    "        return logits, h                       # return tokens logits and latent\n",
    "\n",
    "    def encode(self, x):\n",
    "        emb = self.emb(x)\n",
    "        _, h = self.encoder(emb)\n",
    "        return h.squeeze(0)                    # [B, H]\n",
    "\n",
    "    def decode_greedy(self, z, stoi, itos, max_len=64):\n",
    "        # z: [B, H]\n",
    "        B = z.size(0)\n",
    "        cur = torch.full((B, 1), stoi[\"<bos>\"], dtype=torch.long, device=z.device)\n",
    "        outs = []\n",
    "        h = None\n",
    "        for _ in range(max_len):\n",
    "            emb = self.emb(cur)                 # [B, 1, E]\n",
    "            zrep = z.unsqueeze(1)               # [B, 1, H]\n",
    "            dec_cat = torch.cat([emb, zrep], dim=2)\n",
    "            dec_out, h = self.decoder(dec_cat, h)\n",
    "            logits = self.out(dec_out[:, -1, :])        # [B, V]\n",
    "            nxt = torch.argmax(logits, dim=-1, keepdim=True)  # [B, 1]\n",
    "            outs.append(nxt)\n",
    "            cur = nxt\n",
    "            if int(nxt[0,0].item()) == stoi[\"<eos>\"]:\n",
    "                break\n",
    "        outs = torch.cat(outs, dim=1)  # [B, T']\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e138768",
   "metadata": {},
   "source": [
    "Let us build a tiny dataset class and a single batch to inspect shapes. This helps students see what goes into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd5b6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 64]),\n",
       " tensor([ 1, 19, 17, 19, 19, 19, 19, 19, 19, 19, 19, 19]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SmilesDataset(Dataset):\n",
    "    def __init__(self, smiles, stoi, max_len):\n",
    "        self.smiles = smiles\n",
    "        self.stoi = stoi\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.smiles[idx]\n",
    "        x = encode_smiles(s, self.stoi, self.max_len)\n",
    "        return torch.from_numpy(x)\n",
    "\n",
    "# small C-H dataset for AE\n",
    "train_smiles_ae = ch_smiles\n",
    "ds_ae = SmilesDataset(train_smiles_ae, stoi_ch, max_len_ch)\n",
    "dl_ae = DataLoader(ds_ae, batch_size=64, shuffle=True)\n",
    "\n",
    "batch = next(iter(dl_ae))\n",
    "batch.shape, batch[0][:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc822e5",
   "metadata": {},
   "source": [
    "**What does encode really look like?** We pass one sequence into the encoder and print the latent vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8b4319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent vector shape: (1, 128)\n",
      "First 8 numbers: [-0.045  0.084  0.023 -0.006 -0.034 -0.03  -0.104 -0.035]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ae = AE(vocab_size=len(vocab_ch), emb_dim=64, hid=128).to(device)\n",
    "\n",
    "x1 = batch[:1].to(device)         # one sample\n",
    "with torch.no_grad():\n",
    "    z1 = ae.encode(x1)            # [1, 128]\n",
    "print(\"Latent vector shape:\", tuple(z1.shape))\n",
    "print(\"First 8 numbers:\", z1[0, :8].cpu().numpy().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26780f64",
   "metadata": {},
   "source": [
    "**Exercise A2**\n",
    "\n",
    "1) Change `hid` from 128 to 32 and print the new latent vector shape.  \n",
    "2) Inspect the first 8 numbers again. Are they larger or smaller on average  \n",
    "3) Try `emb_dim` 32 vs 128 and see if the loss in the next section changes faster.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Training a simple AE on C-H subset\n",
    "\n",
    "We keep the training loop short to fit in class time. The goal is to reconstruct the input SMILES.\n",
    "\n",
    "Loss: token cross-entropy over all time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc0a9d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE epoch 1 loss 3.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE epoch 2 loss 2.403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE epoch 3 loss 2.103\n"
     ]
    }
   ],
   "source": [
    "def ce_loss(logits, targets, ignore_index=0):\n",
    "    # logits: [B, T, V], targets: [B, T]\n",
    "    return F.cross_entropy(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        targets.reshape(-1),\n",
    "        ignore_index=ignore_index\n",
    "    )\n",
    "\n",
    "opt = torch.optim.Adam(ae.parameters(), lr=1e-3)\n",
    "ae.train()\n",
    "\n",
    "for epoch in range(3):\n",
    "    losses = []\n",
    "    for xb in dl_ae:\n",
    "        xb = xb.to(device)\n",
    "        logits, z = ae(xb)\n",
    "        loss = ce_loss(logits, xb, ignore_index=stoi_ch[\"<pad>\"])\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    print(f\"AE epoch {epoch+1} loss {np.mean(losses):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9c9d8",
   "metadata": {},
   "source": [
    "Let us reconstruct some strings and compare input vs output. The AE is not a language model. It mostly learns to copy inputs it has seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4914226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in:  CCc1ccc(C2CCCCC2)cc1\n",
      "out: CCCccccccCcCCCCCCccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "\n",
      "in:  CC1COCc2cc3c(cc21)C(C)(C)C(C)C3(C)C\n",
      "out: CCCCCCCccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "\n",
      "in:  O=C(O)c1ccc(P(=O)(c2ccc(C(=O)O)cc2)c2ccc(C(=O)O)cc2)cc1\n",
      "out: CCCCC)CcccccccCC)CCccccccCCC)C)CccccccccccCCC)C)CccccccccccCCCC\n",
      "\n",
      "in:  CC(C)(C)c1ccc2cc3ccccc3cc2c1\n",
      "out: CCCCCCCCCcccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "\n",
      "in:  CCc1cccc(CC)c1\n",
      "out: CCCcccccccCCCccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "\n",
      "in:  CC1=C(C)CCCC1\n",
      "out: CCCCCCCCCCCCCCcCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "\n",
      "in:  CCc1ccc(OC)cc1\n",
      "out: CCCcccccc)CCccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "\n",
      "in:  O=C(O)c1cc(O)c2ccccc2c1O\n",
      "out: CCCCC)Cccccc)Ccccccccccc)ccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ae.eval()\n",
    "with torch.no_grad():\n",
    "    xb = next(iter(dl_ae))[:8].to(device)\n",
    "    logits, z = ae(xb)\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    for i in range(xb.size(0)):\n",
    "        s_in  = decode_ids(xb[i].cpu().numpy(), itos_ch)\n",
    "        s_out = decode_ids(preds[i].cpu().numpy(), itos_ch)\n",
    "        print(f\"in:  {s_in}\")\n",
    "        print(f\"out: {s_out}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c566c00",
   "metadata": {},
   "source": [
    "**AE challenge discussion**\n",
    "\n",
    "- An AE learns to compress and decompress. It does not force a **smooth** latent space.\n",
    "- Sampling a random latent vector often decodes to invalid strings.\n",
    "- Small perturbations in latent space may break validity.\n",
    "- Molecules are discrete graphs. SMILES is a string representation. Errors can violate valence.\n",
    "\n",
    "**Exercise A3**\n",
    "\n",
    "1) Try to decode using `ae.decode_greedy(z_from_other_molecule)` by swapping latent vectors between two inputs.  \n",
    "2) How often do you get invalid SMILES when you decode a random normal vector of size `hid`  \n",
    "3) Count validity using RDKit parsing.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. From AE to VAE\n",
    "\n",
    "To sample new molecules we want a **nice latent space**. The **Variational Autoencoder (VAE)** shapes the latent distribution.\n",
    "\n",
    "Idea:\n",
    "\n",
    "- Encoder outputs a mean and a log-variance for each dimension: $\\mu(x)$ and $\\log\\sigma^2(x)$.\n",
    "- We sample latent with the **reparameterization trick**  \n",
    "  $z = \\mu + \\sigma \\odot \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0, I)$.\n",
    "- Loss has two parts  \n",
    "  1) Reconstruction: token cross-entropy  \n",
    "  2) KL term: $D_{\\text{KL}}\\big(q_\\phi(z\\mid x)\\,\\|\\,\\mathcal{N}(0, I)\\big)$\n",
    "\n",
    "The KL term nudges posteriors toward a unit Gaussian. That makes sampling from $z \\sim \\mathcal{N}(0,I)$ meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101167b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=64, hid=128, zdim=64):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.encoder = nn.GRU(emb_dim, hid, batch_first=True)\n",
    "        self.mu = nn.Linear(hid, zdim)\n",
    "        self.logvar = nn.Linear(hid, zdim)\n",
    "\n",
    "        self.decoder = nn.GRU(emb_dim + zdim, hid, batch_first=True)\n",
    "        self.out = nn.Linear(hid, vocab_size)\n",
    "        self.zdim = zdim\n",
    "\n",
    "    def encode_stats(self, x):\n",
    "        emb = self.emb(x)\n",
    "        _, h = self.encoder(emb)   # [1, B, H]\n",
    "        h = h.squeeze(0)\n",
    "        mu = self.mu(h)\n",
    "        logvar = self.logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparam(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode_stats(x)\n",
    "        z = self.reparam(mu, logvar)                 # [B, Z]\n",
    "        bos = x[:, :1]\n",
    "        dec_in_tokens = torch.cat([bos, x[:, :-1]], dim=1)\n",
    "        dec_emb = self.emb(dec_in_tokens)\n",
    "        zrep = z.unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        dec_cat = torch.cat([dec_emb, zrep], dim=2)\n",
    "        dec_out, _ = self.decoder(dec_cat)\n",
    "        logits = self.out(dec_out)\n",
    "        return logits, mu, logvar, z\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, logvar = self.encode_stats(x)\n",
    "        return mu\n",
    "\n",
    "    def sample(self, n, stoi, itos, max_len=64, device=\"cpu\"):\n",
    "        z = torch.randn(n, self.zdim, device=device)\n",
    "        cur = torch.full((n, 1), stoi[\"<bos>\"], dtype=torch.long, device=device)\n",
    "        outs = []\n",
    "        h = None\n",
    "        for _ in range(max_len):\n",
    "            emb = self.emb(cur)\n",
    "            zrep = z.unsqueeze(1)\n",
    "            dec_cat = torch.cat([emb, zrep], dim=2)\n",
    "            dec_out, h = self.decoder(dec_cat, h)\n",
    "            logits = self.out(dec_out[:, -1, :])\n",
    "            nxt = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            outs.append(nxt)\n",
    "            cur = nxt\n",
    "        ids = torch.cat(outs, dim=1)\n",
    "        return [decode_ids(row.cpu().numpy(), itos) for row in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6043a",
   "metadata": {},
   "source": [
    "We define the VAE loss. The KL weight can start small and increase. This is called **KL warmup** and often stabilizes training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd0ed7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(logits, targets, mu, logvar, kl_weight=1.0, pad_idx=0):\n",
    "    rec = F.cross_entropy(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        targets.reshape(-1),\n",
    "        ignore_index=pad_idx\n",
    "    )\n",
    "    # KL for N(mu, sigma^2) vs N(0,1): -0.5 * sum(1 + logvar - mu^2 - exp(logvar))\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return rec + kl_weight * kl, rec.item(), kl.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa08eb9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Training a VAE on QM9 subset\n",
    "\n",
    "We prepare a loader and run a short training loop. Keep epochs low for class time. You can extend later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8081f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE epoch 1  loss 2.114  rec 2.112  kl 0.006  kl_w 0.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE epoch 2  loss 1.558  rec 1.529  kl 0.030  kl_w 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE epoch 3  loss 1.254  rec 1.217  kl 0.037  kl_w 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE epoch 4  loss 1.049  rec 1.026  kl 0.023  kl_w 1.00\n"
     ]
    }
   ],
   "source": [
    "# dataset and loader\n",
    "ds_vae = SmilesDataset(qm_smiles, stoi_qm, max_len_qm)\n",
    "dl_vae = DataLoader(ds_vae, batch_size=128, shuffle=True)\n",
    "\n",
    "vae = VAE(vocab_size=len(vocab_qm), emb_dim=64, hid=128, zdim=64).to(device)\n",
    "opt = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 4\n",
    "for ep in range(epochs):\n",
    "    vae.train()\n",
    "    lossv, recv, klv = [], [], []\n",
    "    kl_w = min(1.0, (ep+1) / max(1, epochs//2))  # simple warmup\n",
    "    for xb in dl_vae:\n",
    "        xb = xb.to(device)\n",
    "        logits, mu, logvar, z = vae(xb)\n",
    "        loss, rec, kl = vae_loss(logits, xb, mu, logvar, kl_weight=kl_w, pad_idx=stoi_qm[\"<pad>\"])\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        lossv.append(loss.item()); recv.append(rec); klv.append(kl)\n",
    "    print(f\"VAE epoch {ep+1}  loss {np.mean(lossv):.3f}  rec {np.mean(recv):.3f}  kl {np.mean(klv):.3f}  kl_w {kl_w:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af85db8",
   "metadata": {},
   "source": [
    "Let us inspect the **encode** output for a few molecules to see latent vectors. This connects the math to the actual tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7581ba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded mu shape: (3, 64)\n",
      "Row 0 first 10 dims: [-0.005 -0.133 -0.094  0.12   0.265 -0.04  -0.209  0.031  0.063 -0.04 ]\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    xb = next(iter(dl_vae))[:3].to(device)\n",
    "    mu = vae.encode(xb)        # [3, zdim]\n",
    "print(\"Encoded mu shape:\", tuple(mu.shape))\n",
    "print(\"Row 0 first 10 dims:\", mu[0,:10].cpu().numpy().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2adfda9",
   "metadata": {},
   "source": [
    "We now sample new molecules by drawing random $z \\sim \\mathcal{N}(0, I)$ and decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18bbdf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. CCCC\n",
      "02. CCCC\n",
      "03. CCCC\n",
      "04. CCCC\n",
      "05. CCCC\n",
      "06. CCCC\n",
      "07. CCCC\n",
      "08. CCCCC\n",
      "09. CCCC\n",
      "10. CCCC\n",
      "11. CCCC\n",
      "12. CCCC\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    samples = vae.sample(12, stoi_qm, itos_qm, max_len=max_len_qm, device=device)\n",
    "for i, s in enumerate(samples, 1):\n",
    "    print(f\"{i:02d}. {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4b424",
   "metadata": {},
   "source": [
    "Count validity with RDKit. This shows why VAE helps compared to a plain AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c9c733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 12 / 12\n"
     ]
    }
   ],
   "source": [
    "def is_valid_smiles(s):\n",
    "    if not RD: \n",
    "        return True  # skip if RDKit missing\n",
    "    m = Chem.MolFromSmiles(s)\n",
    "    return m is not None\n",
    "\n",
    "valid_flags = [is_valid_smiles(s) for s in samples]\n",
    "print(\"Valid:\", sum(valid_flags), \"/\", len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c77a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Interpolations in latent space\n",
    "\n",
    "A benefit of VAE is smoothness of the latent space. We encode two molecules, then linearly interpolate between their latents and decode each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f04ce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1: CCCN\n",
      "s2: CCNC\n",
      "t=0.00 -> CCCC   valid=True\n",
      "t=0.20 -> CCCC   valid=True\n",
      "t=0.40 -> CCCC   valid=True\n",
      "t=0.60 -> CCCC   valid=True\n",
      "t=0.80 -> CCCC   valid=True\n",
      "t=1.00 -> CCCC   valid=True\n"
     ]
    }
   ],
   "source": [
    "def interpolate(vae, s1, s2, stoi, itos, steps=7, device=\"cpu\", max_len=64):\n",
    "    with torch.no_grad():\n",
    "        x1 = torch.from_numpy(encode_smiles(s1, stoi, max_len)).unsqueeze(0).to(device)\n",
    "        x2 = torch.from_numpy(encode_smiles(s2, stoi, max_len)).unsqueeze(0).to(device)\n",
    "        mu1 = vae.encode(x1)  # [1, Z]\n",
    "        mu2 = vae.encode(x2)  # [1, Z]\n",
    "        outs = []\n",
    "        for t in np.linspace(0, 1, steps):\n",
    "            z = (1-t)*mu1 + t*mu2\n",
    "            # greedy decode from z\n",
    "            cur = torch.full((1,1), stoi[\"<bos>\"], dtype=torch.long, device=device)\n",
    "            h = None\n",
    "            seq = []\n",
    "            for _ in range(max_len):\n",
    "                emb = vae.emb(cur)\n",
    "                zrep = z.unsqueeze(1)\n",
    "                dec_cat = torch.cat([emb, zrep], dim=2)\n",
    "                dec_out, h = vae.decoder(dec_cat, h)\n",
    "                logits = vae.out(dec_out[:,-1,:])\n",
    "                nxt = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "                seq.append(nxt)\n",
    "                cur = nxt\n",
    "            ids = torch.cat(seq, dim=1)\n",
    "            outs.append(decode_ids(ids[0].cpu().numpy(), itos))\n",
    "    return outs\n",
    "\n",
    "s1 = qm_smiles[0]\n",
    "s2 = qm_smiles[1]\n",
    "print(\"s1:\", s1)\n",
    "print(\"s2:\", s2)\n",
    "outs = interpolate(vae, s1, s2, stoi_qm, itos_qm, steps=6, device=device, max_len=max_len_qm)\n",
    "for i, s in enumerate(outs):\n",
    "    ok = is_valid_smiles(s)\n",
    "    print(f\"t={i/(len(outs)-1):.2f} -> {s}   valid={ok}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b9864",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Small AE on C-H reactivity slice\n",
    "\n",
    "As a short targeted demo, we pick a slice of possibly reactive molecules from the C-H dataset by a quick rule like higher `NumRings` or high `LogP`. This is a toy filter to create a thematic mini set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3b7be0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound Name</th>\n",
       "      <th>CAS</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility_mol_per_L</th>\n",
       "      <th>pKa</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Melting Point</th>\n",
       "      <th>Reactivity</th>\n",
       "      <th>Oxidation Site</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>LogP</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>NumRings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isobutylbenzene</td>\n",
       "      <td>538-92-2</td>\n",
       "      <td>CC(C)Cc1ccccc1</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>6.26</td>\n",
       "      <td>toxic</td>\n",
       "      <td>89.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>134.222</td>\n",
       "      <td>2.88510</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-methylquinoline</td>\n",
       "      <td>612-58-8</td>\n",
       "      <td>Cc1cnc2ccccc2c1</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>5.77</td>\n",
       "      <td>toxic</td>\n",
       "      <td>90.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>143.189</td>\n",
       "      <td>2.54322</td>\n",
       "      <td>12.89</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>methyl 3-hydroxythiophene-2-carboxylate</td>\n",
       "      <td>6/9/5118</td>\n",
       "      <td>COC(=O)c1sccc1O</td>\n",
       "      <td>0.135246</td>\n",
       "      <td>5.90</td>\n",
       "      <td>non_toxic</td>\n",
       "      <td>78.4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>158.178</td>\n",
       "      <td>1.24030</td>\n",
       "      <td>46.53</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Compound Name       CAS           SMILES  \\\n",
       "0                          Isobutylbenzene  538-92-2   CC(C)Cc1ccccc1   \n",
       "1                        3-methylquinoline  612-58-8  Cc1cnc2ccccc2c1   \n",
       "2  methyl 3-hydroxythiophene-2-carboxylate  6/9/5118  COC(=O)c1sccc1O   \n",
       "\n",
       "   Solubility_mol_per_L   pKa   Toxicity  Melting Point  Reactivity  \\\n",
       "0              0.021527  6.26      toxic           89.8           1   \n",
       "1              0.046610  5.77      toxic           90.8           1   \n",
       "2              0.135246  5.90  non_toxic           78.4          -1   \n",
       "\n",
       "  Oxidation Site    MolWt     LogP   TPSA  NumRings  \n",
       "0              4  134.222  2.88510   0.00       1.0  \n",
       "1              1  143.189  2.54322  12.89       2.0  \n",
       "2             -1  158.178  1.24030  46.53       1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick 4 descriptors for a slice\n",
    "def calc_descriptors(smiles: str):\n",
    "    if not RD:\n",
    "        return pd.Series({\"MolWt\": np.nan, \"LogP\": np.nan, \"TPSA\": np.nan, \"NumRings\": np.nan})\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    if m is None:\n",
    "        return pd.Series({\"MolWt\": np.nan, \"LogP\": np.nan, \"TPSA\": np.nan, \"NumRings\": np.nan})\n",
    "    return pd.Series({\n",
    "        \"MolWt\": Descriptors.MolWt(m),\n",
    "        \"LogP\": Crippen.MolLogP(m),\n",
    "        \"TPSA\": rdMolDescriptors.CalcTPSA(m),\n",
    "        \"NumRings\": rdMolDescriptors.CalcNumRings(m),\n",
    "    })\n",
    "\n",
    "desc4 = df_ch_small[\"SMILES\"].apply(calc_descriptors)\n",
    "df_ch4 = pd.concat([df_ch_small, desc4], axis=1)\n",
    "df_ch4.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd26dc",
   "metadata": {},
   "source": [
    "We define a simple filter and train a tiny AE on this subset. Then we decode a few reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3848c0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice AE epoch 1 loss 3.413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice AE epoch 2 loss 2.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice AE epoch 3 loss 2.562\n"
     ]
    }
   ],
   "source": [
    "sel = df_ch4.copy()\n",
    "sel = sel.dropna(subset=[\"SMILES\"])\n",
    "# toy filter: aromatic rich or LogP > 2\n",
    "if \"LogP\" in sel.columns and \"NumRings\" in sel.columns:\n",
    "    sel = sel[(sel[\"NumRings\"] >= 1) | (sel[\"LogP\"] > 2.0)]\n",
    "sel = sel.sample(n=min(300, len(sel)), random_state=0).reset_index(drop=True)\n",
    "\n",
    "subset_smiles = sel[\"SMILES\"].astype(str).tolist()\n",
    "vocab_s, stoi_s, itos_s = build_charset(subset_smiles)\n",
    "max_len_s = min(64, max(len(s)+2 for s in subset_smiles))\n",
    "\n",
    "ds_s = SmilesDataset(subset_smiles, stoi_s, max_len_s)\n",
    "dl_s = DataLoader(ds_s, batch_size=64, shuffle=True)\n",
    "\n",
    "ae_s = AE(vocab_size=len(vocab_s), emb_dim=64, hid=96).to(device)\n",
    "opt = torch.optim.Adam(ae_s.parameters(), lr=1e-3)\n",
    "\n",
    "for ep in range(3):\n",
    "    ae_s.train()\n",
    "    losses=[]\n",
    "    for xb in dl_s:\n",
    "        xb = xb.to(device)\n",
    "        logits, z = ae_s(xb)\n",
    "        loss = ce_loss(logits, xb, ignore_index=stoi_s[\"<pad>\"])\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        losses.append(loss.item())\n",
    "    print(f\"slice AE epoch {ep+1} loss {np.mean(losses):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3b136",
   "metadata": {},
   "source": [
    "Reconstructions on this small slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a17c4cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in:  CCCCCOC(=O)c1ccccc1\n",
      "out: CCCCCCCcCccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "\n",
      "in:  Nc1ccc(Cl)cc1C(=O)c1ccccc1\n",
      "out: CCcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "\n",
      "in:  Cc1ccccc1\n",
      "out: CCCccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "\n",
      "in:  Nc1c(O)ccc2ccccc12\n",
      "out: CCcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "\n",
      "in:  CSc1ccccc1\n",
      "out: CCCccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "\n",
      "in:  Oc1c2ccccc2cc2ccccc12\n",
      "out: CCcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "\n",
      "in:  COc1ccc2nc(C)ccc2c1\n",
      "out: CCCccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "\n",
      "in:  Clc1ncnc2nc[nH]c12\n",
      "out: CCCCcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ae_s.eval()\n",
    "with torch.no_grad():\n",
    "    xb = next(iter(dl_s))[:8].to(device)\n",
    "    logits, z = ae_s(xb)\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    for i in range(xb.size(0)):\n",
    "        s_in  = decode_ids(xb[i].cpu().numpy(), itos_s)\n",
    "        s_out = decode_ids(preds[i].cpu().numpy(), itos_s)\n",
    "        print(f\"in:  {s_in}\")\n",
    "        print(f\"out: {s_out}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b2481",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Glossary\n",
    "\n",
    "```{glossary}\n",
    "encoder\n",
    "  Function or network that maps input $x$ to a latent vector $z$.\n",
    "\n",
    "decoder\n",
    "  Function or network that maps a latent vector $z$ back to a sequence.\n",
    "\n",
    "autoencoder (AE)\n",
    "  Model trained to reconstruct inputs with latent $z = f_\\phi(x)$ and reconstruction $\\hat x = g_\\theta(z)$.\n",
    "\n",
    "variational autoencoder (VAE)\n",
    "  Probabilistic AE with latent posterior $q_\\phi(z\\mid x)$ and a KL term that encourages $z$ to follow a simple prior.\n",
    "\n",
    "reparameterization trick\n",
    "  Sampling $z = \\mu + \\sigma \\odot \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0,I)$ to allow gradients through sampling.\n",
    "\n",
    "KL divergence\n",
    "  $D_{\\text{KL}}(q\\parallel p)$ measures how one distribution differs from another. Used to match $q_\\phi(z\\mid x)$ to a prior.\n",
    "\n",
    "teacher forcing\n",
    "  Training method where the decoder sees ground truth tokens shifted by one position.\n",
    "\n",
    "validity\n",
    "  Whether a decoded SMILES parses to a molecule in RDKit.\n",
    "\n",
    "interpolation\n",
    "  Decoding points on the line segment between two latent vectors to see gradual changes.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9. In-class activity\n",
    "\n",
    "Scenario: you are tasked with generating new small molecules for follow up experiments. You have a few hundred SMILES from a known chemistry series and a more general 1k set.\n",
    "\n",
    "Answer these 5 tasks. Most can be handled with the code from class.\n",
    "\n",
    "### Q1. Tokenizer tweaks\n",
    "\n",
    "- Build the QM9 tokenizer as above.\n",
    "- Remove `<unk>` from the vocabulary and re-encode the set by mapping unknown chars to `<pad>`.\n",
    "- Count how many sequences changed compared to the original encoding.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "### Q2. AE latent inspection\n",
    "\n",
    "- Train the C-H slice AE for 2 more epochs.\n",
    "- Encode all molecules to get a matrix `Z` of shape `[n, hid]`.\n",
    "- Plot the histogram of `Z[:, 0]` and `Z[:, 1]`.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "### Q3. VAE sampling and validity\n",
    "\n",
    "- Sample 64 SMILES from the VAE.\n",
    "- Compute validity rate with RDKit.\n",
    "- Print the first 10 valid ones.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "### Q4. Latent interpolation search\n",
    "\n",
    "- Pick two molecules from QM9 that are valid and distinct.\n",
    "- Run interpolation with 8 steps.\n",
    "- Count how many of the decoded steps are valid.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "### Q5. Conditional hinting via nearest neighbor seeding\n",
    "\n",
    "- For one query SMILES `s*`, encode to `mu*`.\n",
    "- Find its 5 nearest neighbors in latent space by Euclidean distance on `mu`.\n",
    "- Average their mus to form `z_avg` and decode 10 samples by adding small Gaussian noise around `z_avg`.\n",
    "- Report validity and print 5 outputs.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Solutions\n",
    "\n",
    "### Q1 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c1a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed encodings on subset: 300 of 300\n"
     ]
    }
   ],
   "source": [
    "# original tokenizer\n",
    "v_org, s_org, i_org = build_charset(qm_smiles)\n",
    "max_len_qm2 = max_len_qm\n",
    "\n",
    "# new tokenizer without <unk>\n",
    "extra = (\"<pad>\", \"<bos>\", \"<eos>\")  # exclude <unk>\n",
    "chars = set(\"\".join(qm_smiles))\n",
    "v_new = list(extra) + sorted(chars)\n",
    "s_new = {c:i for i,c in enumerate(v_new)}\n",
    "i_new = {i:c for c,i in s_new.items()}\n",
    "\n",
    "def enc_no_unk(s, stoi, max_len):\n",
    "    ids = [stoi[\"<bos>\"]]\n",
    "    for ch in s:\n",
    "        if ch in stoi:\n",
    "            ids.append(stoi[ch])\n",
    "        else:\n",
    "            ids.append(stoi[\"<pad>\"])\n",
    "    ids.append(stoi[\"<eos>\"])\n",
    "    ids = ids[:max_len]\n",
    "    ids += [stoi[\"<pad>\"]] * (max_len - len(ids))\n",
    "    return np.array(ids, dtype=np.int64)\n",
    "\n",
    "changed = 0\n",
    "for s in qm_smiles[:300]:  # check a subset for speed\n",
    "    a = encode_smiles(s, s_org, max_len_qm2)\n",
    "    b = enc_no_unk(s, s_new, max_len_qm2)\n",
    "    if not np.array_equal(a, b):\n",
    "        changed += 1\n",
    "print(\"Changed encodings on subset:\", changed, \"of\", 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099faeef",
   "metadata": {},
   "source": [
    "### Q2 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba9b12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra ep 1 loss 2.399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra ep 2 loss 2.405\n"
     ]
    }
   ],
   "source": [
    "# continue training 2 epochs\n",
    "for ep in range(2):\n",
    "    ae_s.train()\n",
    "    ls=[]\n",
    "    for xb in dl_s:\n",
    "        xb = xb.to(device)\n",
    "        logits, z = ae_s(xb)\n",
    "        loss = ce_loss(logits, xb, ignore_index=stoi_s[\"<pad>\"])\n",
    "        torch.optim.Adam(ae_s.parameters(), lr=1e-3).zero_grad()\n",
    "        loss.backward()\n",
    "        for g in ae_s.parameters():\n",
    "            if g.grad is not None:\n",
    "                pass\n",
    "        ls.append(loss.item())\n",
    "    print(f\"extra ep {ep+1} loss {np.mean(ls):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "388f0404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encode entire slice\n",
    "ae_s.eval()\n",
    "Z = []\n",
    "with torch.no_grad():\n",
    "    for xb in DataLoader(ds_s, batch_size=128):\n",
    "        xb = xb.to(device)\n",
    "        z = ae_s.encode(xb)\n",
    "        Z.append(z.cpu().numpy())\n",
    "Z = np.concatenate(Z, axis=0)\n",
    "plt.figure(); plt.hist(Z[:,0], bins=30); plt.title(\"Z[:,0]\"); plt.show()\n",
    "plt.figure(); plt.hist(Z[:,1], bins=30); plt.title(\"Z[:,1]\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429d2c9",
   "metadata": {},
   "source": [
    "### Q3 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32e49556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity: 64 / 64\n",
      "First 10 valid:\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    samp = vae.sample(64, stoi_qm, itos_qm, max_len=max_len_qm, device=device)\n",
    "valid = [is_valid_smiles(s) for s in samp]\n",
    "print(\"Validity:\", sum(valid), \"/\", len(samp))\n",
    "print(\"First 10 valid:\")\n",
    "cnt = 0\n",
    "for s in samp:\n",
    "    if is_valid_smiles(s):\n",
    "        print(s)\n",
    "        cnt += 1\n",
    "        if cnt >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f34639",
   "metadata": {},
   "source": [
    "### Q4 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf304d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid steps: 8 / 8\n",
      "0: CCCC   valid=True\n",
      "1: CCCC   valid=True\n",
      "2: CCCC   valid=True\n",
      "3: CCCC   valid=True\n",
      "4: CCCC   valid=True\n",
      "5: CCCC   valid=True\n",
      "6: CCCC   valid=True\n",
      "7: CCCC   valid=True\n"
     ]
    }
   ],
   "source": [
    "a, b = qm_smiles[0], qm_smiles[1]\n",
    "outs = interpolate(vae, a, b, stoi_qm, itos_qm, steps=8, device=device, max_len=max_len_qm)\n",
    "val = [is_valid_smiles(s) for s in outs]\n",
    "print(\"Valid steps:\", sum(val), \"/\", len(outs))\n",
    "for i,(s,ok) in enumerate(zip(outs, val)):\n",
    "    print(f\"{i}: {s}   valid={ok}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcba93a",
   "metadata": {},
   "source": [
    "### Q5 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2704def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity around z_avg: 10 / 10\n",
      "\n",
      "Five samples:\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n",
      "CCCC\n"
     ]
    }
   ],
   "source": [
    "# encode all mus for nearest neighbor search\n",
    "vae.eval()\n",
    "M = []\n",
    "with torch.no_grad():\n",
    "    for xb in DataLoader(ds_vae, batch_size=256):\n",
    "        xb = xb.to(device)\n",
    "        mu = vae.encode(xb)\n",
    "        M.append(mu.cpu().numpy())\n",
    "Mu = np.concatenate(M, axis=0)  # [N, zdim]\n",
    "\n",
    "# pick query\n",
    "s_star = qm_smiles[10]\n",
    "x_star = torch.from_numpy(encode_smiles(s_star, stoi_qm, max_len_qm)).unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    mu_star = vae.encode(x_star).cpu().numpy()[0]\n",
    "\n",
    "# nearest neighbors\n",
    "d = np.linalg.norm(Mu - mu_star, axis=1)\n",
    "idx = np.argsort(d)[:5]\n",
    "z_avg = Mu[idx].mean(axis=0)\n",
    "\n",
    "# sample around z_avg\n",
    "with torch.no_grad():\n",
    "    z = torch.from_numpy(z_avg).float().unsqueeze(0).to(device)\n",
    "    outs = []\n",
    "    for _ in range(10):\n",
    "        z_noisy = z + 0.1*torch.randn_like(z)\n",
    "        cur = torch.full((1,1), stoi_qm[\"<bos>\"], dtype=torch.long, device=device)\n",
    "        h=None; seq=[]\n",
    "        for _ in range(max_len_qm):\n",
    "            emb = vae.emb(cur)\n",
    "            zrep = z_noisy.unsqueeze(1)\n",
    "            dec_cat = torch.cat([emb, zrep], dim=2)\n",
    "            dec_out, h = vae.decoder(dec_cat, h)\n",
    "            logits = vae.out(dec_out[:,-1,:])\n",
    "            nxt = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            seq.append(nxt); cur = nxt\n",
    "        ids = torch.cat(seq, dim=1)\n",
    "        outs.append(decode_ids(ids[0].cpu().numpy(), itos_qm))\n",
    "\n",
    "ok = [is_valid_smiles(s) for s in outs]\n",
    "print(\"Validity around z_avg:\", sum(ok), \"/\", len(outs))\n",
    "print(\"\\nFive samples:\")\n",
    "for s in outs[:5]:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "source_map": [
   12,
   44,
   65,
   69,
   88,
   92,
   117,
   121,
   152,
   166,
   184,
   198,
   248,
   252,
   274,
   278,
   287,
   307,
   330,
   334,
   346,
   382,
   440,
   444,
   454,
   462,
   484,
   488,
   495,
   499,
   505,
   509,
   518,
   526,
   561,
   569,
   587,
   591,
   619,
   623,
   635,
   735,
   766,
   770,
   788,
   800,
   804,
   818,
   822,
   829,
   833
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}