{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb35755",
   "metadata": {},
   "source": [
    "# Lecture 13 - De novo Molecule Generation\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    ":depth: 1\n",
    "```\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Connect **unsupervised learning** ideas to **molecular generation**.\n",
    "- Explain what an **encoder** and a **decoder** are.\n",
    "- Build a tiny **Autoencoder (AE)** for SMILES and discuss its limits for generation.\n",
    "- Understand the **Variational Autoencoder (VAE)** idea and why it helps sampling.\n",
    "- Train a small **VAE on SMILES** and generate new molecules.\n",
    "- Inspect what **encode** outputs look like and how sampling works in latent space.\n",
    "\n",
    "[![Colab](https://img.shields.io/badge/Open-Colab-orange)](https://colab.research.google.com/drive/1uFA0HFGqZ71MP02VM3wDn_TUacgXYCJ4?usp=sharing)\n",
    "\n",
    "\n",
    "\n",
    "## 1. Setup and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b4ce98",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\users\\52377\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (c:\\users\\52377\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Core\n",
    "import os, math, random, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "  import deepchem as dc\n",
    "except Exception:\n",
    "  %pip -q install deepchem\n",
    "  import deepchem as dc\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "try:\n",
    "    from rdkit import Chem, RDLogger\n",
    "    from rdkit.Chem import Descriptors, Crippen, rdMolDescriptors, QED, Draw\n",
    "    RD = True\n",
    "except Exception:\n",
    "    try:\n",
    "      %pip install rdkit\n",
    "      from rdkit import Chem, RDLogger\n",
    "      from rdkit.Chem import Descriptors, Crippen, rdMolDescriptors, QED, Draw\n",
    "      RD = True\n",
    "    except:\n",
    "      print(\"RDKit not installed\")\n",
    "      RD = False\n",
    "      Chem = None\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Quiet RDKit\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c9eb21",
   "metadata": {},
   "source": [
    "Similar to Lecture 11, we will first build a 10 descriptor dataset for our 575 molecules loaded from C-H oxidation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/C_H_oxidation_dataset.csv\"\n",
    "df_raw = pd.read_csv(url)\n",
    "\n",
    "\n",
    "def calc_descriptors10(smiles: str):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    return pd.Series({\n",
    "        \"MolWt\": Descriptors.MolWt(m),\n",
    "        \"LogP\": Crippen.MolLogP(m),\n",
    "        \"TPSA\": rdMolDescriptors.CalcTPSA(m),\n",
    "        \"NumRings\": rdMolDescriptors.CalcNumRings(m),\n",
    "        \"NumHAcceptors\": rdMolDescriptors.CalcNumHBA(m),\n",
    "        \"NumHDonors\": rdMolDescriptors.CalcNumHBD(m),\n",
    "        \"NumRotatableBonds\": rdMolDescriptors.CalcNumRotatableBonds(m),\n",
    "        \"HeavyAtomCount\": Descriptors.HeavyAtomCount(m),  \n",
    "        \"FractionCSP3\": rdMolDescriptors.CalcFractionCSP3(m),\n",
    "        \"NumAromaticRings\": rdMolDescriptors.CalcNumAromaticRings(m)\n",
    "    })\n",
    "\n",
    "desc10 = df_raw[\"SMILES\"].apply(calc_descriptors10)   # 10 descriptors\n",
    "df10 = pd.concat([df_raw, desc10], axis=1)\n",
    "df10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa5c1f",
   "metadata": {},
   "source": [
    "In the previous lecture, we learned how to explore our dataset by plotting the distribution of molecular properties using histograms.\n",
    "\n",
    "Another way is with a **mask**, which filters molecules by conditions like `molecular weight`, `LogP`, etc. Later in this class we’ll generate new molecules, so it’s helpful to see how many remain in our training set after applying these filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New mask: MolWt between 100–400, LogP between -1 and 5\n",
    "mask = (\n",
    "    (df10[\"MolWt\"].between(100, 400)) &\n",
    "    (df10[\"LogP\"].between(-1, 3)) )\n",
    "\n",
    "# Apply sampling\n",
    "df_small = df10[mask].copy().sample(min(500, mask.sum()), random_state=42)\n",
    "df_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe6615",
   "metadata": {},
   "source": [
    "## 2. Unsupervised recap with a tiny PCA\n",
    "\n",
    "We standardize 10D descriptors and compute a 2D `PCA()` for a quick map. Recall that PCA helps us reduce complexity while preserving the main variation in the data, making it easier to visualize patterns and clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "feat_cols = [\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\",\"NumHAcceptors\",\"NumHDonors\",\n",
    "             \"NumRotatableBonds\",\"HeavyAtomCount\",\"FractionCSP3\",\"NumAromaticRings\"]\n",
    "X = df_small[feat_cols].to_numpy(dtype=float)\n",
    "scaler = StandardScaler().fit(X)\n",
    "Xz = scaler.transform(X)\n",
    "\n",
    "pca = PCA(n_components=2).fit(Xz)\n",
    "Zp = pca.transform(Xz)\n",
    "print(f\"Five Examples of molecules (coordinates): {Zp[:5]}\")\n",
    "\n",
    "\n",
    "plt.scatter(Zp[:,0], Zp[:,1], c=df_small[\"NumRings\"], cmap=\"viridis\", s=12, alpha=0.7)\n",
    "plt.colorbar(label=\"NumRings\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.title(\"PCA on 10 descriptors\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9693d",
   "metadata": {},
   "source": [
    "In the scatter plot we colored the points by the number of rings. This is not required every time, and you could just use a single color for all points. Adding a property as color is simply a way to help you better visualize patterns in the PCA map.\n",
    "\n",
    "In the scatter plot we colored the points by the number of rings. This is not required every time, and you could just use a single color for all points. Adding a property as color is simply a way to help you better visualize patterns in the PCA map.\n",
    "\n",
    "Below we look at `loadings` to see which descriptors drive PC1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa929cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.Series(pca.components_[0], index=feat_cols).sort_values()\n",
    "loadings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a27d98",
   "metadata": {},
   "source": [
    "```{admonition} ⏰ Exercise 2\n",
    "Replace color by `TPSA` in the PCA scatter. What region corresponds to high TPSA\n",
    "```\n",
    "\n",
    "## 3. Autoencoder on descriptors\n",
    "\n",
    "We will train a tiny autoencoder (AE) that learns a low-dimensional summary of our 10 standardized descriptors. \n",
    "\n",
    "Let a molecule’s descriptor vector be:\n",
    "$\n",
    "x \\in \\mathbb{R}^{10}\n",
    "$\n",
    "\n",
    "The **encoder** is a function $f_\\theta$ parameterized by weights $\\theta$. It maps the input $x$ into a **latent code** $z$:\n",
    "\n",
    "$\n",
    "z = f_\\theta(x), \\quad z \\in \\mathbb{R}^2\n",
    "$\n",
    "\n",
    "The **decoder** is a function $g_\\phi$ parameterized by weights $\\phi$. It maps $z$ back to a reconstructed vector $\\hat{x}$ in the original descriptor space:\n",
    "\n",
    "$\n",
    "\\hat{x} = g_\\phi(z), \\quad \\hat{x} \\in \\mathbb{R}^{10}\n",
    "$\n",
    "\n",
    "The training goal is to minimize the **reconstruction loss**, measured by the mean squared error (MSE) between the input and its reconstruction:\n",
    "\n",
    "$\n",
    "\\mathcal{L}(\\theta, \\phi) \\;=\\; \\frac{1}{N} \\sum_{i=1}^N \\lVert x_i - \\hat{x}_i \\rVert_2^2\n",
    "\\quad \\text{with} \\quad \\hat{x}_i = g_\\phi\\!\\big(f_\\theta(x_i)\\big).\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "- The **encoder** acts like a compressor: it reduces the 10D descriptor into 2D latent space.  \n",
    "- The **decoder** acts like an expander: it tries to reconstruct the original 10D input from the 2D code.  \n",
    "- The **loss function** measures how close the reconstructed vector is to the original input.  \n",
    "\n",
    "By training the AE, we learn a latent space where molecules with similar properties may cluster together. Later, this latent space will be useful for generation, since we can sample points in the space and decode them into new molecular-like descriptors.\n",
    "Intuitively, the encoder compresses, the decoder unpacks, and the loss measures how faithful the unpacked vector is to the input.\n",
    "\n",
    "We now implement a very small AE in PyTorch with one hidden layer of 8 units.  \n",
    "\n",
    "Our input has 10 features, this allows the encoder to pass through a slightly smaller hidden layer before reaching the **bottleneck size (2D)**, which forces information to be distilled.  \n",
    "\n",
    "In other words, \n",
    "the encoder reduces 10 → 8 → 2, and the decoder reconstructs 2 → 8 → 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61af6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyAE(nn.Module):\n",
    "    def __init__(self, in_dim=10, hid=8, z_dim=2):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(nn.Linear(in_dim, hid), nn.ReLU(), nn.Linear(hid, z_dim))\n",
    "        self.dec = nn.Sequential(nn.Linear(z_dim, hid), nn.ReLU(), nn.Linear(hid, in_dim))\n",
    "    def encode(self, x): return self.enc(x)\n",
    "    def decode(self, z): return self.dec(z)\n",
    "    def forward(self, x):\n",
    "        z = self.enc(x)\n",
    "        xr = self.dec(z)\n",
    "        return xr, z\n",
    "\n",
    "ae = TinyAE(in_dim=10, hid=8, z_dim=2)\n",
    "ae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11e3a6",
   "metadata": {},
   "source": [
    "We now wrap our standardized descriptors into a PyTorch dataset and build a DataLoader. The DataLoader controls how many samples are processed in each mini-batch.\n",
    "\n",
    "Since our dataset has about 500 molecules, `Batch size = 64` is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i]\n",
    "\n",
    "ds = ArrayDataset(Xz)\n",
    "dl = DataLoader(ds, batch_size=64, shuffle=True)\n",
    "xb = next(iter(dl))\n",
    "xb.shape, xb[0,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135dee0b",
   "metadata": {},
   "source": [
    "Train for a few epochs and watch the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b631135",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(ae.parameters(), lr=1e-3)\n",
    "losses = []\n",
    "for ep in range(8):\n",
    "    for xb in dl:\n",
    "        xr, z = ae(xb)\n",
    "        loss = nn.functional.mse_loss(xr, xb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        losses.append(loss.item())\n",
    "plt.plot(losses); plt.xlabel(\"step\"); plt.ylabel(\"MSE\"); plt.title(\"AE training loss\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e71a3",
   "metadata": {},
   "source": [
    "After training, we use the encoder to map all molecules into the 2D latent space. Each row of `Z` is a compressed representation of one molecule. This is what **encode** returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f76501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Z = ae.encode(torch.from_numpy(Xz.astype(np.float32))).numpy()\n",
    "Z[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 3 random molecules\n",
    "sample_df = df_small.sample(3, random_state=42)\n",
    "\n",
    "# Get SMILES and mol objects\n",
    "smiles_list = sample_df[\"SMILES\"].tolist()\n",
    "mol_list = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
    "\n",
    "# Encode the descriptors into latent space\n",
    "with torch.no_grad():\n",
    "    sample_X = scaler.transform(sample_df[feat_cols].to_numpy(dtype=float))\n",
    "    Z_sample = ae.encode(torch.from_numpy(sample_X.astype(np.float32))).numpy()\n",
    "\n",
    "# Draw molecules\n",
    "img = Draw.MolsToGridImage(mol_list, molsPerRow=3, subImgSize=(200,200), legends=[f\"SMILES: {s}\" for s in smiles_list])\n",
    "display(img)\n",
    "\n",
    "# Print SMILES and encodings\n",
    "for smi, z in zip(smiles_list, Z_sample):\n",
    "    print(f\"SMILES: {smi}\")\n",
    "    print(f\"Encoded (z1, z2): {z}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c170fe0",
   "metadata": {},
   "source": [
    "Plot the latent and color by LogP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Z[:,0], Z[:,1], c=df_small[\"LogP\"], cmap=\"coolwarm\", s=12, alpha=0.8)\n",
    "plt.xlabel(\"z1\"); plt.ylabel(\"z2\"); plt.title(\"AE latent (color = LogP)\")\n",
    "plt.colorbar(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd73525",
   "metadata": {},
   "source": [
    "```{admonition} ⏰ **Exercise**\n",
    "Change `z_dim` to 3 in `TinyAE` and plot the latent. Do you see any difference?\n",
    "```\n",
    "\n",
    "Below we pick one random molecule to show after autoencoder compresses descriptors into latent space, it **then reconstructs them back**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one molecule\n",
    "one_row = df_small.sample(1, random_state=7)\n",
    "one_smiles = one_row[\"SMILES\"].iloc[0]\n",
    "one_mol = Chem.MolFromSmiles(one_smiles)\n",
    "\n",
    "# Original descriptors (unscaled)\n",
    "x_orig = one_row[feat_cols].to_numpy(dtype=float)\n",
    "\n",
    "# Encode and decode (roundtrip)\n",
    "with torch.no_grad():\n",
    "    x_std = scaler.transform(x_orig)                                  # standardize\n",
    "    z = ae.encode(torch.from_numpy(x_std.astype(np.float32))).numpy() # latent code\n",
    "    x_rec_std = ae.decode(torch.from_numpy(z.astype(np.float32))).numpy()\n",
    "x_rec = scaler.inverse_transform(x_rec_std)                           # back to original units\n",
    "\n",
    "# Comparison table\n",
    "df_compare = pd.DataFrame({\n",
    "    \"Descriptor\": feat_cols,\n",
    "    \"Original\": x_orig.flatten(),\n",
    "    \"Reconstructed\": x_rec.flatten()\n",
    "})\n",
    "df_compare[\"AbsError\"] = np.abs(df_compare[\"Original\"] - df_compare[\"Reconstructed\"])\n",
    "\n",
    "# Show molecule image\n",
    "img = Draw.MolsToGridImage([one_mol], molsPerRow=1, subImgSize=(260,260), legends=[f\"SMILES: {one_smiles}\"])\n",
    "display(img)\n",
    "\n",
    "# Print latent vector\n",
    "print(\"=== Roundtrip demonstration ===\")\n",
    "print(f\"SMILES: {one_smiles}\")\n",
    "print(f\"Latent z = ({z[0,0]:.4f}, {z[0,1]:.4f})\\n\")\n",
    "\n",
    "# Display table\n",
    "from IPython.display import display\n",
    "display(df_compare.style.format({\"Original\": \"{:.3f}\", \"Reconstructed\": \"{:.3f}\", \"AbsError\": \"{:.3f}\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207d52f",
   "metadata": {},
   "source": [
    "In the above section, we saw that using a simple autoencoder on 10 descriptors with a very narrow bottleneck (10 → 8 → 2 → 8 → 10) generally did a fair job on reconstructions but not very good. This happens because descriptors are continuous, relatively few, and do not contain enough redundancy for the network to compress and expand reliably.\n",
    "\n",
    "A better strategy for testing reconstruction is to use **high-dimensional representations**. These vectors typically give the autoencoder much richer structure to learn from. Still, with limited data (~500) in our case it will not be perfect, but at least give you an idea of the improvement we can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "\n",
    "# 1) Build Morgan fingerprints from df_small[\"SMILES\"]\n",
    "#    Uses radius=2, 1024 bits for stronger capacity than 10 descriptors.\n",
    "def morgan_bits(smiles, nBits=512, radius=2):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    bv = AllChem.GetMorganFingerprintAsBitVect(m, radius=radius, nBits=nBits)\n",
    "    arr = np.zeros((nBits,), dtype=np.int8)\n",
    "    Chem.DataStructs.ConvertToNumpyArray(bv, arr)\n",
    "    return arr\n",
    "\n",
    "smiles_all = df_small[\"SMILES\"].tolist()\n",
    "X_bits = np.vstack([morgan_bits(s, 512, 2) for s in smiles_all]).astype(np.float32)\n",
    "\n",
    "# 2) Dataset + DataLoader\n",
    "class BitsetDS(Dataset):\n",
    "    def __init__(self, X): self.X = torch.from_numpy(X)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i]\n",
    "ds = BitsetDS(X_bits)\n",
    "dl = DataLoader(ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# 3) AE with higher capacity; BCEWithLogitsLoss for binary recon\n",
    "class MorganAE(nn.Module):\n",
    "    def __init__(self, in_dim=512, h1=256, h2=128, z_dim=32):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(in_dim, h1), nn.ReLU(),\n",
    "            nn.Linear(h1, h2), nn.ReLU(),\n",
    "            nn.Linear(h2, z_dim)\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(z_dim, h2), nn.ReLU(),\n",
    "            nn.Linear(h2, h1), nn.ReLU(),\n",
    "            nn.Linear(h1, in_dim)  # logits\n",
    "        )\n",
    "    def encode(self, x): return self.enc(x)\n",
    "    def decode_logits(self, z): return self.dec(z)  # logits\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        logits = self.decode_logits(z)\n",
    "        return logits, z\n",
    "\n",
    "ae = MorganAE()\n",
    "opt = optim.Adam(ae.parameters(), lr=1e-3)\n",
    "crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 4) Train (few epochs already fit very well for 1024-bit vectors)\n",
    "ae.train()\n",
    "for ep in range(100):\n",
    "    for xb in dl:\n",
    "        logits, _ = ae(xb)\n",
    "        loss = crit(logits, xb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "# 5) Pick one random molecule; show SMILES, Morgan bits, latent, reconstructed bits\n",
    "idx = 102\n",
    "smi = smiles_all[idx]\n",
    "mol = Chem.MolFromSmiles(smi)\n",
    "x_bits = torch.from_numpy(X_bits[idx:idx+1])  # shape (1, 1024)\n",
    "\n",
    "ae.eval()\n",
    "with torch.no_grad():\n",
    "    z = ae.encode(x_bits).numpy()[0]                                  # latent vector\n",
    "    logits = ae.decode_logits(torch.from_numpy(z[None, :]).float())   # logits\n",
    "    probs = torch.sigmoid(logits).numpy()[0]                          # probabilities in [0,1]\n",
    "    x_rec_bits = (probs >= 0.5).astype(np.float32)                    # thresholded reconstruction\n",
    "    acc = (x_rec_bits == X_bits[idx]).mean()\n",
    "\n",
    "# 6) Display: molecule image, text summary; show first 64 bits for compact view\n",
    "img = Draw.MolsToGridImage([mol], molsPerRow=1, subImgSize=(280, 280), legends=[f\"SMILES: {smi}\"])\n",
    "display(img)\n",
    "\n",
    "print(\"=== Random molecule roundtrip with Morgan-AE ===\")\n",
    "print(f\"SMILES: {smi}\")\n",
    "print(f\"Latent z (length {len(z)}): {np.round(z, 3)}\")\n",
    "print(f\"Bit accuracy (full 512): {acc:.4f}\")\n",
    "print(\"\\nFirst 64 original bits:\\n\", \"\".join(map(str, X_bits[idx, :100].astype(int))))\n",
    "print(\"First 64 reconstructed bits:\\n\", \"\".join(map(str, x_rec_bits[:100].astype(int))))\n",
    "\n",
    "# Also show a compact table with counts\n",
    "orig_ones = int(X_bits[idx].sum())\n",
    "rec_ones = int(x_rec_bits.sum())\n",
    "agree_ones = int(((X_bits[idx] == 1) & (x_rec_bits == 1)).sum())\n",
    "agree_zeros = int(((X_bits[idx] == 0) & (x_rec_bits == 0)).sum())\n",
    "print(\"\\nCounts:\")\n",
    "print(pd.DataFrame({\n",
    "    \"metric\": [\"orig ones\", \"rec ones\", \"agree ones\", \"agree zeros\", \"total acc\"],\n",
    "    \"value\": [orig_ones, rec_ones, agree_ones, agree_zeros, f\"{acc:.4f}\"]\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8584f",
   "metadata": {},
   "source": [
    "Note that for the **Morgan fingerprint autoencoder** the input vectors are **binary (0/1)**. In this case, we want the decoder to output logits that are turned into probabilities with a sigmoid. To measure the reconstruction, we use the **binary cross-entropy loss (BCE)**, specifically `BCEWithLogitsLoss` in PyTorch.  \n",
    "\n",
    "The BCE loss is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{BCE}}(\\theta,\\phi) \\;=\\; - \\frac{1}{N}\\sum_{i=1}^N \\sum_{j=1}^{1024}\n",
    "\\Big[ x_{ij}\\,\\log \\sigma(\\hat{x}_{ij}) + (1-x_{ij})\\,\\log(1-\\sigma(\\hat{x}_{ij})) \\Big]\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $x_{ij} \\in \\{0,1\\}$ is the true fingerprint bit.  \n",
    "- $\\hat{x}_{ij} \\in \\mathbb{R}$ is the decoder’s raw output (logit).  \n",
    "- $\\sigma(\\hat{x}_{ij}) = \\tfrac{1}{1+e^{-\\hat{x}_{ij}}}$ is the sigmoid that maps logits to probabilities.  \n",
    "\n",
    "\n",
    "While in previous case, the **descriptor autoencoder (10 → 8 → 2 → 8 → 10)** we minimized **mean squared error (MSE)** because the inputs were continuous-valued descriptors. The loss was:\n",
    "$$\n",
    "\\mathcal{L}_{\\text{MSE}}(\\theta,\\phi) \\;=\\; \\frac{1}{N}\\sum_{i=1}^N \\lVert x_i - \\hat{x}_i \\rVert_2^2\n",
    "$$\n",
    "\n",
    "where $x_i \\in \\mathbb{R}^{10}$ are real-valued molecular descriptors.\n",
    "\n",
    "```{admonition} Key difference\n",
    "\n",
    "- **Descriptors AE:** uses **MSE loss** because inputs are continuous real values.  \n",
    "- **Morgan AE:** uses **BCE loss** because inputs are binary bits (0/1).  \n",
    "```\n",
    "\n",
    "\n",
    "## 4. Why AE is tricky for SMILES\n",
    "\n",
    "While it is exciting to see the decoder can convert latent variable back to something similar to the input, it is important to point out a issue when it's molecule generation:  \n",
    "> an autoencoder that reconstructs descriptors or fingerprints does not guarantee that the reconstructed vector actually corresponds to a real molecule or a valid SMILES string.\n",
    "\n",
    "- With **descriptors**, the AE only learns to match numerical values (like MolWt, LogP, TPSA). A reconstructed descriptor vector might have numbers that do not correspond to any chemically valid structure. For example, a molecule cannot simultaneously have a negative molecular weight or a non-integer ring count.  \n",
    "\n",
    "- With **fingerprints**, the AE tries to reconstruct binary patterns. A reconstructed bit vector might not map back to any actual molecule, since Morgan fingerprints are not bijective (different molecules can share fingerprints, and not every bit pattern corresponds to a valid molecule).  \n",
    "\n",
    "So even if the AE achieves a **low reconstruction error**, there is no guarantee that $\\hat{x}$ corresponds to a valid SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f7641",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# --- assumes these exist from earlier cells ---\n",
    "# df10, df_small, feat_cols, scaler, Xz\n",
    "\n",
    "# 0) Discrete/continuous fields and tolerances (your originals)\n",
    "DISCRETE = [\"NumRings\",\"NumHAcceptors\",\"NumHDonors\",\"NumRotatableBonds\",\"HeavyAtomCount\",\"NumAromaticRings\"]\n",
    "CONTINUOUS = [c for c in feat_cols if c not in DISCRETE]\n",
    "TOL = {\"MolWt\": 2.0, \"LogP\": 0.2, \"TPSA\": 5.0, \"FractionCSP3\": 0.05}\n",
    "\n",
    "def find_match_in_dataset(target: pd.Series, df_features: pd.DataFrame):\n",
    "    mask = np.ones(len(df_features), dtype=bool)\n",
    "    for d in DISCRETE:\n",
    "        mask &= (df_features[d].round().astype(int) == int(round(target[d])))\n",
    "    for c in CONTINUOUS:\n",
    "        tol = TOL.get(c, 0.5)\n",
    "        mask &= (np.abs(df_features[c] - target[c]) <= tol)\n",
    "    idx = np.where(mask)[0]\n",
    "    return idx\n",
    "\n",
    "def nearest_neighbors(target_vec: np.ndarray, mat: np.ndarray, k=5):\n",
    "    d = np.linalg.norm(mat - target_vec[None, :], axis=1)\n",
    "    order = np.argsort(d)\n",
    "    return order[:k], d[order[:k]]\n",
    "\n",
    "# 1) Define a descriptor AE separate from any Morgan AE\n",
    "class TinyDescriptorAE(nn.Module):\n",
    "    def __init__(self, in_dim=10, hid=8, z_dim=2):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid), nn.ReLU(),\n",
    "            nn.Linear(hid, z_dim)\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(z_dim, hid), nn.ReLU(),\n",
    "            nn.Linear(hid, in_dim)\n",
    "        )\n",
    "    def encode(self, x): return self.enc(x)\n",
    "    def decode(self, z): return self.dec(z)\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        xr = self.decode(z)\n",
    "        return xr, z\n",
    "\n",
    "# 2) Train desc_ae on standardized 10D descriptors\n",
    "desc_ae = TinyDescriptorAE(in_dim=10, hid=8, z_dim=2)\n",
    "dl = DataLoader(TensorDataset(torch.from_numpy(Xz.astype(np.float32))), batch_size=32, shuffle=True)\n",
    "opt = optim.Adam(desc_ae.parameters(), lr=1e-3)\n",
    "for ep in range(60):  # 60 short epochs; increase if you want tighter recon\n",
    "    for (xb,) in dl:\n",
    "        xr, _ = desc_ae(xb)\n",
    "        loss = nn.functional.mse_loss(xr, xb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "desc_ae.eval()\n",
    "\n",
    "# 3) Pick one molecule and do encode -> decode with the CORRECT model (desc_ae)\n",
    "one = df_small.sample(1, random_state=202)\n",
    "one_smiles = one[\"SMILES\"].iloc[0]\n",
    "one_mol = Chem.MolFromSmiles(one_smiles)\n",
    "\n",
    "x_orig = one[feat_cols].to_numpy(dtype=float)             # shape (1, 10)\n",
    "with torch.no_grad():\n",
    "    x_std = scaler.transform(x_orig).astype(np.float32)   # standardize\n",
    "    z = desc_ae.encode(torch.from_numpy(x_std)).numpy()   # latent via desc_ae\n",
    "    x_rec_std = desc_ae.decode(torch.from_numpy(z.astype(np.float32))).numpy()\n",
    "x_rec = scaler.inverse_transform(x_rec_std)[0]            # back to original units\n",
    "\n",
    "# 4) Build a \"constrained\" target by rounding discrete fields and clipping bounds\n",
    "target = pd.Series(x_rec, index=feat_cols)\n",
    "for d in DISCRETE:\n",
    "    target[d] = int(round(float(target[d])))\n",
    "target[\"FractionCSP3\"] = float(np.clip(target[\"FractionCSP3\"], 0.0, 1.0))\n",
    "for cnt in DISCRETE:\n",
    "    target[cnt] = max(0, int(target[cnt]))\n",
    "\n",
    "# 5) Search dataset for a feasible match under tolerances; else show nearest neighbors\n",
    "df_feats_only = df10[feat_cols].copy()\n",
    "matches = find_match_in_dataset(target, df_feats_only)\n",
    "\n",
    "print(\"=== Attempt to invert descriptors to a molecule ===\")\n",
    "print(f\"Original SMILES: {one_smiles}\")\n",
    "print(f\"Latent z: {np.round(z[0], 4)}\\n\")\n",
    "\n",
    "if len(matches) == 0:\n",
    "    print(\"No molecule in the dataset matches the reconstructed descriptor targets under tight tolerances.\\n\")\n",
    "    target_vec = target.values.astype(float)\n",
    "    mat = df_feats_only.to_numpy(dtype=float)\n",
    "    nn_idx, nn_dist = nearest_neighbors(target_vec, mat, k=5)\n",
    "    nn_rows = df10.iloc[nn_idx][[\"SMILES\"] + feat_cols].copy()\n",
    "    nn_rows.insert(1, \"distance\", nn_dist)\n",
    "    display(nn_rows.head(5).style.format(precision=3))\n",
    "    # Draw original vs nearest by descriptors\n",
    "    top1_smiles = df10.iloc[nn_idx[0]][\"SMILES\"]\n",
    "    top1_mol = Chem.MolFromSmiles(top1_smiles)\n",
    "    img = Draw.MolsToGridImage([one_mol, top1_mol], molsPerRow=2, subImgSize=(260,260),\n",
    "                               legends=[f\"Original\\n{one_smiles}\",\n",
    "                                        f\"Nearest by descriptors\\n{top1_smiles}\\nDist={nn_dist[0]:.3f}\"])\n",
    "    display(img)\n",
    "else:\n",
    "    print(f\"Found {len(matches)} dataset candidate(s) matching targets under tolerances.\")\n",
    "    display(df10.iloc[matches][[\"SMILES\"] + feat_cols].head(5))\n",
    "\n",
    "# 6) Compare original vs reconstructed target values\n",
    "compare = pd.DataFrame({\n",
    "    \"Descriptor\": feat_cols,\n",
    "    \"Original\": x_orig.flatten(),\n",
    "    \"Recon\": [target[c] for c in feat_cols]\n",
    "})\n",
    "compare[\"AbsError\"] = np.abs(compare[\"Original\"] - compare[\"Recon\"])\n",
    "display(compare.style.format({\"Original\": \"{:.3f}\", \"Recon\": \"{:.3f}\", \"AbsError\": \"{:.3f}\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c58a679",
   "metadata": {},
   "source": [
    "In the previous example we tried to decode reconstructed descriptors back to a molecule and saw that it often fails. The reconstructed values may look **numerically close**, yet they do not correspond to any real molecule. \n",
    "\n",
    "\n",
    "With SMILES the situation becomes even more fragile. A single misplaced character is enough to make the entire string invalid. Unlike descriptors, which are continuous and can be perturbed slightly without losing “type”, SMILES is a discrete symbolic language with strict syntax rules. \n",
    "Parentheses must balance, ring indices must pair, and atom valences must be chemically possible.  \n",
    "\n",
    "\n",
    "\n",
    "The following short experiment takes valid SMILES, applies a single random character disturbance, and checks whether the result is still valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: SMILES validity check and single-character perturbations\n",
    "\n",
    "def is_valid_smiles(s: str) -> bool:\n",
    "    return Chem.MolFromSmiles(s) is not None\n",
    "\n",
    "def random_char_edit(s: str, alphabet=None, p_insert=0.33, p_delete=0.33, p_sub=0.34):\n",
    "    if len(s) == 0: return s\n",
    "    if alphabet is None:\n",
    "        # Build a basic alphabet from common SMILES chars\n",
    "        alphabet = list(set(list(\"CNOFPSIclBr[#]=()1234567890+-@H[]\\\\/\")))\n",
    "    r = random.random()\n",
    "    i = random.randrange(len(s))\n",
    "    if r < p_insert:\n",
    "        c = random.choice(alphabet)\n",
    "        return s[:i] + c + s[i:]\n",
    "    elif r < p_insert + p_delete and len(s) > 1:\n",
    "        return s[:i] + s[i+1:]\n",
    "    else:\n",
    "        c = random.choice(alphabet)\n",
    "        return s[:i] + c + s[i+1:]\n",
    "\n",
    "# Experiment 1: one random edit kills validity most of the time\n",
    "smiles_list = df_small[\"SMILES\"].tolist()\n",
    "k = min(200, len(smiles_list))\n",
    "subset = random.sample(smiles_list, k)\n",
    "\n",
    "perturbed = [random_char_edit(s) for s in subset]\n",
    "valid_orig = sum(is_valid_smiles(s) for s in subset)\n",
    "valid_pert = sum(is_valid_smiles(s) for s in perturbed)\n",
    "print(f\"Original valid: {valid_orig}/{k}  = {valid_orig/k:.2%}\")\n",
    "print(f\"After 1 random edit valid: {valid_pert}/{k}  = {valid_pert/k:.2%}\")\n",
    "\n",
    "# Show a few examples\n",
    "rows = []\n",
    "for i in range(10):\n",
    "    s = subset[i]\n",
    "    t = perturbed[i]\n",
    "    rows.append({\n",
    "        \"orig\": s,\n",
    "        \"perturbed\": t,\n",
    "        \"orig_valid\": is_valid_smiles(s),\n",
    "        \"perturbed_valid\": is_valid_smiles(t)\n",
    "    })\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7337624b",
   "metadata": {},
   "source": [
    "This motivates a VAE which gives a distribution in latent space so we can sample smoothly and then decode to strings.\n",
    "\n",
    "## 5. Variational Autoencoder (VAE)\n",
    "\n",
    "An AE compresses each input to a single point in latent space and learns to reconstruct that point. By constrast, a *Variational* Autoencoder (VAE) treats the latent code as a probability distribution. Instead of mapping an input to one vector, the encoder predicts a mean and a variance for a Gaussian latent. During training we sample from this Gaussian and ask the decoder to reconstruct the input from the sampled point. A **Kullback–Leibler (KL)** term softly pulls the posterior toward a simple prior such as a standard normal. The result is a latent space that is smoother and more continuous, which makes sampling new points more reliable.\n",
    "\n",
    "This shift from **point encoding** to **distribution encoding** matters for generation. With a plain AE, latent space can be patchy. Interpolating between two codes can land you off the data manifold and the decoder struggles. \n",
    "\n",
    "With a VAE, the KL term discourages such patchiness. The model learns a latent space where nearby points decode to similar objects, which helps when we draw new samples from the prior. \n",
    "\n",
    "For SMILES generation, a well shaped latent space **does not** solve syntax by itself, but it does *reduce the chance that sampling lands in regions that decode to garbage*. In practice, VAEs pair well with more robust tokenizations or grammar constraints. Here we first build a compact VAE on the 10 standardized descriptors to make the idea concrete, then we show how to sample and decode new latent points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "\n",
    "class TinyVAE(nn.Module):\n",
    "    def __init__(self, in_dim=10, h=8, z_dim=2):\n",
    "        super().__init__()\n",
    "        # Encoder predicts mean and log-variance\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(in_dim, h), nn.ReLU(),\n",
    "            nn.Linear(h, h), nn.ReLU()\n",
    "        )\n",
    "        self.mu = nn.Linear(h, z_dim)\n",
    "        self.logvar = nn.Linear(h, z_dim)\n",
    "        # Decoder maps z back to x\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(z_dim, h), nn.ReLU(),\n",
    "            nn.Linear(h, h), nn.ReLU(),\n",
    "            nn.Linear(h, in_dim)\n",
    "        )\n",
    "    def encode(self, x):\n",
    "        h = self.enc(x)\n",
    "        return self.mu(h), self.logvar(h)\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    def decode(self, z):\n",
    "        return self.dec(z)\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        xr = self.decode(z)\n",
    "        return xr, mu, logvar, z\n",
    "\n",
    "def vae_loss(xr, x, mu, logvar, beta=1.0):\n",
    "    # MSE recon + beta * KL\n",
    "    recon = nn.functional.mse_loss(xr, x, reduction='mean')\n",
    "    # KL for diagonal Gaussians: -0.5 * sum(1 + logvar - mu^2 - exp(logvar))\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon + beta * kl, recon.item(), kl.item()\n",
    "\n",
    "# 1) Data loader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "X_tensor = torch.from_numpy(Xz.astype(np.float32))\n",
    "dl = DataLoader(TensorDataset(X_tensor), batch_size=128, shuffle=True)\n",
    "\n",
    "# 2) Train\n",
    "vae = TinyVAE(in_dim=10, h=8, z_dim=5)\n",
    "opt = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "steps, recon_hist, kl_hist, loss_hist = [], [], [], []\n",
    "global_step = 0\n",
    "epochs = 2000\n",
    "\n",
    "for ep in range(epochs):\n",
    "    # simple KL annealing from 0 -> 1 over training\n",
    "    beta = min(1.0, ep / max(1, epochs//2))\n",
    "    for (xb,) in dl:\n",
    "        xr, mu, logvar, z = vae(xb)\n",
    "        loss, r_item, k_item = vae_loss(xr, xb, mu, logvar, beta=beta)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        loss_hist.append(loss.item()); recon_hist.append(r_item); kl_hist.append(k_item)\n",
    "        steps.append(global_step); global_step += 1\n",
    "\n",
    "# 3) Plot training curves\n",
    "plt.figure()\n",
    "plt.plot(loss_hist, label=\"total\")\n",
    "plt.plot(recon_hist, label=\"recon\")\n",
    "plt.plot(kl_hist, label=\"kl\")\n",
    "plt.legend(); plt.xlabel(\"step\"); plt.ylabel(\"loss\"); plt.title(\"VAE training\")\n",
    "plt.show()\n",
    "\n",
    "# 4) Encode the dataset to latent means for visualization\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    mu_all, logvar_all = vae.encode(X_tensor)\n",
    "    Z_mu = mu_all.numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(Z_mu[:,0], Z_mu[:,1], s=12, alpha=0.7)\n",
    "plt.xlabel(\"z1\"); plt.ylabel(\"z2\"); plt.title(\"Latent means (VAE)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e13de9",
   "metadata": {},
   "source": [
    "The VAE maximizes the evidence lower bound (ELBO). In practice we minimize the negative ELBO, which has a reconstruction term and a KL term that regularizes the latent posterior toward the prior.\n",
    "\n",
    "$\n",
    "\\mathcal{L}_{\\text{VAE}}\n",
    "\\;=\\;\n",
    "\\underbrace{\\mathbb{E}_{q_\\phi(z\\mid x)}\\big[\\lVert x - \\hat{x}\\rVert_2^2\\big]}_{\\text{reconstruction}}\n",
    "\\;+\\;\n",
    "\\beta\\,\\underbrace{D_{\\text{KL}}\\!\\big(q_\\phi(z\\mid x)\\;\\|\\;p(z)\\big)}_{\\text{regularization}} \\,,\n",
    "\\quad p(z)=\\mathcal{N}(0,I).\n",
    "$\n",
    "\n",
    "To make sampling differentiable we use the reparameterization trick:\n",
    "$\n",
    "z = \\mu + \\sigma \\odot \\epsilon,\\quad \\epsilon \\sim \\mathcal{N}(0, I),\\quad \\sigma = \\exp\\big(\\tfrac{1}{2}\\log\\sigma^2\\big).\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea714d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE distribution comparison for MolWt, LogP, TPSA + one-molecule demo\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Assumes these exist: vae (trained), scaler, df_small, feat_cols, Xz\n",
    "\n",
    "# 1) Reconstruct the whole subset deterministically via latent means\n",
    "vae.eval()\n",
    "X_tensor = torch.from_numpy(Xz.astype(np.float32))\n",
    "with torch.no_grad():\n",
    "    mu_all, logvar_all = vae.encode(X_tensor)          # [N, zdim]\n",
    "    Xr_std = vae.decode(mu_all).numpy()                # standardized recon\n",
    "Xr = scaler.inverse_transform(Xr_std)                   # back to original units\n",
    "Xr_df = pd.DataFrame(Xr, columns=feat_cols)\n",
    "\n",
    "# Originals for comparison\n",
    "orig_df = df_small[feat_cols].reset_index(drop=True)\n",
    "\n",
    "# 2) Pick properties to compare\n",
    "props = [\"MolWt\", \"LogP\", \"TPSA\"]\n",
    "\n",
    "# 3) Histograms for each property (original vs reconstructed)\n",
    "bins = 40\n",
    "for p in props:\n",
    "    plt.figure(figsize=(5.5, 3.8))\n",
    "    plt.hist(orig_df[p].values, bins=bins, alpha=0.55, label=f\"{p} original\", density=True)\n",
    "    plt.hist(Xr_df[p].values,   bins=bins, alpha=0.55, label=f\"{p} reconstructed\", density=True)\n",
    "    plt.xlabel(p); plt.ylabel(\"density\"); plt.title(f\"{p}: original vs reconstructed\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 4) Single random molecule: structure, latent mean, and 3-descriptor table\n",
    "row = df_small.sample(1, random_state=314)\n",
    "smi = row[\"SMILES\"].iloc[0]\n",
    "mol = Chem.MolFromSmiles(smi)\n",
    "\n",
    "x_orig = row[feat_cols].to_numpy(dtype=float)          # (1, 10)\n",
    "with torch.no_grad():\n",
    "    x_std = scaler.transform(x_orig).astype(np.float32)\n",
    "    mu, logvar = vae.encode(torch.from_numpy(x_std))\n",
    "    z_mean = mu.numpy()[0]                             # latent mean (z-dim)\n",
    "    x_rec_std = vae.decode(mu).numpy()                 # decode from mean\n",
    "x_rec = scaler.inverse_transform(x_rec_std)            # (1, 10)\n",
    "\n",
    "# Build a concise comparison table for the three properties\n",
    "tbl = pd.DataFrame({\n",
    "    \"Property\": props,\n",
    "    \"Original\": [float(x_orig[0, feat_cols.index(p)]) for p in props],\n",
    "    \"Reconstructed\": [float(x_rec[0, feat_cols.index(p)]) for p in props]\n",
    "})\n",
    "tbl[\"AbsError\"] = (tbl[\"Original\"] - tbl[\"Reconstructed\"]).abs()\n",
    "\n",
    "# Show structure and print outputs\n",
    "img = Draw.MolsToGridImage([mol], molsPerRow=1, subImgSize=(280, 280), legends=[f\"SMILES: {smi}\"])\n",
    "display(img)\n",
    "print(\"Latent mean z:\", np.round(z_mean, 4))\n",
    "display(tbl.style.format({\"Original\": \"{:.3f}\", \"Reconstructed\": \"{:.3f}\", \"AbsError\": \"{:.3f}\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc704ad",
   "metadata": {},
   "source": [
    "## 6. SMILES VAE for De Novo Molecular Generation\n",
    "\n",
    "In the previous examples, we are limited by the size of training data and the model complexicity so in general the performance is not perfect. Now, we will train a small SMILES-based Variational Autoencoder (VAE) on ~4,000 molecules, then sample new molecules and evaluate how well they match the training set.\n",
    "\n",
    "Below are the steps:\n",
    "- Load a molecular dataset with DeepChem (QM9 subset)\n",
    "- Build a simple SMILES vocabulary\n",
    "- Train a GRU VAE for 10-30 epochs and plot loss\n",
    "- Generate new SMILES and filter invalid ones\n",
    "- Evaluate validity, uniqueness, novelty\n",
    "- Compare distributions of QED, logP, and molecular weight between train and generated sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QM9 via DeepChem (will download the dataset on first run)\n",
    "tasks, datasets, transformers = dc.molnet.load_qm9(featurizer='Raw')\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "\n",
    "def canonicalize_smiles(smi):\n",
    "    \"\"\"Return a canonical SMILES if valid, else None.\"\"\"\n",
    "    if not smi:\n",
    "        return None\n",
    "    try:\n",
    "        # Parse with sanitize=False then sanitize manually to catch errors cleanly\n",
    "        m = Chem.MolFromSmiles(smi, sanitize=False)\n",
    "        if m is None:\n",
    "            return None\n",
    "        Chem.SanitizeMol(m)\n",
    "        return Chem.MolToSmiles(m, canonical=True)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def dataset_to_smiles(ds, max_n=None):\n",
    "    \"\"\"Extract canonical SMILES from a DeepChem dataset of RDKit mols with progress updates.\"\"\"\n",
    "    out = []\n",
    "    n = len(ds.X) if max_n is None else min(len(ds.X), max_n)\n",
    "    step = max(1, n // 10)  # every 10%\n",
    "    for i in range(n):\n",
    "        mol = ds.X[i]\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "                can = canonicalize_smiles(smi)\n",
    "                if can:\n",
    "                    out.append(can)\n",
    "            except Exception:\n",
    "                continue\n",
    "        if (i + 1) % step == 0 or i == n - 1:\n",
    "            pct = int(((i + 1) / n) * 100)\n",
    "            print(f\"Progress: {pct}% ({i + 1}/{n})\")\n",
    "    return out\n",
    "\n",
    "# Collect a pool then de-duplicate\n",
    "pool_smiles = dataset_to_smiles(train_dataset, max_n=1200)\n",
    "pool_smiles = list(dict.fromkeys(pool_smiles))  # keep order, remove duplicates\n",
    "print(\"Pool size:\", len(pool_smiles))\n",
    "\n",
    "# If pool is smaller than certain number in your runtime, this will just take what's available\n",
    "target_n = 2000\n",
    "if len(pool_smiles) > target_n:\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    smiles_all = rng.choice(pool_smiles, size=target_n, replace=False).tolist()\n",
    "else:\n",
    "    smiles_all = pool_smiles[:target_n]\n",
    "\n",
    "print(\"Training pool size used:\", len(smiles_all))\n",
    "print(\"Sample:\", smiles_all[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08c68b",
   "metadata": {},
   "source": [
    "Train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles, val_smiles = train_test_split(smiles_all, test_size=0.1, random_state=SEED)\n",
    "len(train_smiles), len(val_smiles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2769259",
   "metadata": {},
   "source": [
    "We will build a simple character-level vocabulary. The model predicts the next character given the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL = [\"[PAD]\", \"[SOS]\", \"[EOS]\"]\n",
    "\n",
    "def build_vocab(smiles_list):\n",
    "    chars = set()\n",
    "    for s in smiles_list:\n",
    "        for ch in s:\n",
    "            chars.add(ch)\n",
    "    idx2ch = SPECIAL + sorted(chars)\n",
    "    ch2idx = {c:i for i,c in enumerate(idx2ch)}\n",
    "    return ch2idx, idx2ch\n",
    "\n",
    "ch2idx, idx2ch = build_vocab(train_smiles)\n",
    "PAD, SOS, EOS = ch2idx[\"[PAD]\"], ch2idx[\"[SOS]\"], ch2idx[\"[EOS]\"]\n",
    "vocab_size = len(idx2ch)\n",
    "\n",
    "MAX_LEN = 120  # raise if many strings are longer\n",
    "\n",
    "def smiles_to_idx(s):\n",
    "    toks = [SOS] + [ch2idx[ch] for ch in s if ch in ch2idx] + [EOS]\n",
    "    toks = toks[:MAX_LEN]\n",
    "    attn = [1]*len(toks)\n",
    "    if len(toks) < MAX_LEN:\n",
    "        toks += [PAD]*(MAX_LEN - len(toks))\n",
    "        attn += [0]*(MAX_LEN - len(attn))\n",
    "    return np.array(toks, dtype=np.int64), np.array(attn, dtype=np.int64)\n",
    "\n",
    "class SmilesDataset(Dataset):\n",
    "    def __init__(self, smiles_list):\n",
    "        enc = [smiles_to_idx(s) for s in smiles_list]\n",
    "        self.toks = np.stack([e[0] for e in enc])\n",
    "        self.attn = np.stack([e[1] for e in enc])\n",
    "    def __len__(self):\n",
    "        return len(self.toks)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.toks[idx]), torch.from_numpy(self.attn[idx])\n",
    "\n",
    "train_ds = SmilesDataset(train_smiles)\n",
    "val_ds   = SmilesDataset(val_smiles)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=128, shuffle=False, drop_last=False)\n",
    "\n",
    "print(\"Vocab size:\", vocab_size, \"Train size:\", len(train_ds), \"Val size:\", len(val_ds))\n",
    "print(\"Index to char sample:\", idx2ch[:40])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a5ae4",
   "metadata": {},
   "source": [
    "Now, we will define a tiny SMILES VAE (GRU encoder and decoder), which is a compact model that trains quickly:\n",
    "- Embedding\n",
    "- GRU encoder produces mean and log-variance for latent vector\n",
    "- GRU decoder generates characters\n",
    "- Loss = cross entropy + KL term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, hid_dim=256, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "        self.mu = nn.Linear(hid_dim, z_dim)\n",
    "        self.logvar = nn.Linear(hid_dim, z_dim)\n",
    "    def forward(self, x, attn):\n",
    "        emb = self.emb(x)\n",
    "        lengths = attn.sum(1).cpu()\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, h = self.gru(packed)\n",
    "        h = h[-1]\n",
    "        return self.mu(h), self.logvar(h)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, hid_dim=256, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
    "        self.fc_z = nn.Linear(z_dim, hid_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "        self.out = nn.Linear(hid_dim, vocab_size)\n",
    "    def forward(self, z, x_in):\n",
    "        h0 = self.fc_z(z).unsqueeze(0)\n",
    "        emb = self.emb(x_in)\n",
    "        o, _ = self.gru(emb, h0)\n",
    "        return self.out(o)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, hid_dim=256, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(vocab_size, emb_dim, hid_dim, z_dim)\n",
    "        self.dec = Decoder(vocab_size, emb_dim, hid_dim, z_dim)\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    def forward(self, x, attn):\n",
    "        mu, logvar = self.enc(x, attn)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        logits = self.dec(z, x[:, :-1])  # teacher forcing\n",
    "        return logits, mu, logvar\n",
    "\n",
    "def vae_loss(logits, x, mu, logvar, kl_weight=0.1):\n",
    "    targets = x[:, 1:]\n",
    "    ce = nn.functional.cross_entropy(logits.reshape(-1, logits.size(-1)),\n",
    "                                     targets.reshape(-1),\n",
    "                                     ignore_index=PAD)\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return ce + kl_weight*kl, ce.item(), kl.item()\n",
    "\n",
    "model = VAE(vocab_size).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693fa70",
   "metadata": {},
   "source": [
    "We track both training and validation loss. Lower is better. If validation loss stops improving, consider lowering learning rate or adding early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d485a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "hist = {\"train\": [], \"val\": [], \"ce\": [], \"kl\": []}\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    ce_losses = []\n",
    "    kl_losses = []\n",
    "    for x, a in train_loader:\n",
    "        x, a = x.to(device), a.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits, mu, logvar = model(x, a)\n",
    "        loss, ce, kl = vae_loss(logits, x, mu, logvar, kl_weight=0.1)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        train_losses.append(loss.item())\n",
    "        ce_losses.append(ce)\n",
    "        kl_losses.append(kl)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        for x, a in val_loader:\n",
    "            x, a = x.to(device), a.to(device)\n",
    "            logits, mu, logvar = model(x, a)\n",
    "            l, _, _ = vae_loss(logits, x, mu, logvar, kl_weight=0.1)\n",
    "            val_losses.append(l.item())\n",
    "    tr = float(np.mean(train_losses))\n",
    "    va = float(np.mean(val_losses)) if len(val_losses) > 0 else float('nan')\n",
    "    hist[\"train\"].append(tr)\n",
    "    hist[\"val\"].append(va)\n",
    "    hist[\"ce\"].append(float(np.mean(ce_losses)))\n",
    "    hist[\"kl\"].append(float(np.mean(kl_losses)))\n",
    "    print(f\"Epoch {ep:02d} | train {tr:.3f} | val {va:.3f} | CE {np.mean(ce_losses):.3f} | KL {np.mean(kl_losses):.3f}\")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist[\"train\"], label=\"Train loss\")\n",
    "plt.plot(hist[\"val\"], label=\"Val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"VAE loss over epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bbd7f4",
   "metadata": {},
   "source": [
    "Finally, we carry out sampling and evaluation.\n",
    "\n",
    "Sample strings from the decoder by drawing `z` from the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c026fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_smiles(n=1500, max_len=120, temp=1.0):\n",
    "    model.eval()\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(n, model.enc.mu.out_features, device=device)\n",
    "        x_t = torch.full((n,1), SOS, dtype=torch.long, device=device)\n",
    "        h = model.dec.fc_z(z).unsqueeze(0)\n",
    "        for t in range(max_len-1):\n",
    "            emb = model.dec.emb(x_t[:,-1:])\n",
    "            o, h = model.dec.gru(emb, h)\n",
    "            logits = model.dec.out(o[:, -1])\n",
    "            probs = nn.functional.softmax(logits / temp, dim=-1)\n",
    "            nxt = torch.multinomial(probs, num_samples=1)\n",
    "            x_t = torch.cat([x_t, nxt], dim=1)\n",
    "        seqs = x_t[:, 1:].tolist()\n",
    "    for seq in seqs:\n",
    "        chars = []\n",
    "        for idx in seq:\n",
    "            ch = idx2ch[idx]\n",
    "            if ch == \"[EOS]\":\n",
    "                break\n",
    "            if ch not in (\"[PAD]\", \"[SOS]\"):\n",
    "                chars.append(ch)\n",
    "        out.append(\"\".join(chars))\n",
    "    return out\n",
    "\n",
    "def safe_mol_from_smiles(smi):\n",
    "    if not smi:\n",
    "        return None\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(smi, sanitize=False)\n",
    "        if m is None:\n",
    "            return None\n",
    "        Chem.SanitizeMol(m)\n",
    "        return m\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def canonicalize_batch(smiles_list):\n",
    "    out = []\n",
    "    for s in smiles_list:\n",
    "        m = safe_mol_from_smiles(s)\n",
    "        if m is None:\n",
    "            continue\n",
    "        can = Chem.MolToSmiles(m, canonical=True)\n",
    "        if can:\n",
    "            out.append(can)\n",
    "    return out\n",
    "\n",
    "gen_raw = sample_smiles(n=2000, temp=1.0)  # adjust temperature if desired\n",
    "gen_smiles = canonicalize_batch(gen_raw)\n",
    "\n",
    "print(\"Generated raw:\", len(gen_raw), \"Valid after sanitize:\", len(gen_smiles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe435e",
   "metadata": {},
   "source": [
    "Filter to valid canonical SMILES and compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8947ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def safe_mol_from_smiles(smi):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(smi, sanitize=False)\n",
    "        if m is None: return None\n",
    "        Chem.SanitizeMol(m)\n",
    "        return m\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def canonicalize_batch(smiles_list):\n",
    "    out = []\n",
    "    for s in smiles_list:\n",
    "        m = safe_mol_from_smiles(s)\n",
    "        if m is None: continue\n",
    "        can = Chem.MolToSmiles(m, canonical=True)\n",
    "        if can: out.append(can)\n",
    "    return out\n",
    "\n",
    "gen_smiles = canonicalize_batch(gen_raw)\n",
    "train_set = set(train_smiles)\n",
    "\n",
    "validity   = len(gen_smiles) / max(1, len(gen_raw))\n",
    "uniq_list  = list(dict.fromkeys(gen_smiles))\n",
    "uniqueness = len(uniq_list) / max(1, len(gen_smiles))\n",
    "novelty    = sum(1 for s in uniq_list if s not in train_set) / max(1, len(uniq_list))\n",
    "\n",
    "print(f\"Validity: {validity:.2f}  Uniqueness: {uniqueness:.2f}  Novelty: {novelty:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee231986",
   "metadata": {},
   "source": [
    "Compare property distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51667e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import QED, Crippen, Descriptors\n",
    "\n",
    "def props_from_smiles(smiles):\n",
    "    rows = []\n",
    "    for s in smiles:\n",
    "        m = safe_mol_from_smiles(s)\n",
    "        if m is None: continue\n",
    "        rows.append({\"SMILES\": s, \"QED\": QED.qed(m), \"logP\": Crippen.MolLogP(m), \"MW\": Descriptors.MolWt(m)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "train_unique = list(set(train_smiles))\n",
    "gen_unique   = list(set(gen_smiles))\n",
    "train_sample = rng.choice(train_unique, size=min(3000, len(train_unique)), replace=False)\n",
    "gen_sample   = rng.choice(gen_unique, size=min(3000, len(gen_unique)), replace=False)\n",
    "\n",
    "df_train = props_from_smiles(train_sample)\n",
    "df_gen   = props_from_smiles(gen_sample)\n",
    "\n",
    "def plot_dist(metric, bins=40):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(df_train[metric].dropna(), bins=bins, alpha=0.5, density=True, label=\"Train\")\n",
    "    plt.hist(df_gen[metric].dropna(),   bins=bins, alpha=0.5, density=True, label=\"Generated\")\n",
    "    plt.xlabel(metric); plt.ylabel(\"Density\"); plt.title(f\"{metric} distribution\"); plt.legend(); plt.show()\n",
    "\n",
    "for m in [\"QED\",\"logP\",\"MW\"]:\n",
    "    plot_dist(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f7912",
   "metadata": {},
   "source": [
    "```{admonition} ⏰ Exercise 6\n",
    "Run `sample_smiles` with temperatures 0.7 and 1.3. Which one increases validity Which one increases uniqueness How do the histograms shift\n",
    "```\n",
    "\n",
    "## 9. Glossary\n",
    "\n",
    "```{glossary}\n",
    "encoder\n",
    "  A mapping from input $x$ to latent $z$.\n",
    "\n",
    "decoder\n",
    "  A mapping from latent $z$ to reconstructed $\\hat x$.\n",
    "\n",
    "autoencoder (AE)\n",
    "  A model trained to reconstruct input. Learns a compact latent code.\n",
    "\n",
    "latent space\n",
    "  The internal coordinate used by the model to organize inputs.\n",
    "\n",
    "VAE\n",
    "  A probabilistic AE that learns $q_\\theta(z\\mid x)$ near a simple prior to enable sampling.\n",
    "\n",
    "validity\n",
    "  Fraction of generated strings that sanitize as molecules.\n",
    "\n",
    "uniqueness\n",
    "  Fraction of valid generated molecules that are unique.\n",
    "\n",
    "novelty\n",
    "  Fraction of unique generated molecules not present in the training set.\n",
    "```\n",
    "\n",
    "## 10. In-class activity with solutions\n",
    "\n",
    "**Q1.** AE latent: change `z_dim` to 3 and plot `z[:,0]` vs `z[:,1]`. Compare to `z[:,1]` vs `z[:,2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7244c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae3 = TinyAE(in_dim=10, hid=64, z_dim=3)\n",
    "opt = optim.Adam(ae3.parameters(), lr=1e-3)\n",
    "for ep in range(4):\n",
    "    for xb in dl:\n",
    "        xr, z = ae3(xb)\n",
    "        loss = nn.functional.mse_loss(xr, xb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "with torch.no_grad():\n",
    "    Z3 = ae3.encode(torch.from_numpy(Xz.astype(np.float32))).numpy()\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.scatter(Z3[:,0], Z3[:,1], s=10, alpha=0.7); plt.xlabel(\"z0\"); plt.ylabel(\"z1\"); plt.title(\"z0 vs z1\")\n",
    "plt.subplot(1,2,2); plt.scatter(Z3[:,1], Z3[:,2], s=10, alpha=0.7); plt.xlabel(\"z1\"); plt.ylabel(\"z2\"); plt.title(\"z1 vs z2\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b0ac1",
   "metadata": {},
   "source": [
    "**Q2.** VAE temperature sweep: compute validity for T in [0.7, 1.0, 1.3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ce53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [0.7, 1.0, 1.3]:\n",
    "    raw = sample_smiles(n=800, temp=t)\n",
    "    val = len(canonicalize_batch(raw)) / max(1, len(raw))\n",
    "    print(f\"T={t}: validity {val:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "source_map": [
   12,
   38,
   87,
   91,
   115,
   124,
   133,
   139,
   160,
   168,
   172,
   223,
   240,
   246,
   257,
   261,
   271,
   275,
   280,
   301,
   305,
   309,
   317,
   353,
   360,
   453,
   496,
   610,
   622,
   668,
   683,
   768,
   786,
   846,
   860,
   915,
   918,
   924,
   927,
   974,
   983,
   1039,
   1041,
   1088,
   1094,
   1150,
   1154,
   1185,
   1189,
   1217,
   1255,
   1269,
   1273
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}