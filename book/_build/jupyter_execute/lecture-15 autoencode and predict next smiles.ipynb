{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572abf9e",
   "metadata": {},
   "source": [
    "# Lecture 12 — Self-supervised Learning\n",
    " \n",
    "## 0. Setup for sections 7–8\n",
    "\n",
    "This file is self-contained. It installs packages if needed, loads the dataset, and prepares descriptor tables used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a198446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import sys, subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# RDKit (install if missing)\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors, Crippen, rdMolDescriptors\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    from rdkit import DataStructs\n",
    "except Exception as e:\n",
    "    print(\"Installing rdkit...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit-pypi\"])\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors, Crippen, rdMolDescriptors\n",
    "    from rdkit.Chem import rdFingerprintGenerator\n",
    "    from rdkit import DataStructs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d64070b",
   "metadata": {},
   "source": [
    "**Load the C–H oxidation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1583ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound Name</th>\n",
       "      <th>CAS</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility_mol_per_L</th>\n",
       "      <th>pKa</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Melting Point</th>\n",
       "      <th>Reactivity</th>\n",
       "      <th>Oxidation Site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3,4-dihydro-1H-isochromene</td>\n",
       "      <td>493-05-0</td>\n",
       "      <td>c1ccc2c(c1)CCOC2</td>\n",
       "      <td>0.103906</td>\n",
       "      <td>5.80</td>\n",
       "      <td>non_toxic</td>\n",
       "      <td>65.8</td>\n",
       "      <td>1</td>\n",
       "      <td>8,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9H-fluorene</td>\n",
       "      <td>86-73-7</td>\n",
       "      <td>c1ccc2c(c1)Cc1ccccc1-2</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>5.82</td>\n",
       "      <td>toxic</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,2,3,4-tetrahydronaphthalene</td>\n",
       "      <td>119-64-2</td>\n",
       "      <td>c1ccc2c(c1)CCCC2</td>\n",
       "      <td>0.020589</td>\n",
       "      <td>5.74</td>\n",
       "      <td>toxic</td>\n",
       "      <td>69.4</td>\n",
       "      <td>1</td>\n",
       "      <td>7,10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Compound Name       CAS                  SMILES  \\\n",
       "0     3,4-dihydro-1H-isochromene  493-05-0        c1ccc2c(c1)CCOC2   \n",
       "1                    9H-fluorene   86-73-7  c1ccc2c(c1)Cc1ccccc1-2   \n",
       "2  1,2,3,4-tetrahydronaphthalene  119-64-2        c1ccc2c(c1)CCCC2   \n",
       "\n",
       "   Solubility_mol_per_L   pKa   Toxicity  Melting Point  Reactivity  \\\n",
       "0              0.103906  5.80  non_toxic           65.8           1   \n",
       "1              0.010460  5.82      toxic           90.0           1   \n",
       "2              0.020589  5.74      toxic           69.4           1   \n",
       "\n",
       "  Oxidation Site  \n",
       "0           8,10  \n",
       "1              7  \n",
       "2           7,10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/C_H_oxidation_dataset.csv\"\n",
    "df_raw = pd.read_csv(url)\n",
    "print(df_raw.shape)\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3740b1e",
   "metadata": {},
   "source": [
    "**Descriptor functions**\n",
    "\n",
    "- `calc_descriptors10` returns 10 quick descriptors per SMILES.\n",
    "- `morgan_bits` returns a compact bitstring for Morgan fingerprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda48883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_descriptors10(smiles: str):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    if m is None:\n",
    "        return pd.Series({\n",
    "            \"MolWt\": np.nan, \"LogP\": np.nan, \"TPSA\": np.nan, \"NumRings\": np.nan,\n",
    "            \"NumHAcceptors\": np.nan, \"NumHDonors\": np.nan, \"NumRotatableBonds\": np.nan,\n",
    "            \"HeavyAtomCount\": np.nan, \"FractionCSP3\": np.nan, \"NumAromaticRings\": np.nan\n",
    "        })\n",
    "    return pd.Series({\n",
    "        \"MolWt\": Descriptors.MolWt(m),\n",
    "        \"LogP\": Crippen.MolLogP(m),\n",
    "        \"TPSA\": rdMolDescriptors.CalcTPSA(m),\n",
    "        \"NumRings\": rdMolDescriptors.CalcNumRings(m),\n",
    "        \"NumHAcceptors\": rdMolDescriptors.CalcNumHBA(m),\n",
    "        \"NumHDonors\": rdMolDescriptors.CalcNumHBD(m),\n",
    "        \"NumRotatableBonds\": rdMolDescriptors.CalcNumRotatableBonds(m),\n",
    "        \"HeavyAtomCount\": Descriptors.HeavyAtomCount(m),\n",
    "        \"FractionCSP3\": rdMolDescriptors.CalcFractionCSP3(m),\n",
    "        \"NumAromaticRings\": rdMolDescriptors.CalcNumAromaticRings(m)\n",
    "    })\n",
    "\n",
    "def morgan_bits(smiles: str, n_bits: int = 64, radius: int = 2):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    if m is None:\n",
    "        return np.nan\n",
    "    gen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
    "    fp = gen.GetFingerprint(m)\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return \"\".join(map(str, arr))\n",
    "\n",
    "desc_cols = [\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\",\n",
    "             \"NumHAcceptors\",\"NumHDonors\",\"NumRotatableBonds\",\n",
    "             \"HeavyAtomCount\",\"FractionCSP3\",\"NumAromaticRings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa91ef0",
   "metadata": {},
   "source": [
    "**Build descriptor tables used in Sections 7 and 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727da452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df10 shape: (575, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>LogP</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>NumRings</th>\n",
       "      <th>NumHAcceptors</th>\n",
       "      <th>NumHDonors</th>\n",
       "      <th>NumRotatableBonds</th>\n",
       "      <th>HeavyAtomCount</th>\n",
       "      <th>FractionCSP3</th>\n",
       "      <th>NumAromaticRings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3,4-dihydro-1H-isochromene</td>\n",
       "      <td>c1ccc2c(c1)CCOC2</td>\n",
       "      <td>non_toxic</td>\n",
       "      <td>134.178</td>\n",
       "      <td>1.7593</td>\n",
       "      <td>9.23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9H-fluorene</td>\n",
       "      <td>c1ccc2c(c1)Cc1ccccc1-2</td>\n",
       "      <td>toxic</td>\n",
       "      <td>166.223</td>\n",
       "      <td>3.2578</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,2,3,4-tetrahydronaphthalene</td>\n",
       "      <td>c1ccc2c(c1)CCCC2</td>\n",
       "      <td>toxic</td>\n",
       "      <td>132.206</td>\n",
       "      <td>2.5654</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Compound Name                  SMILES   Toxicity    MolWt  \\\n",
       "0     3,4-dihydro-1H-isochromene        c1ccc2c(c1)CCOC2  non_toxic  134.178   \n",
       "1                    9H-fluorene  c1ccc2c(c1)Cc1ccccc1-2      toxic  166.223   \n",
       "2  1,2,3,4-tetrahydronaphthalene        c1ccc2c(c1)CCCC2      toxic  132.206   \n",
       "\n",
       "     LogP  TPSA  NumRings  NumHAcceptors  NumHDonors  NumRotatableBonds  \\\n",
       "0  1.7593  9.23       2.0            1.0         0.0                0.0   \n",
       "1  3.2578  0.00       3.0            0.0         0.0                0.0   \n",
       "2  2.5654  0.00       2.0            0.0         0.0                0.0   \n",
       "\n",
       "   HeavyAtomCount  FractionCSP3  NumAromaticRings  \n",
       "0            10.0      0.333333               1.0  \n",
       "1            13.0      0.076923               2.0  \n",
       "2            10.0      0.400000               1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-descriptor table\n",
    "desc10 = df_raw[\"SMILES\"].apply(calc_descriptors10)\n",
    "df10 = pd.concat([df_raw[[\"Compound Name\",\"SMILES\",\"Toxicity\"]], desc10], axis=1).dropna(subset=desc_cols)\n",
    "print(\"df10 shape:\", df10.shape)\n",
    "df10.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa229f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. In-class activities\n",
    "\n",
    "We practice three light self-supervised ideas that fit experimental chemistry. Each activity is short and shows intermediate structures.\n",
    "\n",
    "### 7.1 Masked descriptor imputation (pretext task)\n",
    "\n",
    "**Idea**  \n",
    "Randomly hide one descriptor and predict it from the other 9. This is a pretext task that learns relationships inside $x$ without labels $y$.\n",
    "\n",
    "**Prepare the matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e781ae19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_desc_all = df10[desc_cols].copy()\n",
    "X = X_desc_all.to_numpy().astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436943b",
   "metadata": {},
   "source": [
    "**Loop over columns and score $R^2$ with LinearRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011195c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 1 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m X_trf = imp.transform(X_trm)\n\u001b[32m     15\u001b[39m X_tef = imp.transform(X_tem)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m X_tr_use = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m X_te_use = np.delete(X_tef, j, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     20\u001b[39m reg = LinearRegression().fit(X_tr_use, y_tr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:5437\u001b[39m, in \u001b[36mdelete\u001b[39m\u001b[34m(arr, obj, axis)\u001b[39m\n\u001b[32m   5434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m single_value:\n\u001b[32m   5435\u001b[39m     \u001b[38;5;66;03m# optimization for a single value\u001b[39;00m\n\u001b[32m   5436\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (obj < -N \u001b[38;5;129;01mor\u001b[39;00m obj >= N):\n\u001b[32m-> \u001b[39m\u001b[32m5437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m   5438\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is out of bounds for axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5439\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   5440\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (obj < \u001b[32m0\u001b[39m):\n\u001b[32m   5441\u001b[39m         obj += N\n",
      "\u001b[31mIndexError\u001b[39m: index 9 is out of bounds for axis 1 with size 9"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "col_scores = {}\n",
    "for j, col in enumerate(desc_cols):\n",
    "    X_tr, X_te = train_test_split(X, test_size=0.25, random_state=42)\n",
    "    y_tr, y_te = X_tr[:, j].copy(), X_te[:, j].copy()\n",
    "\n",
    "    X_trm = X_tr.copy(); X_trm[:, j] = np.nan\n",
    "    X_tem = X_te.copy(); X_tem[:, j] = np.nan\n",
    "\n",
    "    imp = SimpleImputer(strategy=\"mean\").fit(X_trm)\n",
    "    X_trf = imp.transform(X_trm)\n",
    "    X_tef = imp.transform(X_tem)\n",
    "\n",
    "    X_tr_use = np.delete(X_trf, j, axis=1)\n",
    "    X_te_use = np.delete(X_tef, j, axis=1)\n",
    "\n",
    "    reg = LinearRegression().fit(X_tr_use, y_tr)\n",
    "    y_hat = reg.predict(X_te_use)\n",
    "    col_scores[col] = r2_score(y_te, y_hat)\n",
    "\n",
    "pd.Series(col_scores).sort_values(ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750dffeb",
   "metadata": {},
   "source": [
    "We just learned which descriptors are most predictable from the rest. That signals redundancy in the feature space.\n",
    "\n",
    "**Visualize parity for the best column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58871e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_col = max(col_scores, key=col_scores.get)\n",
    "j = desc_cols.index(best_col)\n",
    "\n",
    "# repeat fit for plotting\n",
    "X_tr, X_te = train_test_split(X, test_size=0.25, random_state=42)\n",
    "y_tr, y_te = X_tr[:, j].copy(), X_te[:, j].copy()\n",
    "X_trm = X_tr.copy(); X_trm[:, j] = np.nan\n",
    "X_tem = X_te.copy(); X_tem[:, j] = np.nan\n",
    "\n",
    "imp = SimpleImputer(strategy=\"mean\").fit(X_trm)\n",
    "X_trf = imp.transform(X_trm); X_tef = imp.transform(X_tem)\n",
    "\n",
    "X_tr_use = np.delete(X_trf, j, axis=1)\n",
    "X_te_use = np.delete(X_tef, j, axis=1)\n",
    "\n",
    "reg = LinearRegression().fit(X_tr_use, y_tr)\n",
    "y_hat = reg.predict(X_te_use)\n",
    "\n",
    "print(f\"Best masked column: {best_col}\")\n",
    "print(f\"R2 on test: {r2_score(y_te, y_hat):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_te, y_hat, alpha=0.6)\n",
    "lims = [min(y_te.min(), y_hat.min()), max(y_te.max(), y_hat.max())]\n",
    "plt.plot(lims, lims, \"k--\")\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(f\"Masked imputation parity for {best_col}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed171a0",
   "metadata": {},
   "source": [
    "```{admonition} Tip\n",
    "If a descriptor has low $R^2$ here, it carries information that is less redundant with the rest. That can be useful when you decide which features to keep.\n",
    "```\n",
    "\n",
    "**⏰ Exercise 7.1**\n",
    "\n",
    "- Replace LinearRegression with `Ridge(alpha=1.0)` and repeat the loop. Compare per-column $R^2$.  \n",
    "- For one weaker column, plot residuals $r = y - \\hat y$ vs `MolWt` and comment on the pattern.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7.2 Character language model for SMILES\n",
    "\n",
    "Train an $n$-gram model that predicts the next character in SMILES. This mirrors next-token or masked-token pretraining at a tiny scale.\n",
    "\n",
    "**Collect SMILES and build a character set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ef4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df10[\"SMILES\"].dropna().astype(str).tolist()\n",
    "from collections import Counter\n",
    "all_text = \"\".join(smiles)\n",
    "chars = sorted(set(all_text))\n",
    "len(chars), chars[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aab6b5",
   "metadata": {},
   "source": [
    "**Count trigrams ($n=3$)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "n = 3\n",
    "counts = defaultdict(Counter)\n",
    "\n",
    "for s in smiles:\n",
    "    s2 = \"^\"*(n-1) + s + \"$\"\n",
    "    for i in range(len(s2)-(n-1)):\n",
    "        context = s2[i:i+(n-1)]\n",
    "        nxt = s2[i+(n-1)]\n",
    "        counts[context][nxt] += 1\n",
    "\n",
    "len(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43365d",
   "metadata": {},
   "source": [
    "**Turn counts into probabilities with add-$\\alpha$ smoothing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "vocab_plus = [\"^\",\"$\"] + chars\n",
    "\n",
    "def context_probs(context):\n",
    "    c = counts[context]\n",
    "    total = sum(c.values()) + alpha*len(vocab_plus)\n",
    "    return {ch: (c.get(ch,0) + alpha)/total for ch in vocab_plus}\n",
    "\n",
    "# peek baseline context\n",
    "context_probs(\"^\"*(n-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d179b53",
   "metadata": {},
   "source": [
    "**Sequence negative log likelihood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sequence_nll(s):\n",
    "    s2 = \"^\"*(n-1) + s + \"$\"\n",
    "    nll = 0.0\n",
    "    for i in range(len(s2)-(n-1)):\n",
    "        ctx = s2[i:i+(n-1)]\n",
    "        nxt = s2[i+(n-1)]\n",
    "        p = context_probs(ctx).get(nxt, 1e-12)\n",
    "        nll += -math.log(p + 1e-12)\n",
    "    return nll\n",
    "\n",
    "vals = pd.Series([sequence_nll(s) for s in smiles[:10]], index=smiles[:10])\n",
    "vals.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296668b",
   "metadata": {},
   "source": [
    "**Top-k next-token suggestions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6569d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_next(context, k=5):\n",
    "    pr = context_probs(context)\n",
    "    return sorted(pr.items(), key=lambda x: -x[1])[:k]\n",
    "\n",
    "topk_next(\"^C\", k=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e3f3f",
   "metadata": {},
   "source": [
    "**Sample a few SMILES candidates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_smiles(rng=None, max_len=120):\n",
    "    if rng is None:\n",
    "        rng = random.Random(0)\n",
    "    s = \"^\"*(n-1)\n",
    "    out = []\n",
    "    for _ in range(max_len):\n",
    "        pr = context_probs(s[-(n-1):])\n",
    "        items, probs = zip(*pr.items())\n",
    "        cum = np.cumsum(probs)\n",
    "        u = rng.random() * cum[-1]\n",
    "        j = int(np.searchsorted(cum, u))\n",
    "        token = items[j]\n",
    "        if token == \"$\":\n",
    "            break\n",
    "        if token not in [\"^\"]:\n",
    "            out.append(token)\n",
    "        s += token\n",
    "    return \"\".join(out)\n",
    "\n",
    "[sample_smiles(random.Random(i)) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1dea2f",
   "metadata": {},
   "source": [
    "```{admonition} Note\n",
    "Many sampled strings will not be valid molecules. The goal is to see how a self-supervised signal teaches token statistics without property labels.\n",
    "```\n",
    "\n",
    "**⏰ Exercise 7.2**\n",
    "\n",
    "- Rebuild the model with $n=4$ and compare mean sequence NLL on a set of 100 molecules.  \n",
    "- Create a masked character task: pick one position (not the first), hide it, and check if the true char appears in the model’s top-5 guesses. Report hit@5.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7.3 Linear autoencoder via PCA on descriptors\n",
    "\n",
    "Treat PCA as an encoder-decoder. Choose $k$ by explained variance and study reconstruction error per column and per molecule.\n",
    "\n",
    "**Standardize and fit PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_desc_all)\n",
    "Xz = scaler.transform(X_desc_all)\n",
    "\n",
    "pca = PCA().fit(Xz)\n",
    "evr = np.cumsum(pca.explained_variance_ratio_)\n",
    "pd.Series(evr[:10]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04bd52",
   "metadata": {},
   "source": [
    "**Pick $k$ where cumulative EVR $\\ge 0.95$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(np.argmax(evr >= 0.95) + 1)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed640107",
   "metadata": {},
   "source": [
    "**Encode and decode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pca.transform(Xz)[:, :k]\n",
    "Xz_hat = Z @ pca.components_[:k, :]\n",
    "X_hat = scaler.inverse_transform(Xz_hat)\n",
    "\n",
    "recon = pd.DataFrame(X_hat, columns=desc_cols, index=X_desc_all.index)\n",
    "recon.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461f8ab",
   "metadata": {},
   "source": [
    "**RMSE per descriptor and per molecule**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_rmse = {c: mean_squared_error(X_desc_all[c], recon[c], squared=False) for c in desc_cols}\n",
    "pd.Series(col_rmse).sort_values().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabde7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_mol_err = np.sqrt(((X_desc_all.values - recon.values)**2).mean(axis=1))\n",
    "per_mol_err.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19183229",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(per_mol_err, bins=30, alpha=0.7)\n",
    "plt.xlabel(\"Per-molecule RMSE (10 desc)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(f\"PCA autoencoder error, k={k}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e3e6d",
   "metadata": {},
   "source": [
    "**⏰ Exercise 7.3**\n",
    "\n",
    "- Fix $k=3$ and recompute RMSE per descriptor. Which columns are hardest to reconstruct  \n",
    "- Plot per-molecule error vs `MolWt` and comment on any trend.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7.4 Contrast of two descriptor views with cosine\n",
    "\n",
    "Make two simple views of the same molecule: standardized descriptors and a noisy copy. Check that each molecule matches its own view by cosine similarity.\n",
    "\n",
    "**Build two views**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54819786",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "Xz = scaler.transform(X_desc_all.values)\n",
    "Xz_noisy = Xz + rng.normal(0, 0.05, size=Xz.shape)\n",
    "\n",
    "Xz[:2], Xz_noisy[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b620a89",
   "metadata": {},
   "source": [
    "**Cosine similarity and top-1 hit rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7aa3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = cosine_similarity(Xz, Xz_noisy)\n",
    "row_argmax = S.argmax(axis=1)\n",
    "top1 = np.mean(row_argmax == np.arange(S.shape[0]))\n",
    "print(f\"Top-1 match rate for own noisy view: {top1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111a86e",
   "metadata": {},
   "source": [
    "**⏰ Exercise 7.4**\n",
    "\n",
    "- Increase the noise std to `0.2` and compute the new top-1 rate.  \n",
    "- Replace cosine with similarity $1/(1+d)$ where $d$ is Euclidean distance and compare.\n",
    "\n",
    "```python\n",
    "# TO DO\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7.5 Optional: map the encoder codes\n",
    "\n",
    "Plot the first two principal components as a quick 2D map of the encoder codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = Z[:, :2]\n",
    "plt.scatter(Z2[:,0], Z2[:,1], s=12, alpha=0.7)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Encoder codes (first 2 PCs)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e13f9f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Solutions\n",
    "\n",
    "Short reference solutions that match the activities above.\n",
    "\n",
    "### Solution 7.1 Ridge and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores = {}\n",
    "for j, col in enumerate(desc_cols):\n",
    "    X_tr, X_te = train_test_split(X, test_size=0.25, random_state=42)\n",
    "    y_tr, y_te = X_tr[:, j].copy(), X_te[:, j].copy()\n",
    "    X_trm, X_tem = X_tr.copy(), X_te.copy()\n",
    "    X_trm[:, j] = np.nan; X_tem[:, j] = np.nan\n",
    "\n",
    "    imp = SimpleImputer(strategy=\"mean\").fit(X_trm)\n",
    "    X_trf = imp.transform(X_trm); X_tef = imp.transform(X_tem)\n",
    "\n",
    "    X_tr_use = np.delete(X_trf, j, axis=1)\n",
    "    X_te_use = np.delete(X_tef, j, axis=1)\n",
    "\n",
    "    rr = Ridge(alpha=1.0).fit(X_tr_use, y_tr)\n",
    "    ridge_scores[col] = r2_score(y_te, rr.predict(X_te_use))\n",
    "\n",
    "pd.DataFrame({\"Linear\": pd.Series(col_scores), \"Ridge\": pd.Series(ridge_scores)}).round(3).sort_values(\"Linear\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals vs MolWt for a weaker column\n",
    "weak_col = min(col_scores, key=col_scores.get)\n",
    "j = desc_cols.index(weak_col)\n",
    "\n",
    "X_tr, X_te = train_test_split(X, test_size=0.25, random_state=42)\n",
    "y_tr, y_te = X_tr[:, j].copy(), X_te[:, j].copy()\n",
    "X_trm, X_tem = X_tr.copy(), X_te.copy()\n",
    "X_trm[:, j] = np.nan; X_tem[:, j] = np.nan\n",
    "\n",
    "imp = SimpleImputer(strategy=\"mean\").fit(X_trm)\n",
    "X_trf = imp.transform(X_trm); X_tef = imp.transform(X_tem)\n",
    "X_tr_use = np.delete(X_trf, j, axis=1); X_te_use = np.delete(X_tef, j, axis=1)\n",
    "\n",
    "reg = LinearRegression().fit(X_tr_use, y_tr)\n",
    "y_hat = reg.predict(X_te_use)\n",
    "res = y_te - y_hat\n",
    "molwt_te = X_te[:, desc_cols.index(\"MolWt\")]\n",
    "\n",
    "plt.scatter(molwt_te, res, alpha=0.6)\n",
    "plt.axhline(0, color=\"k\", linestyle=\"--\")\n",
    "plt.xlabel(\"MolWt\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(f\"Residuals vs MolWt for {weak_col}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83037ff0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Solution 7.2 $n=4$ and masked hit@5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild counts with n=4\n",
    "n = 4\n",
    "counts = defaultdict(Counter)\n",
    "for s in smiles:\n",
    "    s2 = \"^\"*(n-1) + s + \"$\"\n",
    "    for i in range(len(s2)-(n-1)):\n",
    "        ctx = s2[i:i+(n-1)]; nxt = s2[i+(n-1)]\n",
    "        counts[ctx][nxt] += 1\n",
    "\n",
    "alpha = 0.5\n",
    "vocab_plus = [\"^\",\"$\"] + chars\n",
    "\n",
    "def context_probs(context):\n",
    "    c = counts[context]\n",
    "    total = sum(c.values()) + alpha*len(vocab_plus)\n",
    "    return {ch: (c.get(ch,0) + alpha)/total for ch in vocab_plus}\n",
    "\n",
    "def sequence_nll(s):\n",
    "    s2 = \"^\"*(n-1) + s + \"$\"\n",
    "    nll = 0.0\n",
    "    for i in range(len(s2)-(n-1)):\n",
    "        ctx = s2[i:i+(n-1)]; nxt = s2[i+(n-1)]\n",
    "        p = context_probs(ctx).get(nxt, 1e-12)\n",
    "        nll += -np.log(p + 1e-12)\n",
    "    return nll\n",
    "\n",
    "subset = smiles[:100]\n",
    "mean_nll_n4 = float(np.mean([sequence_nll(s) for s in subset]))\n",
    "mean_nll_n4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_next(context, k=5):\n",
    "    pr = context_probs(context)\n",
    "    return [ch for ch,_ in sorted(pr.items(), key=lambda x: -x[1])[:k]]\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "def masked_hit_at_5(s):\n",
    "    if len(s) < n: \n",
    "        return None\n",
    "    pos = rng.randint(n-1, len(s))  # choose a position with context available\n",
    "    ctx = (\"^\"*(n-1) + s)[pos-(n-1):pos]\n",
    "    true_char = s[pos] if pos < len(s) else \"$\"\n",
    "    preds = topk_next(ctx, k=5)\n",
    "    return 1 if true_char in preds else 0\n",
    "\n",
    "hits = [h for s in subset if (h := masked_hit_at_5(s)) is not None]\n",
    "hit_at_5 = float(np.mean(hits))\n",
    "hit_at_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89738b1d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Solution 7.3 $k=3$ and error vs MolWt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "Z3 = pca.transform(Xz)[:, :k]\n",
    "Xz_hat3 = Z3 @ pca.components_[:k, :]\n",
    "X_hat3 = scaler.inverse_transform(Xz_hat3)\n",
    "recon3 = pd.DataFrame(X_hat3, columns=desc_cols, index=X_desc_all.index)\n",
    "\n",
    "rmse3 = {c: mean_squared_error(X_desc_all[c], recon3[c], squared=False) for c in desc_cols}\n",
    "pd.Series(rmse3).sort_values().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_mol_err3 = np.sqrt(((X_desc_all.values - recon3.values)**2).mean(axis=1))\n",
    "molwt = X_desc_all[\"MolWt\"].values\n",
    "plt.scatter(molwt, per_mol_err3, alpha=0.6)\n",
    "plt.xlabel(\"MolWt\")\n",
    "plt.ylabel(\"Per-molecule RMSE (k=3)\")\n",
    "plt.title(\"Reconstruction error vs MolWt\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e2b02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Solution 7.4 Noise sweep and alt similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb974482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def top1_rate_cosine(std_noise):\n",
    "    rng = np.random.RandomState(0)\n",
    "    Xz_noisy = Xz + rng.normal(0, std_noise, size=Xz.shape)\n",
    "    S = cosine_similarity(Xz, Xz_noisy)\n",
    "    return float(np.mean(S.argmax(axis=1) == np.arange(S.shape[0])))\n",
    "\n",
    "rates = {s: top1_rate_cosine(s) for s in [0.05, 0.1, 0.2, 0.3]}\n",
    "pd.Series(rates).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top1_rate_euclid_like(std_noise):\n",
    "    rng = np.random.RandomState(0)\n",
    "    Xz_noisy = Xz + rng.normal(0, std_noise, size=Xz.shape)\n",
    "    D = euclidean_distances(Xz, Xz_noisy)\n",
    "    S = 1.0/(1.0 + D)\n",
    "    return float(np.mean(S.argmax(axis=1) == np.arange(S.shape[0])))\n",
    "\n",
    "rates_e = {s: top1_rate_euclid_like(s) for s in [0.05, 0.1, 0.2, 0.3]}\n",
    "pd.Series(rates_e).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc6f32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Solution 7.5 Code map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = pca.transform(Xz)[:, :2]\n",
    "plt.scatter(Z2[:,0], Z2[:,1], s=12, alpha=0.7)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Encoder codes (first 2 PCs)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "source_map": [
   12,
   20,
   52,
   56,
   61,
   68,
   103,
   107,
   113,
   128,
   132,
   136,
   161,
   167,
   190,
   198,
   221,
   227,
   231,
   245,
   249,
   260,
   264,
   279,
   283,
   289,
   293,
   315,
   338,
   345,
   349,
   352,
   356,
   363,
   367,
   372,
   377,
   383,
   402,
   408,
   412,
   417,
   434,
   441,
   451,
   471,
   496,
   502,
   534,
   552,
   558,
   569,
   577,
   583,
   596,
   606,
   612
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}