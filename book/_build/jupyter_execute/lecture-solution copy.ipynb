{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7bae76",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## lecture 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0052b66c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorDataset, DataLoader\n\u001b[0;32m      3\u001b[0m dl_desc \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m----> 4\u001b[0m     TensorDataset(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_numpy(Xz\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))),\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m      6\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 3D latent AE and training loop (unpack with (xb,))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m ae3 \u001b[38;5;241m=\u001b[39m TinyAE(in_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, hid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, z_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dl_desc = DataLoader(\n",
    "    TensorDataset(torch.from_numpy(Xz.astype(np.float32))),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# 3D latent AE and training loop (unpack with (xb,))\n",
    "ae3 = TinyAE(in_dim=10, hid=64, z_dim=3)\n",
    "opt = optim.Adam(ae3.parameters(), lr=1e-3)\n",
    "\n",
    "for ep in range(4):\n",
    "    for (xb,) in dl_desc:\n",
    "        xr, z = ae3(xb)\n",
    "        loss = nn.functional.mse_loss(xr, xb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "# Encode with the trained model\n",
    "with torch.no_grad():\n",
    "    Z3 = ae3.encode(torch.from_numpy(Xz.astype(np.float32))).numpy()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "p = ax.scatter(\n",
    "    Z3[:, 0], Z3[:, 1], Z3[:, 2],\n",
    "    c=df_small[\"LogP\"].values,\n",
    "    s=12, alpha=0.85\n",
    ")\n",
    "ax.set_xlabel(\"z0\"); ax.set_ylabel(\"z1\"); ax.set_zlabel(\"z2\")\n",
    "ax.set_title(\"AE latent space (3D), color = LogP\")\n",
    "cb = fig.colorbar(p, ax=ax, shrink=0.7, pad=0.1)\n",
    "cb.set_label(\"LogP\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e2370",
   "metadata": {},
   "source": [
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab662dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [0.01, 0.1, 0.3, 0.5, 1.0, 1.5, 2]:\n",
    "    raw = sample_smiles(n=800, temp=t)\n",
    "    val = len(canonicalize_batch(raw)) / max(1, len(raw))\n",
    "    print(f\"T={t}: validity {val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db1edf",
   "metadata": {},
   "source": [
    "#Lecture 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec49c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared pieces\n",
    "U_cand = candidate_cloud(m=6000, seed=1)\n",
    "\n",
    "def rf_mean_std(rf, Xc):\n",
    "    preds = np.stack([est.predict(Xc) for est in rf.estimators_], axis=1)\n",
    "    mu = preds.mean(axis=1)\n",
    "    sd = preds.std(axis=1)\n",
    "    return mu, sd\n",
    "\n",
    "def run_rf_bo_ei_estimators(n_estimators=100, n_iter=20, seed=42, noise_sd=1.8):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    # same initial 8 runs for fairness\n",
    "    U0 = rng.rand(8, 3)\n",
    "    lab0 = np.array([decode_3d(u) for u in U0])\n",
    "    y0 = suzuki_yield(lab0[:,0], lab0[:,1], lab0[:,2], rng=rng)\n",
    "\n",
    "    U = U0.copy()\n",
    "    y = y0.copy()\n",
    "    best_hist = [y.max()]\n",
    "    rf_snap = None\n",
    "\n",
    "    for t in range(n_iter):\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=None,\n",
    "            min_samples_leaf=1,\n",
    "            bootstrap=True,\n",
    "            random_state=seed + t,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        rf.fit(U, y)\n",
    "        mu_rf, sd_rf = rf_mean_std(rf, U_cand)\n",
    "        ei = acq_ei(mu_rf, sd_rf, y_best=y.max(), xi=0.01)\n",
    "        u_next, _ = argmax_on_grid(ei, U_cand)\n",
    "        lab_next = decode_3d(u_next.ravel())\n",
    "        y_next = suzuki_yield(lab_next[0], lab_next[1], lab_next[2], rng=rng)\n",
    "        U = np.vstack([U, u_next])\n",
    "        y = np.hstack([y, y_next])\n",
    "        best_hist.append(y.max())\n",
    "        if t == n_iter - 1:\n",
    "            rf_snap = (U.copy(), y.copy(), mu_rf.copy(), sd_rf.copy())\n",
    "    return np.array(best_hist), rf_snap\n",
    "\n",
    "def run_gp_bo_ei(n_iter=20, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    U0 = rng.rand(8, 3)\n",
    "    lab0 = np.array([decode_3d(u) for u in U0])\n",
    "    y0 = suzuki_yield(lab0[:,0], lab0[:,1], lab0[:,2], rng=rng)\n",
    "\n",
    "    U = U0.copy()\n",
    "    y = y0.copy()\n",
    "    best_hist = [y.max()]\n",
    "\n",
    "    kernel3 = C(50.0) * Matern(length_scale=[0.2,0.2,0.2], nu=2.5) + WhiteKernel(1.0)\n",
    "    gp3 = GaussianProcessRegressor(kernel=kernel3, normalize_y=True, n_restarts_optimizer=3, random_state=seed)\n",
    "    gp_snap = None\n",
    "\n",
    "    for t in range(n_iter):\n",
    "        gp3.fit(U, y)\n",
    "        mu, sd = gp3.predict(U_cand, return_std=True)\n",
    "        ei = acq_ei(mu, sd, y_best=y.max(), xi=0.01)\n",
    "        u_next, _ = argmax_on_grid(ei, U_cand)\n",
    "        lab_next = decode_3d(u_next.ravel())\n",
    "        y_next = suzuki_yield(lab_next[0], lab_next[1], lab_next[2], rng=rng)\n",
    "        U = np.vstack([U, u_next])\n",
    "        y = np.hstack([y, y_next])\n",
    "        best_hist.append(y.max())\n",
    "        if t == n_iter - 1:\n",
    "            gp_snap = (U.copy(), y.copy(), mu.copy(), sd.copy())\n",
    "    return np.array(best_hist), gp_snap\n",
    "\n",
    "# 1) RF 100\n",
    "hist_rf100, snap_rf100 = run_rf_bo_ei_estimators(n_estimators=100,  n_iter=20, seed=10)\n",
    "# 2) RF 1000\n",
    "hist_rf1000, snap_rf1000 = run_rf_bo_ei_estimators(n_estimators=1000, n_iter=20, seed=10)\n",
    "# 3) GP\n",
    "hist_gp, snap_gp = run_gp_bo_ei(n_iter=20, seed=10)\n",
    "\n",
    "# 4) Compare best-so-far\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(hist_rf100,  marker=\"o\", label=\"RF+EI 100 trees\")\n",
    "plt.plot(hist_rf1000, marker=\"s\", label=\"RF+EI 1000 trees\")\n",
    "plt.plot(hist_gp,     marker=\"^\", label=\"GP+EI\")\n",
    "plt.xlabel(\"Iteration\"); plt.ylabel(\"Best observed yield\")\n",
    "plt.title(\"Suzuki BO: RF size vs GP\")\n",
    "plt.legend(); plt.grid(False); plt.show()\n",
    "\n",
    "# 5) FYI: bands for RF-100 vs RF-1000 on U_cand\n",
    "for tag, snap in [(\"RF 100\", snap_rf100), (\"RF 1000\", snap_rf1000)]:\n",
    "    U_obs, y_obs, mu_final, sd_final = snap\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.hist(sd_final, bins=40)\n",
    "    plt.title(f\"{tag}: distribution of RF posterior sd on candidate cloud\")\n",
    "    plt.xlabel(\"sd across trees\"); plt.ylabel(\"count\"); plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "source_map": [
   12,
   23,
   62,
   67,
   73,
   77
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}