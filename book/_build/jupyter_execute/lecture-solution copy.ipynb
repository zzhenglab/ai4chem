{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1329a988",
   "metadata": {},
   "source": [
    "## 11. Solutions\n",
    "\n",
    "### Solution Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc5162d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_reg \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMolWt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTPSA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumRings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMelting Point\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m df_reg[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMolWt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTPSA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumRings\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m df_reg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMelting Point\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_reg = df[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\",\"Melting Point\"]].dropna()\n",
    "X = df_reg[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]].values\n",
    "y = df_reg[\"Melting Point\"].values\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlp\", MLPRegressor(hidden_layer_sizes=(32,), activation=\"relu\",\n",
    "                         alpha=1e-3, learning_rate_init=0.01,\n",
    "                         max_iter=1500, random_state=0))\n",
    "]).fit(Xtr, ytr)\n",
    "\n",
    "yhat = pipe.predict(Xte)\n",
    "print(f\"MSE={mean_squared_error(yte,yhat):.2f}  MAE={mean_absolute_error(yte,yhat):.2f}  R2={r2_score(yte,yhat):.3f}\")\n",
    "\n",
    "plt.figure(figsize=(4.5,4))\n",
    "plt.scatter(yte, yhat, alpha=0.65)\n",
    "lims = [min(yte.min(), yhat.min()), max(yte.max(), yhat.max())]\n",
    "plt.plot(lims, lims, \"k--\")\n",
    "plt.xlabel(\"True MP\"); plt.ylabel(\"Pred MP\"); plt.title(\"Q1 parity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c02710",
   "metadata": {},
   "source": [
    "### Solution Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [(16,), (32,), (64,32)]\n",
    "df_sol = df[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\",\"Solubility_mol_per_L\"]].dropna().copy()\n",
    "df_sol[\"logS\"] = np.log10(df_sol[\"Solubility_mol_per_L\"]+1e-6)\n",
    "X = df_sol[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]].values\n",
    "y = df_sol[\"logS\"].values\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "r2s, curves = [], []\n",
    "for sz in sizes:\n",
    "    reg = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"mlp\", MLPRegressor(hidden_layer_sizes=sz, activation=\"relu\",\n",
    "                             alpha=1e-3, learning_rate_init=0.01,\n",
    "                             early_stopping=True, validation_fraction=0.15,\n",
    "                             max_iter=3000, random_state=0))\n",
    "    ]).fit(Xtr, ytr)\n",
    "    yhat = reg.predict(Xte)\n",
    "    r2s.append(r2_score(yte, yhat))\n",
    "    curves.append(reg.named_steps[\"mlp\"].loss_curve_)\n",
    "\n",
    "print(pd.DataFrame({\"hidden_sizes\":[str(s) for s in sizes],\"R2\":np.round(r2s,3)}))\n",
    "\n",
    "plt.figure(figsize=(5.5,3.5))\n",
    "for sz, c in zip(sizes, curves):\n",
    "    plt.plot(c, label=str(sz))\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Q2 loss curves\")\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b7140a",
   "metadata": {},
   "source": [
    "### Solution Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = df[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\",\"Toxicity\"]].dropna()\n",
    "y = df_clf[\"Toxicity\"].str.lower().map({\"toxic\":1,\"non_toxic\":0}).astype(int).values\n",
    "X = df_clf[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]].values\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlp\", MLPClassifier(hidden_layer_sizes=(32,), activation=\"relu\",\n",
    "                          alpha=1e-3, learning_rate_init=0.01,\n",
    "                          early_stopping=True, validation_fraction=0.15,\n",
    "                          max_iter=3000, random_state=0))\n",
    "]).fit(Xtr, ytr)\n",
    "\n",
    "proba = clf.predict_proba(Xte)[:,1]\n",
    "for t in [0.3, 0.5, 0.7]:\n",
    "    pred = (proba >= t).astype(int)\n",
    "    print(f\"t={t:.1f}  acc={accuracy_score(yte,pred):.3f}  prec={precision_score(yte,pred):.3f}  rec={recall_score(yte,pred):.3f}  f1={f1_score(yte,pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96bb174",
   "metadata": {},
   "source": [
    "### Solution Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91addf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol = df[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\",\"Solubility_mol_per_L\"]].dropna().copy()\n",
    "df_sol[\"logS\"] = np.log10(df_sol[\"Solubility_mol_per_L\"]+1e-6)\n",
    "X = df_sol[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]].values\n",
    "y = df_sol[\"logS\"].values\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "sc = StandardScaler().fit(Xtr)\n",
    "Xtr_s, Xte_s = sc.transform(Xtr), sc.transform(Xte)\n",
    "\n",
    "lr = LinearRegression().fit(Xtr_s, ytr)\n",
    "yhat_lr = lr.predict(Xte_s)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(32,), activation=\"relu\",\n",
    "                   alpha=1e-3, learning_rate_init=0.01,\n",
    "                   max_iter=3000, random_state=0).fit(Xtr_s, ytr)\n",
    "yhat_mlp = mlp.predict(Xte_s)\n",
    "\n",
    "print(f\"Linear R2: {r2_score(yte, yhat_lr):.3f}\")\n",
    "print(f\"MLP    R2: {r2_score(yte, yhat_mlp):.3f}\")\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "plt.scatter(yte, yhat_lr, alpha=0.6, label=\"Linear\")\n",
    "plt.scatter(yte, yhat_mlp, alpha=0.6, label=\"MLP\")\n",
    "lims = [min(yte.min(), yhat_lr.min(), yhat_mlp.min()), max(yte.max(), yhat_lr.max(), yhat_mlp.max())]\n",
    "plt.plot(lims, lims, \"k--\")\n",
    "plt.xlabel(\"True logS\"); plt.ylabel(\"Predicted\")\n",
    "plt.legend(); plt.title(\"Q4 parity: Linear vs MLP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47011ea",
   "metadata": {},
   "source": [
    "### Solution Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Q5 (full run + metrics + plots)\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Data\n",
    "df_mp = df[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\",\"Melting Point\"]].dropna().copy()\n",
    "\n",
    "X = df_mp[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]].values.astype(np.float32)\n",
    "y = df_mp[\"Melting Point\"].values.astype(np.float32).reshape(-1,1)\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "scaler = StandardScaler().fit(Xtr)\n",
    "Xtr_s = scaler.transform(Xtr).astype(np.float32)\n",
    "Xte_s = scaler.transform(Xte).astype(np.float32)\n",
    "\n",
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(NumpyDataset(Xtr_s, ytr), batch_size=64, shuffle=True)\n",
    "\n",
    "in_dim = Xtr_s.shape[1]\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_dim, 32), nn.ReLU(),\n",
    "    nn.Linear(32, 16),     nn.ReLU(),\n",
    "    nn.Linear(16, 1)\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "train_losses = []\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    batch_losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        batch_losses.append(loss.item())\n",
    "    train_losses.append(np.mean(batch_losses))\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = model(torch.from_numpy(Xte_s)).numpy()\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(yte, yhat):.3f}\")\n",
    "print(f\"MAE: {mean_absolute_error(yte, yhat):.3f}\")\n",
    "print(f\"R2:  {r2_score(yte, yhat):.3f}\")\n",
    "\n",
    "# Learning curve\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"train MSE\"); plt.title(\"Training loss (melting point)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Parity plot\n",
    "plt.figure(figsize=(4.6,4))\n",
    "plt.scatter(yte, yhat, alpha=0.65)\n",
    "lims = [min(yte.min(), yhat.min()), max(yte.max(), yhat.max())]\n",
    "plt.plot(lims, lims, \"k--\")\n",
    "plt.xlabel(\"True MP\"); plt.ylabel(\"Pred MP\"); plt.title(\"Parity plot (PyTorch MP)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "source_map": [
   12,
   19,
   41,
   45,
   73,
   77,
   95,
   99,
   128,
   132
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}