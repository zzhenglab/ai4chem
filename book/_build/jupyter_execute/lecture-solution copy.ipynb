{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73216791",
   "metadata": {},
   "source": [
    "## 10. In-class activity\n",
    "\n",
    "\n",
    "### 10.1 Linear Regression with two features\n",
    "\n",
    "Use only `MolWt` and `TPSA` to predict **Melting Point** with Linear Regression. Use a 90/10 split and report **MSE**, **MAE**, and **R²**.\n",
    "\n",
    "```python\n",
    "\n",
    "# Q1 starter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "X = df_reg_mp[[\"MolWt\", \"TPSA\"]]\n",
    "y = df_reg_mp[\"Melting Point\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=0\n",
    ")\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "print(f\"R2:  {r2_score(y_test, y_pred):.3f}\")\n",
    "```\n",
    "\n",
    "### 10.2 Ridge across splits\n",
    "\n",
    "Train a Ridge model (`alpha=1.0`) for **Melting Point** using `MolWt, LogP, TPSA, NumRings`. Compare test **R²** for train sizes 60, 70, 80, 90 percent with `random_state=42`. Plot **R²** vs train percent.\n",
    "\n",
    "```python\n",
    "X = df_reg_mp[[\"MolWt\", \"LogP\", \"TPSA\", \"NumRings\"]].values\n",
    "y = df_reg_mp[\"Melting Point\"].values\n",
    "\n",
    "splits = [0.4, 0.3, 0.2, 0.1]  # corresponds to 60/40, 70/30, 80/20, 90/10\n",
    "r2_scores = []\n",
    "\n",
    "for t in splits:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=t, random_state=42\n",
    "    )\n",
    "    model = Ridge(alpha=1.0).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot([60,70,80,90], r2_scores, \"o-\", lw=2)\n",
    "plt.xlabel(\"Train %\")\n",
    "plt.ylabel(\"R² (test)\")\n",
    "plt.title(\"Effect of train/test split on Ridge Regression accuracy\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 10.3 pKa regression two ways\n",
    "\n",
    "Build Ridge regression for **pKa** and for **exp(pKa)** using the same four descriptors. Report **R²** and **MSE** for each.\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Keep rows with a valid pKa\n",
    "df_pka = df[[\"MolWt\", \"LogP\", \"TPSA\", \"NumRings\", \"pKa\"]].dropna()\n",
    "\n",
    "X = df_pka[[\"MolWt\", \"LogP\", \"TPSA\", \"NumRings\"]].values\n",
    "y = df_pka[\"pKa\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "model = Ridge(alpha=1.0).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Test R2:  {r2_score(y_test, y_pred):.3f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "# Parity plot\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
    "plt.plot(lims, lims, \"k--\")\n",
    "plt.xlabel(\"True pKa\")\n",
    "plt.ylabel(\"Predicted pKa\")\n",
    "plt.title(\"Parity plot for pKa regression (Ridge)\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 10.4 pKa to classification\n",
    "\n",
    "Turn **pKa** into a binary label and train Logistic Regression with the same descriptors. Report Accuracy, Precision, Recall, F1, and AUC, and draw the ROC. You may pick either rule.\n",
    "\n",
    "- Option A: acidic if pKa ≤ 7  \n",
    "- Option B: median split on pKa\n",
    "\n",
    "```python\n",
    "\n",
    "# Clean pKa subset\n",
    "df_pka = df[[\"MolWt\", \"LogP\", \"TPSA\", \"NumRings\", \"pKa\"]].dropna()\n",
    "X = df_pka[[\"MolWt\", \"LogP\", \"TPSA\", \"NumRings\"]].values\n",
    "pka_vals = df_pka[\"pKa\"].values\n",
    "\n",
    "# ---- Helper to run classification and plot ----\n",
    "def run_classification(y_cls, rule_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_cls, test_size=0.20, random_state=42, stratify=y_cls\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc  = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    print(f\"--- {rule_name} ---\")\n",
    "    print(f\"Accuracy:  {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall:    {rec:.3f}\")\n",
    "    print(f\"F1:        {f1:.3f}\")\n",
    "    print(f\"AUC:       {auc:.3f}\")\n",
    "    print()\n",
    "\n",
    "    # ROC plot\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_proba)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUC = {auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1], \"k--\", lw=1)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for pKa classification ({rule_name})\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# ---- Rule A: acidic if pKa ≤ 7 ----\n",
    "y_cls_A = (pka_vals <= 7.0).astype(int)\n",
    "run_classification(y_cls_A, \"Rule A (pKa ≤ 7 = acidic)\")\n",
    "\n",
    "# ---- Rule B: median split ----\n",
    "median_val = np.median(pka_vals)\n",
    "y_cls_B = (pka_vals <= median_val).astype(int)\n",
    "run_classification(y_cls_B, f\"Rule B (≤ median pKa = acidic, median={median_val:.2f})\")\n",
    "```\n",
    "\n",
    "### 10.5 Threshold tuning on toxicity\n",
    "\n",
    "Using the toxicity classifier from Section 5, scan thresholds `0.2` to `0.8` in steps of `0.05`. Find the smallest threshold with **recall ≥ 0.80** and report the corresponding **precision** and **F1**. Plot the metric curves vs threshold.\n",
    "\n",
    "```python\n",
    "# Starter\n",
    "ths = np.arange(0.20, 0.81, 0.05)\n",
    "rec_list, prec_list, f1_list = [], [], []\n",
    "best_t = None\n",
    "\n",
    "for t in ths:\n",
    "    pred_t = (y_proba >= t).astype(int)\n",
    "    r = recall_score(y_test, pred_t)\n",
    "    p = precision_score(y_test, pred_t, zero_division=0)\n",
    "    f = f1_score(y_test, pred_t, zero_division=0)\n",
    "    rec_list.append(r); prec_list.append(p); f1_list.append(f)\n",
    "    if best_t is None and r >= 0.80:\n",
    "        best_t = t\n",
    "\n",
    "print(\"First threshold with recall >= 0.80:\", best_t)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(ths, rec_list, marker=\"o\", label=\"Recall\")\n",
    "plt.plot(ths, prec_list, marker=\"o\", label=\"Precision\")\n",
    "plt.plot(ths, f1_list, marker=\"o\", label=\"F1\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Threshold tuning on toxicity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 11. Solutions\n",
    "\n",
    "### 11.1 Solution Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e46f6e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_reg_mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Log target\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_reg_mp = \u001b[43mdf_reg_mp\u001b[49m.copy()\n\u001b[32m      3\u001b[39m y_log = np.log10(df_reg_mp[\u001b[33m\"\u001b[39m\u001b[33mSolubility_mol_per_L\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1e-6\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Features and split\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_reg_mp' is not defined"
     ]
    }
   ],
   "source": [
    "# Log target\n",
    "df_reg_mp = df_reg_mp.copy()\n",
    "y_log = np.log10(df_reg_mp[\"Solubility_mol_per_L\"] + 1e-6)\n",
    "\n",
    "# Features and split\n",
    "X = df_reg_mp[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]].values\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y_log, test_size=0.2, random_state=15)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.hist(y_log, bins=30, alpha=0.85)\n",
    "plt.xlabel(\"log10(Solubility + 1e-6)\"); plt.ylabel(\"Count\"); plt.title(\"Log-solubility\")\n",
    "plt.show()\n",
    "\n",
    "pd.plotting.scatter_matrix(df_reg_mp[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]], figsize=(5.5,5.5))\n",
    "plt.suptitle(\"Descriptor scatter matrix\", y=1.02); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b4c87",
   "metadata": {},
   "source": [
    "### 11.2 Solution Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "alphas = np.logspace(-2, 3, 12)\n",
    "means = [cross_val_score(Ridge(alpha=a), X_tr, y_tr, cv=cv, scoring=\"r2\").mean() for a in alphas]\n",
    "best_a = float(alphas[int(np.argmax(means))])\n",
    "ridge_best = Ridge(alpha=best_a).fit(X_tr, y_tr)\n",
    "print(f\"best alpha={best_a:.4f}  CV mean R2={max(means):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b78412",
   "metadata": {},
   "source": [
    "### 11.3 Solution Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = ridge_best.predict(X_te)\n",
    "print(f\"Test MSE={mean_squared_error(y_te,y_hat):.4f}  \"\n",
    "      f\"MAE={mean_absolute_error(y_te,y_hat):.4f}  \"\n",
    "      f\"R2={r2_score(y_te,y_hat):.3f}\")\n",
    "\n",
    "plt.figure(figsize=(4.2,4))\n",
    "plt.scatter(y_te, y_hat, alpha=0.7)\n",
    "lims = [min(y_te.min(), y_hat.min()), max(y_te.max(), y_hat.max())]\n",
    "plt.plot(lims, lims, \"k--\", lw=1)\n",
    "plt.xlabel(\"True log-solubility\"); plt.ylabel(\"Predicted\"); plt.title(\"Parity — Ridge\"); plt.show()\n",
    "\n",
    "resid = y_te - y_hat\n",
    "plt.figure(figsize=(4.2,4))\n",
    "plt.scatter(y_hat, resid, alpha=0.7); plt.axhline(0, color=\"k\", ls=\":\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"Residual\"); plt.title(\"Residuals — Ridge\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e278a5d",
   "metadata": {},
   "source": [
    "### 11.4 Solution Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([\n",
    "    [135.0,  2.0,  9.2, 2],   # Molecule A\n",
    "    [301.0,  0.5, 17.7, 2]    # Molecule B\n",
    "])  # descriptors: [MolWt, LogP, TPSA, NumRings]\n",
    "\n",
    "y_new = ridge_best.predict(X_new)\n",
    "print(pd.DataFrame({\n",
    "    \"MolWt\": X_new[:,0], \"LogP\": X_new[:,1], \"TPSA\": X_new[:,2], \"NumRings\": X_new[:,3],\n",
    "    \"Predicted log10(solubility)\": y_new\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470fb240",
   "metadata": {},
   "source": [
    "### 11.5 Solution Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = [\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]\n",
    "\n",
    "coef_ser = pd.Series(ridge_best.coef_, index=feat).sort_values(key=np.abs, ascending=False)\n",
    "print(\"Ridge coefficients:\\n\", coef_ser)\n",
    "coef_ser.plot(kind=\"barh\"); plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Coefficient\"); plt.title(\"Ridge coefficients\"); plt.show()\n",
    "\n",
    "perm = permutation_importance(ridge_best, X_te, y_te, scoring=\"r2\", n_repeats=30, random_state=1)\n",
    "perm_ser = pd.Series(perm.importances_mean, index=feat).sort_values()\n",
    "perm_ser.plot(kind=\"barh\"); plt.xlabel(\"Mean decrease in R²\"); plt.title(\"Permutation importance on test\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f7b4c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "source_map": [
   12,
   222,
   239,
   243,
   250,
   254,
   270,
   274,
   285,
   289,
   300
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}