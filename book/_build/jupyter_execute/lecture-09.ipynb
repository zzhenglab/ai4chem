{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c5259b",
   "metadata": {},
   "source": [
    "# Lecture 9 - Graph Neural Networks (Chemistry)\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    ":depth: 1\n",
    "```\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Build basic MLP-style Neural Networks from scratch using **PyTorch**.  \n",
    "- Explain molecules as **graphs**: atoms = nodes, bonds = edges, features at each.  \n",
    "- Write the **message passing** equations and understand neighborhood aggregation.  \n",
    "- Build a tiny GNN in PyTorch on toy molecules.  \n",
    "- Prepare molecular **graphs from SMILES** and run a mini GNN.  \n",
    "- Experience with a MPNN example **Chemprop**.  \n",
    "\n",
    "---\n",
    "\n",
    "## 1) Setup\n",
    "\n",
    "We reuse most of the stack from earlier lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec43dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup\n",
    "import warnings, math, os, sys, json, time, random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn bits for splitting and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,\n",
    "                             accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, roc_curve, confusion_matrix)\n",
    "\n",
    "# Torch for MLP and GNN\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "except Exception as e:\n",
    "    print(\"Installing torch, this may take a minute...\")\n",
    "    %pip -q install torch\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# RDKit is optional\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import rdchem\n",
    "except Exception:\n",
    "    Chem = None  # we will use toy graphs if RDKit is unavailable\n",
    "\n",
    "# A small global seed helper\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b4f9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2) From MLP (Lecture 8) to PyTorch MLP (recap)\n",
    "\n",
    "In Lecture 8 we built MLPs with scikit‑learn. Today we start by doing the same with **PyTorch** so that the later GNN will feel familiar.\n",
    "\n",
    "We will predict **melting point** from four descriptors: `MolWt`, `LogP`, `TPSA`, `NumRings`, same as before.\n",
    "\n",
    "### 2.1 Load the same CSV and compute descriptors quickly (RDKit optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3a62c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound Name</th>\n",
       "      <th>CAS</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility_mol_per_L</th>\n",
       "      <th>pKa</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Melting Point</th>\n",
       "      <th>Reactivity</th>\n",
       "      <th>Oxidation Site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3,4-dihydro-1H-isochromene</td>\n",
       "      <td>493-05-0</td>\n",
       "      <td>c1ccc2c(c1)CCOC2</td>\n",
       "      <td>0.103906</td>\n",
       "      <td>5.80</td>\n",
       "      <td>non_toxic</td>\n",
       "      <td>65.8</td>\n",
       "      <td>1</td>\n",
       "      <td>8,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9H-fluorene</td>\n",
       "      <td>86-73-7</td>\n",
       "      <td>c1ccc2c(c1)Cc1ccccc1-2</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>5.82</td>\n",
       "      <td>toxic</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,2,3,4-tetrahydronaphthalene</td>\n",
       "      <td>119-64-2</td>\n",
       "      <td>c1ccc2c(c1)CCCC2</td>\n",
       "      <td>0.020589</td>\n",
       "      <td>5.74</td>\n",
       "      <td>toxic</td>\n",
       "      <td>69.4</td>\n",
       "      <td>1</td>\n",
       "      <td>7,10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Compound Name       CAS                  SMILES  \\\n",
       "0     3,4-dihydro-1H-isochromene  493-05-0        c1ccc2c(c1)CCOC2   \n",
       "1                    9H-fluorene   86-73-7  c1ccc2c(c1)Cc1ccccc1-2   \n",
       "2  1,2,3,4-tetrahydronaphthalene  119-64-2        c1ccc2c(c1)CCCC2   \n",
       "\n",
       "   Solubility_mol_per_L   pKa   Toxicity  Melting Point  Reactivity  \\\n",
       "0              0.103906  5.80  non_toxic           65.8           1   \n",
       "1              0.010460  5.82      toxic           90.0           1   \n",
       "2              0.020589  5.74      toxic           69.4           1   \n",
       "\n",
       "  Oxidation Site  \n",
       "0           8,10  \n",
       "1              7  \n",
       "2           7,10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/C_H_oxidation_dataset.csv\"\n",
    "df_raw = pd.read_csv(url)\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf1bfb",
   "metadata": {},
   "source": [
    "If RDKit is available we recompute 4 descriptors. If not, we will use the columns already present in the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b086f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MolWt</th>\n",
       "      <th>LogP</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>NumRings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0, 5, 4, 3, 2, 1], [6, 7, 8, 9, 3, 4]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0, 5, 4, 3, 2, 1], [6, 4, 3, 12, 7], [8, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0, 5, 4, 3, 2, 1], [6, 7, 8, 9, 3, 4]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MolWt  LogP  TPSA                                           NumRings\n",
       "0    NaN   NaN   NaN           [[0, 5, 4, 3, 2, 1], [6, 7, 8, 9, 3, 4]]\n",
       "1    NaN   NaN   NaN  [[0, 5, 4, 3, 2, 1], [6, 4, 3, 12, 7], [8, 9, ...\n",
       "2    NaN   NaN   NaN           [[0, 5, 4, 3, 2, 1], [6, 7, 8, 9, 3, 4]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quick_desc(smiles):\n",
    "    if Chem is None:\n",
    "        # If RDKit not present, return NaNs to fall back to existing columns\n",
    "        return pd.Series({\"MolWt\": np.nan, \"LogP\": np.nan, \"TPSA\": np.nan, \"NumRings\": np.nan})\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    if m is None:\n",
    "        return pd.Series({\"MolWt\": np.nan, \"LogP\": np.nan, \"TPSA\": np.nan, \"NumRings\": np.nan})\n",
    "    # Minimal set computed from RDKit's atom/bond info without heavy deps\n",
    "    mw = rdchem.CalcExactMolWt(m) if hasattr(rdchem, \"CalcExactMolWt\") else np.nan\n",
    "    # Fallbacks if helpers are missing\n",
    "    logp = float(np.nan)\n",
    "    tpsa = float(np.nan)\n",
    "    rings = Chem.GetSSSR(m) if hasattr(Chem, \"GetSSSR\") else np.nan\n",
    "    return pd.Series({\"MolWt\": mw, \"LogP\": logp, \"TPSA\": tpsa, \"NumRings\": rings})\n",
    "\n",
    "# Try to add descriptors; if they already exist with numbers, we will use them\n",
    "maybe_desc = df_raw[\"SMILES\"].head(3).apply(quick_desc)  # quick probe\n",
    "maybe_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa41a28",
   "metadata": {},
   "source": [
    "To keep the class portable, we will **prefer the 4 columns already in the dataset** if they are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dac2eeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['MolWt', 'LogP', 'TPSA', 'NumRings'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m cols = [\u001b[33m\"\u001b[39m\u001b[33mMolWt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLogP\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTPSA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNumRings\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMelting Point\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_reg = \u001b[43mdf_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m]\u001b[49m.dropna()\n\u001b[32m      3\u001b[39m X = df_reg[[\u001b[33m\"\u001b[39m\u001b[33mMolWt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLogP\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTPSA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNumRings\u001b[39m\u001b[33m\"\u001b[39m]].values.astype(np.float32)\n\u001b[32m      4\u001b[39m y = df_reg[\u001b[33m\"\u001b[39m\u001b[33mMelting Point\u001b[39m\u001b[33m\"\u001b[39m].values.astype(np.float32).reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['MolWt', 'LogP', 'TPSA', 'NumRings'] not in index\""
     ]
    }
   ],
   "source": [
    "cols = [\"MolWt\", \"LogP\", \"TPSA\", \"NumRings\", \"Melting Point\"]\n",
    "df_reg = df_raw[cols].dropna()\n",
    "X = df_reg[[\"MolWt\", \"LogP\", \"TPSA\", \"NumRings\"]].values.astype(np.float32)\n",
    "y = df_reg[\"Melting Point\"].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler().fit(Xtr)\n",
    "Xtr_s, Xte_s = scaler.transform(Xtr).astype(np.float32), scaler.transform(Xte).astype(np.float32)\n",
    "\n",
    "Xtr_s.shape, ytr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3016bfdf",
   "metadata": {},
   "source": [
    "### 2.2 Define a tiny MLP in PyTorch\n",
    "\n",
    "We keep one hidden layer to keep the shape clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ddcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyMLP(nn.Module):\n",
    "    def __init__(self, in_dim=4, hidden=32, out_dim=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hidden)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.fc1(x))\n",
    "        out = self.fc2(h)\n",
    "        return out\n",
    "\n",
    "mlp = TinyMLP(in_dim=Xtr_s.shape[1], hidden=32, out_dim=1)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3723af",
   "metadata": {},
   "source": [
    "Check the parameter shapes so you see what is being learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in mlp.named_parameters():\n",
    "    print(name, tuple(p.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3cf192",
   "metadata": {},
   "source": [
    "### 2.3 One training epoch by hand\n",
    "\n",
    "We will implement a plain loop: forward → loss → backward → update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a550ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.Adam(mlp.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "xb = torch.from_numpy(Xtr_s[:64])\n",
    "yb = torch.from_numpy(ytr[:64])\n",
    "pred = mlp(xb)\n",
    "loss = loss_fn(pred, yb)\n",
    "opt.zero_grad(); loss.backward(); opt.step()\n",
    "float(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46eae1f",
   "metadata": {},
   "source": [
    "### 2.4 Full training with a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(NumpyDataset(Xtr_s, ytr), batch_size=64, shuffle=True)\n",
    "\n",
    "mlp = TinyMLP(in_dim=Xtr_s.shape[1], hidden=32, out_dim=1)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.Adam(mlp.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(150):\n",
    "    batch_losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        pred = mlp(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        batch_losses.append(loss.item())\n",
    "    train_losses.append(np.mean(batch_losses))\n",
    "\n",
    "plt.plot(train_losses); plt.xlabel(\"epoch\"); plt.ylabel(\"train MSE\"); plt.title(\"MLP training curve\"); plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ece0b",
   "metadata": {},
   "source": [
    "Evaluate on test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ac6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = mlp(torch.from_numpy(Xte_s)).numpy()\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(yte, yhat):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(yte, yhat):.2f}\")\n",
    "print(f\"R2 : {r2_score(yte, yhat):.3f}\")\n",
    "\n",
    "plt.scatter(yte, yhat, alpha=0.6)\n",
    "lims = [min(yte.min(), yhat.min()), max(yte.max(), yhat.max())]\n",
    "plt.plot(lims, lims, \"k--\"); plt.xlabel(\"True MP\"); plt.ylabel(\"Pred MP\"); plt.title(\"MLP parity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e2d86",
   "metadata": {},
   "source": [
    "```{admonition} ⏰ Exercises 2.x\n",
    "1) Change the hidden size to 64 and rerun. Does R² improve.  \n",
    "2) Switch `ReLU` to `Tanh` and rerun. Compare training curve shape.  \n",
    "3) Increase `weight_decay` to `1e-2`. What happens to train vs test scores.  \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Molecules as graphs\n",
    "\n",
    "A molecule can be seen as a graph:  \n",
    "- **Nodes** are atoms with a feature vector per atom.  \n",
    "- **Edges** are bonds that carry types such as single, double, aromatic.  \n",
    "- A molecule level label (melting point, toxicity) requires **pooling** node representations into one vector.\n",
    "\n",
    "### 3.1 Minimal node and edge features\n",
    "\n",
    "Common node features:\n",
    "- One‑hot element type, degree, formal charge, aromatic flag.  \n",
    "Common edge features:\n",
    "- Bond type one‑hot: single, double, triple, aromatic.\n",
    "\n",
    "We will assemble a small structure that holds:\n",
    "- `x`: node feature matrix, shape `[n_nodes, d_node]`  \n",
    "- `edge_index`: list of edges as two rows `[2, n_edges]`  \n",
    "- `edge_attr`: edge features `[n_edges, d_edge]` (optional)  \n",
    "- `y`: target for the graph\n",
    "\n",
    "### 3.2 Build tiny toy graphs by hand\n",
    "\n",
    "We start with two toy molecules without RDKit: Methane and Ethane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_methane():\n",
    "    # C with 4 H; simple graph centered on C\n",
    "    # nodes: 0=C, 1..4=H\n",
    "    x = np.array([\n",
    "        [6, 4, 0, 0],  # very small features: [atomic_number, degree, is_aromatic, formal_charge]\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 1, 0, 0],\n",
    "    ], dtype=np.float32)\n",
    "    edges = []\n",
    "    for h in [1,2,3,4]:\n",
    "        edges += [(0, h), (h, 0)]\n",
    "    edge_index = np.array(edges, dtype=np.int64).T  # shape [2, 8]\n",
    "    return {\"x\": x, \"edge_index\": edge_index}\n",
    "\n",
    "def toy_ethane():\n",
    "    # C-C with 3 H on each carbon\n",
    "    x = np.array([\n",
    "        [6, 4, 0, 0], [6, 4, 0, 0],  # two carbons\n",
    "        [1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0],  # Hs on C0\n",
    "        [1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0],  # Hs on C1\n",
    "    ], dtype=np.float32)\n",
    "    edges = [(0,1),(1,0)]\n",
    "    for h in [2,3,4]: edges += [(0,h),(h,0)]\n",
    "    for h in [5,6,7]: edges += [(1,h),(h,1)]\n",
    "    edge_index = np.array(edges, dtype=np.int64).T\n",
    "    return {\"x\": x, \"edge_index\": edge_index}\n",
    "\n",
    "g1, g2 = toy_methane(), toy_ethane()\n",
    "[g1[\"x\"].shape, g1[\"edge_index\"].shape, g2[\"x\"].shape, g2[\"edge_index\"].shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1beb1",
   "metadata": {},
   "source": [
    "Peek at arrays to make sure the shapes are what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c72df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Methane x:\\n\", g1[\"x\"])\n",
    "print(\"Methane edges (first 6 cols):\\n\", g1[\"edge_index\"][:, :6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b53db5",
   "metadata": {},
   "source": [
    "```{admonition} Tip\n",
    "Large SMILES → RDKit graphs come later. For now the goal is to **see** the shapes and write a message passing layer on these toy graphs.\n",
    "```\n",
    "\n",
    "```{admonition} ⏰ Exercises 3.x\n",
    "Add a new toy graph for **propane** with indices `[0,1,2]` as the carbon chain and correct hydrogens. Return the same keys `x` and `edge_index`. Print its shapes.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Message passing: the core idea\n",
    "\n",
    "At each layer `t`, every node gets messages from its neighbors and updates its hidden state.\n",
    "\n",
    "A simple form:\n",
    "\n",
    "$$\n",
    "h_v^{(t+1)} = \\sigma\\left(W_\\text{self}\\, h_v^{(t)} + \\sum_{u \\in \\mathcal{N}(v)} W_\\text{nei}\\, h_u^{(t)} + b\\right)\n",
    "$$\n",
    "\n",
    "- `h_v^{(t)}` is the node vector at layer `t`.  \n",
    "- `W_self` maps the node to itself.  \n",
    "- `W_nei` maps neighbor messages.  \n",
    "- Sum neighbor messages, then apply a nonlinearity `σ` such as ReLU.\n",
    "\n",
    "After `T` layers, pool all node vectors to get a graph vector:\n",
    "\n",
    "$$\n",
    "h_\\text{graph} = \\text{POOL}\\left(\\{h_v^{(T)} : v \\in \\text{nodes}\\}\\right)\n",
    "$$\n",
    "\n",
    "POOL can be **sum**, **mean**, or **max**. For regression we feed `h_graph` to a linear head to predict a scalar.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Your first GNN layer in pure PyTorch\n",
    "\n",
    "We implement a very small GNN layer that follows the equation above. No external graph library is needed.\n",
    "\n",
    "### 5.1 A neighbor sum helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor_sum(x, edge_index):\n",
    "    \"\"\"\n",
    "    x: [N, d] node features\n",
    "    edge_index: [2, E] with rows [src, dst]\n",
    "    returns: [N, d] sum of neighbor features for each node (incoming edges)\n",
    "    \"\"\"\n",
    "    N, d = x.shape\n",
    "    out = torch.zeros_like(x)\n",
    "    src, dst = edge_index\n",
    "    out.index_add_(0, dst, x[src])  # sum x[src] into row dst\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed349215",
   "metadata": {},
   "source": [
    "### 5.2 Define one message passing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.self_lin = nn.Linear(in_dim, out_dim, bias=True)\n",
    "        self.nei_lin  = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: [N, in_dim], edge_index: tensor [2, E]\n",
    "        nei_agg = neighbor_sum(x, edge_index)           # [N, in_dim]\n",
    "        out = self.self_lin(x) + self.nei_lin(nei_agg)  # [N, out_dim]\n",
    "        return self.act(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfbe99",
   "metadata": {},
   "source": [
    "### 5.3 Stack layers and pool to a graph vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f589e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyGNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, out_dim, num_layers=2, pool=\"mean\"):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dim = in_dim\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(SimpleMP(dim, hidden))\n",
    "            dim = hidden\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.head = nn.Linear(hidden, out_dim)\n",
    "        self.pool = pool\n",
    "\n",
    "    def readout(self, x):\n",
    "        if self.pool == \"sum\":  return x.sum(dim=0, keepdim=True)\n",
    "        if self.pool == \"max\":  return x.max(dim=0, keepdim=True).values\n",
    "        return x.mean(dim=0, keepdim=True)  # default mean\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for mp in self.layers:\n",
    "            x = mp(x, edge_index)\n",
    "        hg = self.readout(x)         # [1, hidden]\n",
    "        y = self.head(hg)            # [1, out_dim]\n",
    "        return y  # graph-level output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aecc55d",
   "metadata": {},
   "source": [
    "### 5.4 Sanity check with toy graphs\n",
    "\n",
    "We will make up fake targets for the toys to see the forward pass shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9037724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor_graph(g):\n",
    "    x = torch.from_numpy(g[\"x\"])\n",
    "    edge_index = torch.from_numpy(g[\"edge_index\"])\n",
    "    return x, edge_index\n",
    "\n",
    "x1, e1 = to_tensor_graph(g1)\n",
    "x2, e2 = to_tensor_graph(g2)\n",
    "\n",
    "gnn = TinyGNN(in_dim=x1.shape[1], hidden=16, out_dim=1, num_layers=2, pool=\"mean\")\n",
    "with torch.no_grad():\n",
    "    y1 = gnn(x1, e1)\n",
    "    y2 = gnn(x2, e2)\n",
    "print(\"Toy outputs:\", y1.shape, y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae97feb",
   "metadata": {},
   "source": [
    "### 5.5 Train on toy data (regression on a made‑up scalar)\n",
    "\n",
    "Let us define a toy label such as “number of heavy atoms”. This is only for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heavy_atom_count(g):\n",
    "    # heavy atoms = atomic_number > 1\n",
    "    return float((g[\"x\"][:,0] > 1).sum())\n",
    "\n",
    "train_graphs = [toy_methane(), toy_ethane()]\n",
    "y_train = torch.tensor([[heavy_atom_count(g)] for g in train_graphs], dtype=torch.float32)\n",
    "\n",
    "gnn = TinyGNN(in_dim=train_graphs[0][\"x\"].shape[1], hidden=16, out_dim=1, num_layers=2, pool=\"sum\")\n",
    "opt = torch.optim.Adam(gnn.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(200):\n",
    "    epoch_loss = 0.0\n",
    "    for g, ytrue in zip(train_graphs, y_train):\n",
    "        x, ei = to_tensor_graph(g)\n",
    "        pred = gnn(x, ei)\n",
    "        loss = loss_fn(pred, ytrue.view(1,1))\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        epoch_loss += float(loss.item())\n",
    "    losses.append(epoch_loss/len(train_graphs))\n",
    "\n",
    "plt.plot(losses); plt.xlabel(\"epoch\"); plt.ylabel(\"MSE\"); plt.title(\"Toy GNN regression loss\")\n",
    "plt.grid(alpha=0.3); plt.show()\n",
    "\n",
    "for g in train_graphs:\n",
    "    with torch.no_grad():\n",
    "        p = gnn(*to_tensor_graph(g)).item()\n",
    "    print(\"pred\", round(p,3), \"target\", heavy_atom_count(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef5529",
   "metadata": {},
   "source": [
    "```{admonition} What you saw\n",
    "- Node vectors flowed through two message passing layers.  \n",
    "- A readout pooled node states to a graph vector.  \n",
    "- A tiny head predicted a scalar.  \n",
    "```\n",
    "\n",
    "```{admonition} ⏰ Exercises 5.x\n",
    "1) Switch pooling from `\"sum\"` to `\"mean\"` and retrain. Compare convergence.  \n",
    "2) Replace `ReLU` with `Tanh` inside `SimpleMP`. Does the curve change.  \n",
    "3) Change the target to “number of hydrogens” and retrain.  \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6) From SMILES to graphs with RDKit (mini pipeline)\n",
    "\n",
    "Now we prepare graphs from real SMILES. If RDKit is not available in your environment, skip to Section 7 (Chemprop), which does not require RDKit.\n",
    "\n",
    "### 6.1 Featurization helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509429f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom):\n",
    "    # one short vector per atom; keep it tiny for speed\n",
    "    return np.array([\n",
    "        atom.GetAtomicNum(),                 # Z\n",
    "        atom.GetTotalDegree(),               # degree\n",
    "        int(atom.GetIsAromatic()),           # aromatic\n",
    "        atom.GetFormalCharge()               # charge\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "def bond_pairs(mol):\n",
    "    src, dst = [], []\n",
    "    for b in mol.GetBonds():\n",
    "        a = b.GetBeginAtomIdx()\n",
    "        c = b.GetEndAtomIdx()\n",
    "        src += [a, c]\n",
    "        dst += [c, a]\n",
    "    return np.array([src, dst], dtype=np.int64)\n",
    "\n",
    "def smiles_to_graph(smi):\n",
    "    if Chem is None:\n",
    "        raise RuntimeError(\"RDKit not available. Please skip to Section 7 (Chemprop).\")\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None or mol.GetNumAtoms() == 0:\n",
    "        return None\n",
    "    x = np.vstack([atom_features(a) for a in mol.GetAtoms()])  # [N,d]\n",
    "    ei = bond_pairs(mol)                                       # [2,E]\n",
    "    return {\"x\": x, \"edge_index\": ei}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344c1a7",
   "metadata": {},
   "source": [
    "### 6.2 Make a small dataset from the CSV\n",
    "\n",
    "We will try to regress **melting point** as a quick demo with the tiny GNN. This is only to show the flow; Chemprop will do a stronger job later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Chem is not None:\n",
    "    small = df_raw[[\"SMILES\",\"Melting Point\"]].dropna().sample(200, random_state=0)\n",
    "    graphs, targets = [], []\n",
    "    for smi, mp in zip(small[\"SMILES\"], small[\"Melting Point\"]):\n",
    "        g = smiles_to_graph(smi)\n",
    "        if g is not None:\n",
    "            graphs.append(g); targets.append(mp)\n",
    "    y_all = torch.tensor(targets, dtype=torch.float32).view(-1,1)\n",
    "    len(graphs), y_all.shape\n",
    "else:\n",
    "    print(\"RDKit missing. Skip to Section 7.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb3ce5",
   "metadata": {},
   "source": [
    "### 6.3 Tiny training loop for graphs\n",
    "\n",
    "We split by index since graphs are already constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Chem is not None and len(graphs) > 20:\n",
    "    idx = np.arange(len(graphs))\n",
    "    tr_idx, te_idx = train_test_split(idx, test_size=0.2, random_state=42)\n",
    "    gnn = TinyGNN(in_dim=graphs[0][\"x\"].shape[1], hidden=32, out_dim=1, num_layers=3, pool=\"mean\")\n",
    "    opt = torch.optim.Adam(gnn.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(60):\n",
    "        batch = np.random.choice(tr_idx, size=min(64, len(tr_idx)), replace=False)\n",
    "        epoch_loss = 0.0\n",
    "        for i in batch:\n",
    "            x = torch.from_numpy(graphs[i][\"x\"])\n",
    "            ei = torch.from_numpy(graphs[i][\"edge_index\"])\n",
    "            pred = gnn(x, ei)\n",
    "            loss = loss_fn(pred, y_all[i:i+1])\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            epoch_loss += float(loss.item())\n",
    "        losses.append(epoch_loss/len(batch))\n",
    "\n",
    "    plt.plot(losses); plt.xlabel(\"epoch\"); plt.ylabel(\"MSE\"); plt.title(\"Tiny GNN on melting point\")\n",
    "    plt.grid(alpha=0.3); plt.show()\n",
    "\n",
    "    # Evaluate\n",
    "    y_true, y_pred = [], []\n",
    "    gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in te_idx:\n",
    "            p = gnn(torch.from_numpy(graphs[i][\"x\"]),\n",
    "                    torch.from_numpy(graphs[i][\"edge_index\"])).item()\n",
    "            y_true.append(float(y_all[i]))\n",
    "            y_pred.append(p)\n",
    "\n",
    "    print(f\"MSE: {mean_squared_error(y_true, y_pred):.2f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_true, y_pred):.2f}\")\n",
    "    print(f\"R2 : {r2_score(y_true, y_pred):.3f}\")\n",
    "\n",
    "    plt.scatter(y_true, y_pred, alpha=0.6)\n",
    "    lims = [min(min(y_true), min(y_pred)), max(max(y_true), max(y_pred))]\n",
    "    plt.plot(lims, lims, \"k--\"); plt.xlabel(\"True MP\"); plt.ylabel(\"Pred MP\"); plt.title(\"Tiny GNN parity\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fc955",
   "metadata": {},
   "source": [
    "```{admonition} Takeaway\n",
    "This simple GNN is **minimal**. Real molecular GNNs use richer atom and bond features, multiple heads, dropout, and careful training schedules.\n",
    "```\n",
    "\n",
    "```{admonition} ⏰ Exercises 6.x\n",
    "1) Change `num_layers` from 3 to 2 and 4. Record test R² for each.  \n",
    "2) Change pooling from mean to sum. Does performance change.  \n",
    "3) Add `nn.Dropout(p=0.1)` after each `SimpleMP` in `TinyGNN` and test again.  \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Chemprop v2: practical graph models for chemistry\n",
    "\n",
    "Chemprop implements a directed message passing neural network with strong defaults. We will:\n",
    "\n",
    "1) **Install Chemprop v2**  \n",
    "2) Run a **melting point** regression  \n",
    "3) Run a **reactivity** classification and predict on new SMILES\n",
    "\n",
    "### 7.1 Install Chemprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need a restart after install in some environments\n",
    "%pip -q install chemprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58425d80",
   "metadata": {},
   "source": [
    "### 7.2 Melting point regression\n",
    "\n",
    "Prepare a minimal CSV: `SMILES,Melting Point`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and write a small CSV\n",
    "url = \"https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/C_H_oxidation_dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "reg_cols = [\"SMILES\", \"Melting Point\"]\n",
    "df_reg = df[reg_cols].dropna().copy()\n",
    "df_reg.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de66d94",
   "metadata": {},
   "source": [
    "Save to disk for Chemprop CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f105a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.to_csv(\"mp_data.csv\", index=False)\n",
    "len(df_reg), df_reg.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fe3193",
   "metadata": {},
   "source": [
    "Train a **small** model so it runs in class. We log common metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A short run. Increase epochs later if you have time/GPU.\n",
    "!chemprop train \\\n",
    "  --data-path mp_data.csv \\\n",
    "  -t regression \\\n",
    "  -s SMILES \\\n",
    "  --target-columns \"Melting Point\" \\\n",
    "  -o mp_model \\\n",
    "  --num-replicates 1 \\\n",
    "  --epochs 15 \\\n",
    "  --save-smiles-splits \\\n",
    "  --metrics mae rmse r2 \\\n",
    "  --tracking-metric r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca9c9a1",
   "metadata": {},
   "source": [
    "Make quick predictions on a few molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = [\n",
    "    \"CCO\",              # ethanol\n",
    "    \"c1ccccc1\",         # benzene\n",
    "    \"CC(=O)O\",          # acetic acid\n",
    "    \"CCN(CC)CC\"         # triethylamine\n",
    "]\n",
    "pd.DataFrame({\"SMILES\": smiles_list}).to_csv(\"custom_smiles_reg.csv\", index=False)\n",
    "\n",
    "!chemprop predict \\\n",
    "  --test-path custom_smiles_reg.csv \\\n",
    "  --model-paths mp_model/replicate_0/model_0/best.pt \\\n",
    "  --preds-path mp_preds.csv\n",
    "\n",
    "pd.read_csv(\"mp_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e1bd8",
   "metadata": {},
   "source": [
    "### 7.3 Reactivity classification (C–H oxidation dataset)\n",
    "\n",
    "We use the `Reactivity` column and convert it to **binary** 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)\n",
    "df[\"Reactivity_bin\"] = df[\"Reactivity\"].replace({-1: 0}).astype(int)\n",
    "df[[\"SMILES\",\"Reactivity\",\"Reactivity_bin\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a584fa1",
   "metadata": {},
   "source": [
    "Write a minimal file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"SMILES\", \"Reactivity_bin\"]].to_csv(\"reactivity_data_bin.csv\", index=False)\n",
    "\n",
    "# Optional: sanity check the class balance\n",
    "print(df[\"Reactivity\"].value_counts(dropna=False).to_dict())\n",
    "print(df[\"Reactivity_bin\"].value_counts(dropna=False).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d6107",
   "metadata": {},
   "source": [
    "Train a short classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392fdd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chemprop train \\\n",
    "  --data-path reactivity_data_bin.csv \\\n",
    "  -t classification \\\n",
    "  -s SMILES \\\n",
    "  --target-columns Reactivity_bin \\\n",
    "  -o reactivity_model \\\n",
    "  --num-replicates 1 \\\n",
    "  --epochs 15 \\\n",
    "  --class-balance \\\n",
    "  --metrics roc prc accuracy \\\n",
    "  --tracking-metric roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b00d0c",
   "metadata": {},
   "source": [
    "Predict on new SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb655ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = [\n",
    "    \"CCO\",\n",
    "    \"c1ccccc1C(F)\",\n",
    "    \"C1=C([C@@H]2C[C@H](C1)C2(C)C)\",\n",
    "    \"C1=CC=CC=C1C=O\",\n",
    "    \"CCN(CC)CC\",\n",
    "    \"c1cccc(C=CC)c1\"\n",
    "]\n",
    "pd.DataFrame({\"SMILES\": smiles_list}).to_csv(\"custom_smiles.csv\", index=False)\n",
    "\n",
    "!chemprop predict \\\n",
    "  --test-path custom_smiles.csv \\\n",
    "  --model-paths reactivity_model/replicate_0/model_0/best.pt \\\n",
    "  --preds-path custom_preds.csv\n",
    "\n",
    "pd.read_csv(\"custom_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee600e2",
   "metadata": {},
   "source": [
    "```{admonition} Tips\n",
    "- Increase `--num-replicates` to 3 and `--epochs` to 50-100 for stronger baselines.  \n",
    "- For class imbalance, keep `--class-balance`.  \n",
    "- Use `--save-smiles-splits` to capture exact train/val/test molecules for reproducibility.  \n",
    "```\n",
    "\n",
    "```{admonition} ⏰ Exercises 7.x\n",
    "1) Add `--ensemble-size 5` during prediction by passing multiple `--model-paths` if you trained replicates. Compare ROC.  \n",
    "2) Change tracking metric to `prc` and rerun. Does validation selection change.  \n",
    "3) For melting point, add `--ffn-hidden-size 800` to increase the head capacity and try 30 epochs.  \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 8) References\n",
    "\n",
    "- Gilmer, J. et al., **Neural Message Passing for Quantum Chemistry**, ICML 2017.  \n",
    "- Yang, K. et al., **Analyzing Learned Molecular Representations for Property Prediction**, J. Chem. Inf. Model. 2019.  \n",
    "- Chemprop documentation: training flags, metrics, and examples.  \n",
    "- RDKit: molecule objects, atom and bond APIs.  \n",
    "- PyTorch: custom `nn.Module`, autograd, and optimizers.\n",
    "\n",
    "*(If you need links, see your course page where these are listed with URLs.)*\n",
    "\n",
    "---\n",
    "\n",
    "## 9) Glossary\n",
    "\n",
    "```{glossary}\n",
    "graph neural network\n",
    "  A neural model that updates node states by aggregating messages from neighbors.\n",
    "\n",
    "message passing\n",
    "  The update step where a node combines its own vector with aggregated neighbor vectors.\n",
    "\n",
    "readout (pooling)\n",
    "  Operation that compresses node states into a single graph vector, often by sum, mean, or max.\n",
    "\n",
    "edge index\n",
    "  A 2×E tensor listing source and destination of each edge.\n",
    "\n",
    "Chemprop\n",
    "  A practical library that trains message passing networks directly from SMILES.\n",
    "\n",
    "replicate\n",
    "  Independent training run with a different random seed. Often ensembled for stability.\n",
    "\n",
    "tracking metric\n",
    "  The metric used to pick the best checkpoint during training.\n",
    "\n",
    "class balance\n",
    "  Loss weighting that compensates for skewed class proportions.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 10) In‑class activity and solutions\n",
    "\n",
    "Each question is designed to be solved with what you coded above. Try first, then check the solution blocks.\n",
    "\n",
    "### Q1. MLP warmup on melting point\n",
    "\n",
    "- Use features `[MolWt, LogP, TPSA, NumRings]`  \n",
    "- Standardize, then train the PyTorch MLP `(32,)` for 150 epochs  \n",
    "- Report `MSE`, `MAE`, `R²` and draw a parity plot\n",
    "\n",
    "```python\n",
    "# TO DO: write your MLP training in PyTorch as in Section 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Q2. Build and inspect the toy GNN\n",
    "\n",
    "- Train `TinyGNN` with pooling `\"sum\"` on methane and ethane to predict **heavy atom count**  \n",
    "- Plot the loss  \n",
    "- Change pooling to `\"mean\"` and compare loss and predictions\n",
    "\n",
    "```python\n",
    "# TO DO: reuse the code in Section 5\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Q3. RDKit graph mini‑set (optional if RDKit missing)\n",
    "\n",
    "- Sample 200 SMILES with melting points from the CSV  \n",
    "- Convert to graphs and train `TinyGNN` with `num_layers=3`, hidden 32  \n",
    "- Report `R²` on a 80/20 split and draw a parity plot\n",
    "\n",
    "```python\n",
    "# TO DO: follow Section 6\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Q4. Chemprop regression on melting point\n",
    "\n",
    "- Train Chemprop on `mp_data.csv` for `--epochs 20`  \n",
    "- Predict on at least 5 new SMILES of your choice and list the predictions\n",
    "\n",
    "```python\n",
    "# TO DO: run the chemprop CLI as in Section 7.2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Q5. Chemprop classification on toxicity (student challenge)\n",
    "\n",
    "- Convert `Toxicity` to `1/0` using the mapping `{toxic:1, non_toxic:0}`  \n",
    "- Save `[\"SMILES\",\"Toxicity_bin\"]` to `tox_data.csv`  \n",
    "- Train with `--class-balance --epochs 20` and metrics `roc prc accuracy`  \n",
    "- Predict on a small set of SMILES; show the class probability\n",
    "\n",
    "```python\n",
    "# TO DO: similar to Section 7.3, but target is Toxicity_bin\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Solutions\n",
    "\n",
    "#### Solution Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 solution\n",
    "set_seed(0)\n",
    "df_reg = df_raw[[\"MolWt\", \"LogP\", \"TPSA\", \"NumRings\", \"Melting Point\"]].dropna()\n",
    "X = df_reg[[\"MolWt\",\"LogP\",\"TPSA\",\"NumRings\"]].values.astype(np.float32)\n",
    "y = df_reg[\"Melting Point\"].values.astype(np.float32).reshape(-1,1)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sc = StandardScaler().fit(Xtr)\n",
    "Xtr_s = sc.transform(Xtr).astype(np.float32)\n",
    "Xte_s = sc.transform(Xte).astype(np.float32)\n",
    "\n",
    "mlp = TinyMLP(in_dim=4, hidden=32, out_dim=1)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.Adam(mlp.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "train_loader = DataLoader(NumpyDataset(Xtr_s, ytr), batch_size=64, shuffle=True)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(150):\n",
    "    bs = []\n",
    "    for xb, yb in train_loader:\n",
    "        pred = mlp(xb); loss = loss_fn(pred, yb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        bs.append(loss.item())\n",
    "    losses.append(np.mean(bs))\n",
    "\n",
    "mlp.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = mlp(torch.from_numpy(Xte_s)).numpy()\n",
    "\n",
    "print(f\"MSE={mean_squared_error(yte, yhat):.2f}  MAE={mean_absolute_error(yte, yhat):.2f}  R2={r2_score(yte, yhat):.3f}\")\n",
    "plt.plot(losses); plt.xlabel(\"epoch\"); plt.ylabel(\"MSE\"); plt.title(\"Q1 MLP loss\"); plt.grid(alpha=0.3); plt.show()\n",
    "\n",
    "plt.scatter(yte, yhat, alpha=0.6)\n",
    "lims = [min(yte.min(), yhat.min()), max(yte.max(), yhat.max())]\n",
    "plt.plot(lims, lims, \"k--\"); plt.xlabel(\"True MP\"); plt.ylabel(\"Pred MP\"); plt.title(\"Q1 parity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c271b",
   "metadata": {},
   "source": [
    "#### Solution Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 solution\n",
    "train_graphs = [toy_methane(), toy_ethane()]\n",
    "y_train = torch.tensor([[heavy_atom_count(g)] for g in train_graphs], dtype=torch.float32)\n",
    "\n",
    "def run(pool):\n",
    "    gnn = TinyGNN(in_dim=train_graphs[0][\"x\"].shape[1], hidden=16, out_dim=1, num_layers=2, pool=pool)\n",
    "    opt = torch.optim.Adam(gnn.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    losses = []\n",
    "    for epoch in range(200):\n",
    "        s = 0.0\n",
    "        for g, ytrue in zip(train_graphs, y_train):\n",
    "            x = torch.from_numpy(g[\"x\"]); ei = torch.from_numpy(g[\"edge_index\"])\n",
    "            pred = gnn(x, ei); loss = loss_fn(pred, ytrue.view(1,1))\n",
    "            opt.zero_grad(); loss.backward(); opt.step(); s += loss.item()\n",
    "        losses.append(s/len(train_graphs))\n",
    "    return gnn, losses\n",
    "\n",
    "g_sum, L_sum = run(\"sum\")\n",
    "g_mean, L_mean = run(\"mean\")\n",
    "\n",
    "plt.plot(L_sum, label=\"sum\"); plt.plot(L_mean, label=\"mean\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"MSE\"); plt.title(\"Q2 loss\"); plt.legend(); plt.grid(alpha=0.3); plt.show()\n",
    "\n",
    "for tag, gnn in [(\"sum\", g_sum), (\"mean\", g_mean)]:\n",
    "    for g in train_graphs:\n",
    "        with torch.no_grad():\n",
    "            p = gnn(torch.from_numpy(g[\"x\"]), torch.from_numpy(g[\"edge_index\"])).item()\n",
    "        print(tag, \"pred\", round(p,3), \"target\", heavy_atom_count(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a3207",
   "metadata": {},
   "source": [
    "#### Solution Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 solution (skip if RDKit missing)\n",
    "if Chem is not None:\n",
    "    small = df_raw[[\"SMILES\",\"Melting Point\"]].dropna().sample(200, random_state=0)\n",
    "    graphs, y = [], []\n",
    "    for smi, mp in zip(small[\"SMILES\"], small[\"Melting Point\"]):\n",
    "        g = smiles_to_graph(smi)\n",
    "        if g is not None:\n",
    "            graphs.append(g); y.append(mp)\n",
    "    y = torch.tensor(y, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "    idx = np.arange(len(graphs))\n",
    "    tr, te = train_test_split(idx, test_size=0.2, random_state=42)\n",
    "    gnn = TinyGNN(in_dim=graphs[0][\"x\"].shape[1], hidden=32, out_dim=1, num_layers=3, pool=\"mean\")\n",
    "    opt = torch.optim.Adam(gnn.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(60):\n",
    "        batch = np.random.choice(tr, size=min(64, len(tr)), replace=False)\n",
    "        for i in batch:\n",
    "            x = torch.from_numpy(graphs[i][\"x\"])\n",
    "            ei = torch.from_numpy(graphs[i][\"edge_index\"])\n",
    "            pred = gnn(x, ei); loss = loss_fn(pred, y[i:i+1])\n",
    "            opt.zero_grad(); opt.step()\n",
    "\n",
    "    yt, yp = [], []\n",
    "    gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in te:\n",
    "            yp.append(gnn(torch.from_numpy(graphs[i][\"x\"]),\n",
    "                          torch.from_numpy(graphs[i][\"edge_index\"])).item())\n",
    "            yt.append(float(y[i]))\n",
    "\n",
    "    from sklearn.metrics import mean_absolute_error, r2_score\n",
    "    print(f\"R2: {r2_score(yt, yp):.3f}  MAE: {mean_absolute_error(yt, yp):.2f}\")\n",
    "else:\n",
    "    print(\"RDKit missing; skip Q3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245bf988",
   "metadata": {},
   "source": [
    "#### Solution Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 solution\n",
    "df_reg = df[[\"SMILES\",\"Melting Point\"]].dropna().copy()\n",
    "df_reg.to_csv(\"mp_data.csv\", index=False)\n",
    "\n",
    "!chemprop train \\\n",
    "  --data-path mp_data.csv \\\n",
    "  -t regression \\\n",
    "  -s SMILES \\\n",
    "  --target-columns \"Melting Point\" \\\n",
    "  -o mp_model_q4 \\\n",
    "  --num-replicates 1 \\\n",
    "  --epochs 20 \\\n",
    "  --metrics mae rmse r2 \\\n",
    "  --tracking-metric r2\n",
    "\n",
    "pd.DataFrame({\"SMILES\": [\"CCO\",\"c1ccccc1\",\"CC(=O)O\",\"CCN(CC)CC\",\"O=C(O)C(O)C\"]}).to_csv(\"q4_smiles.csv\", index=False)\n",
    "\n",
    "!chemprop predict \\\n",
    "  --test-path q4_smiles.csv \\\n",
    "  --model-paths mp_model_q4/replicate_0/model_0/best.pt \\\n",
    "  --preds-path q4_preds.csv\n",
    "\n",
    "pd.read_csv(\"q4_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e28f1",
   "metadata": {},
   "source": [
    "#### Solution Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5db542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 solution\n",
    "df = pd.read_csv(url)\n",
    "df = df[[\"SMILES\",\"Toxicity\"]].dropna().copy()\n",
    "df[\"Toxicity_bin\"] = df[\"Toxicity\"].str.lower().map({\"toxic\":1, \"non_toxic\":0}).astype(int)\n",
    "df[[\"SMILES\",\"Toxicity_bin\"]].to_csv(\"tox_data.csv\", index=False)\n",
    "\n",
    "!chemprop train \\\n",
    "  --data-path tox_data.csv \\\n",
    "  -t classification \\\n",
    "  -s SMILES \\\n",
    "  --target-columns Toxicity_bin \\\n",
    "  -o tox_model \\\n",
    "  --num-replicates 1 \\\n",
    "  --epochs 20 \\\n",
    "  --class-balance \\\n",
    "  --metrics roc prc accuracy \\\n",
    "  --tracking-metric roc\n",
    "\n",
    "pd.DataFrame({\"SMILES\": [\"CCO\",\"c1ccccc1\",\"O=[N+](=O)[O-]\",\"ClCCl\",\"CC(=O)Cl\"]}).to_csv(\"q5_smiles.csv\", index=False)\n",
    "\n",
    "!chemprop predict \\\n",
    "  --test-path q5_smiles.csv \\\n",
    "  --model-paths tox_model/replicate_0/model_0/best.pt \\\n",
    "  --preds-path q5_preds.csv\n",
    "\n",
    "pd.read_csv(\"q5_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ecc8b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Quick cheat sheet\n",
    "\n",
    "- Message passing layer shape checks help catch indexing mistakes early.  \n",
    "- Pooling choice can change gradients a lot on small graphs.  \n",
    "- Chemprop is fast to try. Start with 15–30 epochs and 1–3 replicates during class. Increase later.  \n",
    "- For classification targets, always look at `roc` and `prc`, not only accuracy.  \n",
    "\n",
    "---\n",
    "\n",
    "```{admonition} What to remember\n",
    "- An MLP ignores graph structure. A GNN uses edges to mix neighbor information.  \n",
    "- The core update is neighbor aggregation followed by a learnable transformation.  \n",
    "- Chemprop encodes many best practices so you can focus on data and targets.  \n",
    "```\n",
    "\n",
    "```{admonition} Where this connects\n",
    "Back to Lecture 8: you built MLPs and read loss curves. The same training loop ideas apply to GNNs. The difference is the **forward** pass uses a graph structure to route information.\n",
    "```\n",
    "\n",
    "```{admonition} Try at home\n",
    "- Compare `sum` vs `mean` pooling on size‑varying molecules.  \n",
    "- Add bond type one‑hot to the neighbor message with a small MLP inside `SimpleMP`.  \n",
    "- Use Chemprop for **logS** regression and compare to your MLP from Lecture 8.  \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "source_map": [
   12,
   36,
   75,
   87,
   91,
   95,
   114,
   118,
   129,
   135,
   150,
   154,
   157,
   163,
   173,
   177,
   203,
   207,
   220,
   254,
   286,
   290,
   293,
   336,
   348,
   352,
   365,
   369,
   393,
   399,
   413,
   419,
   449,
   471,
   499,
   505,
   517,
   523,
   565,
   589,
   592,
   598,
   605,
   609,
   612,
   616,
   629,
   633,
   648,
   654,
   658,
   662,
   668,
   672,
   684,
   688,
   705,
   831,
   867,
   871,
   901,
   905,
   942,
   946,
   970,
   974,
   1001
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}