
<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Lecture 7 - Decision Trees and Random Forests &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css?v=6ad1a40c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=2b91c5f0"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js?v=afe5de03"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lecture-07';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Lecture 8 - Neural Networks" href="lecture-08.html" />
    <link rel="prev" title="Lecture 6 - Cross-Validation" href="lecture-06.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to CHEM 5080: AI for Chemistry
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-01.html">Lecture 1 - Python Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-02.html">Lecture 2 - Pandas and Plotting</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-03.html">Lecture 3 - SMILES and RDKit</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-04.html">Lecture 4 - Chemical Structure Identifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-05.html">Lecture 5 - Regression and Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-06.html">Lecture 6 - Cross-Validation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lecture 7 - Decision Trees and Random Forests</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-08.html">Lecture 8 - Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-09.html">Lecture 9 - Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-10.html">Lecture 10 - Property &amp; Reaction Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-11.html">Lecture 11 - Dimension Reduction for Data Visualization</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Flecture-07.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/lecture-07.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 7 - Decision Trees and Random Forests</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-goals">Learning goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">0. Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree">1. Decision tree</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-data-and-build-descriptors">1.1 Load data and build descriptors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-decision-tree">1.2 What is a decision tree</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tiny-classification-example-one-split">1.3 Tiny classification example: one split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grow-deeper-and-control-overfitting">1.4 Grow deeper and control overfitting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-based-importance-gini-importance">1.5 Model-based importance: Gini importance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-based-importance-permutation-importance">1.6 Data-based importance: Permutation importance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-trees-on-melting-point">2. Regression trees on Melting Point</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-bagging-many-trees">3. Random Forest: bagging many trees</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-forest-on-toxicity">3.1 Classification forest on toxicity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-forest-on-melting-point">3.2 Regression forest on Melting Point</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ensembles">4. Ensembles</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-single-tree-vs-random-forest">4.1 Experiment: single tree vs random forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-ensembles-by-model-averaging">4.2 Simple Ensembles by Model Averaging</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-ensembles-by-voting">4.3 Simple Ensembles by Voting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-topic-boosting-a-different-ensemble-structure">4.4 (Optional Topic) Boosting: a different ensemble structure</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#end-to-end-recipe-for-random-forest">5. End-to-end recipe for random forest</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-reference">6. Quick reference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-class-activities">7. In-class activities</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tree-vs-forest-on-log-solubility">7.1 Tree vs Forest on log-solubility</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pruning-with-min-samples-leaf">7.2 Pruning with <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#toxicity-prediction">7.3 Toxicity prediction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-importance-agreement">7.4 Feature importance agreement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-search-with-cross-validation">7.5 Hyperparameter search with cross validation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions">8. Solutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q1">Q1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q2">Q2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q3">Q3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q4">Q4</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q5">Q5</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-7-decision-trees-and-random-forests">
<h1>Lecture 7 - Decision Trees and Random Forests<a class="headerlink" href="#lecture-7-decision-trees-and-random-forests" title="Permalink to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#learning-goals" id="id1">Learning goals</a></p></li>
<li><p><a class="reference internal" href="#setup" id="id2">0. Setup</a></p></li>
<li><p><a class="reference internal" href="#decision-tree" id="id3">1. Decision tree</a></p></li>
<li><p><a class="reference internal" href="#regression-trees-on-melting-point" id="id4">2. Regression trees on Melting Point</a></p></li>
<li><p><a class="reference internal" href="#random-forest-bagging-many-trees" id="id5">3. Random Forest: bagging many trees</a></p></li>
<li><p><a class="reference internal" href="#ensembles" id="id6">4. Ensembles</a></p></li>
<li><p><a class="reference internal" href="#end-to-end-recipe-for-random-forest" id="id7">5. End-to-end recipe for random forest</a></p></li>
<li><p><a class="reference internal" href="#quick-reference" id="id8">6. Quick reference</a></p></li>
<li><p><a class="reference internal" href="#in-class-activities" id="id9">7. In-class activities</a></p></li>
<li><p><a class="reference internal" href="#solutions" id="id10">8. Solutions</a></p></li>
</ul>
</nav>
<section id="learning-goals">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Learning goals</a><a class="headerlink" href="#learning-goals" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>Explain the intuition of <strong>decision trees</strong> for regression and classification.</p></li>
<li><p>Read <strong>Gini</strong> and <strong>entropy</strong> for splits and <strong>MSE</strong> for regression splits.</p></li>
<li><p>Grow a tree step by step and inspect internal structures: nodes, depth, leaf counts.</p></li>
<li><p>Control tree growth with <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>.</p></li>
<li><p>Visualize a fitted tree and feature importance.</p></li>
<li><p>Train a <strong>Random Forest</strong> and compare to a single tree.</p></li>
<li><p>Put it all together in a short end-to-end workflow.</p>
<p><a class="reference external" href="https://colab.research.google.com/drive/1gok-fXtkuhjkI3zn5s17E02B-tcvek8h?usp=sharing"><img alt="Colab" src="https://img.shields.io/badge/Open-Colab-orange" /></a></p>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="setup">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">0. Setup</a><a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 0. Setup</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">rdkit</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chem</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">rdkit.Chem</span><span class="w"> </span><span class="kn">import</span> <span class="n">Descriptors</span><span class="p">,</span> <span class="n">Crippen</span><span class="p">,</span> <span class="n">rdMolDescriptors</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">Chem</span> <span class="o">=</span> <span class="kc">None</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">,</span>
    <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span>
    <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="p">,</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">plot_tree</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.inspection</span><span class="w"> </span><span class="kn">import</span> <span class="n">permutation_importance</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">lasso_path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;X does not have valid feature names&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;X has feature names&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="decision-tree">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">1. Decision tree</a><a class="headerlink" href="#decision-tree" title="Permalink to this heading">#</a></h2>
<section id="load-data-and-build-descriptors">
<h3>1.1 Load data and build descriptors<a class="headerlink" href="#load-data-and-build-descriptors" title="Permalink to this heading">#</a></h3>
<p>We will reuse the same dataset to keep the context consistent. If RDKit is available, we compute four descriptors; otherwise we fallback to numeric columns that are already present.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/C_H_oxidation_dataset.csv&quot;</span>
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">df_raw</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Compound Name</th>
      <th>CAS</th>
      <th>SMILES</th>
      <th>Solubility_mol_per_L</th>
      <th>pKa</th>
      <th>Toxicity</th>
      <th>Melting Point</th>
      <th>Reactivity</th>
      <th>Oxidation Site</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3,4-dihydro-1H-isochromene</td>
      <td>493-05-0</td>
      <td>c1ccc2c(c1)CCOC2</td>
      <td>0.103906</td>
      <td>5.80</td>
      <td>non_toxic</td>
      <td>65.8</td>
      <td>1</td>
      <td>8,10</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9H-fluorene</td>
      <td>86-73-7</td>
      <td>c1ccc2c(c1)Cc1ccccc1-2</td>
      <td>0.010460</td>
      <td>5.82</td>
      <td>toxic</td>
      <td>90.0</td>
      <td>1</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1,2,3,4-tetrahydronaphthalene</td>
      <td>119-64-2</td>
      <td>c1ccc2c(c1)CCCC2</td>
      <td>0.020589</td>
      <td>5.74</td>
      <td>toxic</td>
      <td>69.4</td>
      <td>1</td>
      <td>7,10</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ethylbenzene</td>
      <td>100-41-4</td>
      <td>CCc1ccccc1</td>
      <td>0.048107</td>
      <td>5.87</td>
      <td>non_toxic</td>
      <td>65.0</td>
      <td>1</td>
      <td>1,2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>cyclohexene</td>
      <td>110-83-8</td>
      <td>C1=CCCCC1</td>
      <td>0.060688</td>
      <td>5.66</td>
      <td>non_toxic</td>
      <td>96.4</td>
      <td>1</td>
      <td>3,6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">calc_descriptors</span><span class="p">(</span><span class="n">smiles</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">Chem</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s2">&quot;MolWt&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">})</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s2">&quot;MolWt&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span>
        <span class="s2">&quot;MolWt&quot;</span><span class="p">:</span> <span class="n">Descriptors</span><span class="o">.</span><span class="n">MolWt</span><span class="p">(</span><span class="n">m</span><span class="p">),</span>
        <span class="s2">&quot;LogP&quot;</span><span class="p">:</span> <span class="n">Crippen</span><span class="o">.</span><span class="n">MolLogP</span><span class="p">(</span><span class="n">m</span><span class="p">),</span>
        <span class="s2">&quot;TPSA&quot;</span><span class="p">:</span> <span class="n">rdMolDescriptors</span><span class="o">.</span><span class="n">CalcTPSA</span><span class="p">(</span><span class="n">m</span><span class="p">),</span>
        <span class="s2">&quot;NumRings&quot;</span><span class="p">:</span> <span class="n">rdMolDescriptors</span><span class="o">.</span><span class="n">CalcNumRings</span><span class="p">(</span><span class="n">m</span><span class="p">),</span>
    <span class="p">})</span>

<span class="n">desc</span> <span class="o">=</span> <span class="n">df_raw</span><span class="p">[</span><span class="s2">&quot;SMILES&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">calc_descriptors</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_raw</span><span class="p">,</span> <span class="n">desc</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Compound Name</th>
      <th>CAS</th>
      <th>SMILES</th>
      <th>Solubility_mol_per_L</th>
      <th>pKa</th>
      <th>Toxicity</th>
      <th>Melting Point</th>
      <th>Reactivity</th>
      <th>Oxidation Site</th>
      <th>MolWt</th>
      <th>LogP</th>
      <th>TPSA</th>
      <th>NumRings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3,4-dihydro-1H-isochromene</td>
      <td>493-05-0</td>
      <td>c1ccc2c(c1)CCOC2</td>
      <td>0.103906</td>
      <td>5.80</td>
      <td>non_toxic</td>
      <td>65.8</td>
      <td>1</td>
      <td>8,10</td>
      <td>134.178</td>
      <td>1.7593</td>
      <td>9.23</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9H-fluorene</td>
      <td>86-73-7</td>
      <td>c1ccc2c(c1)Cc1ccccc1-2</td>
      <td>0.010460</td>
      <td>5.82</td>
      <td>toxic</td>
      <td>90.0</td>
      <td>1</td>
      <td>7</td>
      <td>166.223</td>
      <td>3.2578</td>
      <td>0.00</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1,2,3,4-tetrahydronaphthalene</td>
      <td>119-64-2</td>
      <td>c1ccc2c(c1)CCCC2</td>
      <td>0.020589</td>
      <td>5.74</td>
      <td>toxic</td>
      <td>69.4</td>
      <td>1</td>
      <td>7,10</td>
      <td>132.206</td>
      <td>2.5654</td>
      <td>0.00</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="admonition-features admonition">
<p class="admonition-title">Features</p>
<p>We will use <code class="docutils literal notranslate"><span class="pre">MolWt</span></code>, <code class="docutils literal notranslate"><span class="pre">LogP</span></code>, <code class="docutils literal notranslate"><span class="pre">TPSA</span></code>, <code class="docutils literal notranslate"><span class="pre">NumRings</span></code> as base features. They worked well in earlier lectures and are fast to compute.</p>
</div>
</section>
<hr class="docutils" />
<section id="what-is-a-decision-tree">
<h3>1.2 What is a decision tree<a class="headerlink" href="#what-is-a-decision-tree" title="Permalink to this heading">#</a></h3>
<p>A tree splits the feature space into rectangles by asking simple questions like <code class="docutils literal notranslate"><span class="pre">LogP</span> <span class="pre">&lt;=</span> <span class="pre">1.3</span></code>. Each split tries to make the target inside each branch more pure.</p>
<ul class="simple">
<li><p>For <strong>classification</strong>, purity is measured by <strong>Gini</strong> or <strong>entropy</strong>.</p></li>
<li><p>For <strong>regression</strong>, it is common to use <strong>MSE</strong> reduction.</p></li>
</ul>
<div class="admonition-purity admonition">
<p class="admonition-title">Purity</p>
<ul class="simple">
<li><p>Gini for a node with class probs <span class="math notranslate nohighlight">\(p_k\)</span>: <span class="math notranslate nohighlight">\(1 - \sum_k p_k^2\)</span></p></li>
<li><p>Entropy:  <span class="math notranslate nohighlight">\(-\sum_k p_k \log_2 p_k\)</span></p></li>
<li><p>Regression impurity at a node: mean squared error to the node mean</p></li>
</ul>
</div>
<div class="admonition-idea admonition">
<p class="admonition-title">Idea</p>
<p>A decision tree learns a sequence of questions like <code class="docutils literal notranslate"><span class="pre">MolWt</span> <span class="pre">&lt;=</span> <span class="pre">200.5</span></code>. Each split aims to make child nodes purer.</p>
</div>
<ul class="simple">
<li><p><strong>Regression tree</strong> chooses splits that reduce <strong>MSE</strong> the most. A leaf predicts the <strong>mean</strong> of training <code class="docutils literal notranslate"><span class="pre">y</span></code> within that leaf.</p></li>
<li><p><strong>Classification tree</strong> chooses splits that reduce <strong>Gini</strong> or <strong>entropy</strong>. A leaf predicts the <strong>majority class</strong> and class probabilities.</p></li>
</ul>
<p>Key hyperparameters you will tune frequently:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code> - maximum levels of splits</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> - minimum samples required to attempt a split</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> - minimum samples allowed in a leaf</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_features</span></code> - number of features to consider when finding the best split</p></li>
</ul>
<p>Trees handle different feature scales naturally, and they do not require standardization. They can struggle with high noise and very small datasets if left unconstrained.</p>
<div class="admonition-vocabulary admonition">
<p class="admonition-title">Vocabulary</p>
<ul class="simple">
<li><p><strong>Node</strong> is a point where a question is asked.</p></li>
<li><p><strong>Leaf</strong> holds a simple prediction.</p></li>
<li><p><strong>Impurity</strong> is a measure of how mixed a node is. Lower is better.</p></li>
</ul>
<blockquote>
<div><p>For regression, impurity at a node is measured by mean squared error to the node mean.
For classification, it is measured by <strong>Gini</strong> for a node with class probs or <strong>Entropy</strong>.</p>
</div></blockquote>
</div>
</section>
<hr class="docutils" />
<section id="tiny-classification-example-one-split">
<h3>1.3 Tiny classification example: one split<a class="headerlink" href="#tiny-classification-example-one-split" title="Permalink to this heading">#</a></h3>
<p>We start with toxicity as a binary label to see a single split and the data shape at each step.</p>
<p>We will split the dataset into train and test parts. Stratification (<code class="docutils literal notranslate"><span class="pre">stratify</span> <span class="pre">=</span> <span class="pre">y</span></code>) keeps the class ratio similar in both parts, which is important when classes are imbalanced.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_clf</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">,</span> <span class="s2">&quot;Toxicity&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;toxic&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;non_toxic&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[</span><span class="s2">&quot;Toxicity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(460, 4)
</pre></div>
</div>
</div>
</div>
<p>As you remember, we have total 575 data points and 80% goes to training samples.</p>
<p>You can glance at the first few rows to get a feel for the feature scales. Trees do not require scaling, but it is still useful context.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MolWt</th>
      <th>LogP</th>
      <th>TPSA</th>
      <th>NumRings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>275</th>
      <td>309.162</td>
      <td>4.8137</td>
      <td>17.07</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>411</th>
      <td>126.203</td>
      <td>1.9771</td>
      <td>24.72</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>328</th>
      <td>195.221</td>
      <td>2.8936</td>
      <td>32.59</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>444</th>
      <td>272.282</td>
      <td>-0.8694</td>
      <td>109.93</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>99.133</td>
      <td>0.2386</td>
      <td>20.31</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We will grow a stump: a tree with <code class="docutils literal notranslate"><span class="pre">max_depth=1</span></code>. This forces one split. It helps you see how a split is chosen and how samples are divided.</p>
<div class="admonition-stump admonition">
<p class="admonition-title">Stump</p>
<p>The tree considers possible thresholds on each feature.
For each candidate threshold it computes an impurity score on the left and right child nodes. We use Gini impurity, which gets smaller when a node contains mostly one class.
It picks the feature and threshold that bring the largest impurity decrease.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stump</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;gini&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">stump</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature used at root:&quot;</span><span class="p">,</span> <span class="n">stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Threshold at root:&quot;</span><span class="p">,</span> <span class="n">stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;n_nodes:&quot;</span><span class="p">,</span> <span class="n">stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">node_count</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;children_left:&quot;</span><span class="p">,</span> <span class="n">stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;children_right:&quot;</span><span class="p">,</span> <span class="n">stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature used at root: 0
Threshold at root: 134.1999969482422
n_nodes: 3
children_left: [ 1 -1 -1]
children_right: [ 2 -1 -1]
</pre></div>
</div>
</div>
</div>
<p>The model stores feature indices internally. Mapping that index back to the column name makes the split human readable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Map index to name for readability</span>
<span class="n">feat_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">root_feat</span> <span class="o">=</span> <span class="n">feat_names</span><span class="p">[</span><span class="n">stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">thr</span> <span class="o">=</span> <span class="n">stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Root rule: </span><span class="si">{</span><span class="n">root_feat</span><span class="si">}</span><span class="s2"> &lt;= </span><span class="si">{</span><span class="n">thr</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">?&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Root rule: MolWt &lt;= 134.200?
</pre></div>
</div>
</div>
</div>
<p>Read the rule as: if the condition is true, the sample goes to the left leaf, otherwise to the right leaf.</p>
<div class="admonition-how-good-is-one-split admonition">
<p class="admonition-title">How good is one split</p>
<p>A single split is intentionally simple. It may already capture a strong signal if one feature provides a clean separation. We will check test performance with standard metrics.</p>
<blockquote>
<div><p>Precision of class k: among items predicted as k, how many were truly k
Recall of class k: among true items of k, how many did we catch
F1 is the harmonic mean of precision and recall
Support is the number of true samples for each class
It picks the feature and threshold that bring the largest impurity decrease.</p>
</div></blockquote>
</div>
<p>Use the confusion matrix to see the error pattern.</p>
<p>In this case:
<code class="docutils literal notranslate"><span class="pre">FP</span></code> are non toxic predicted as toxic
<code class="docutils literal notranslate"><span class="pre">FN</span></code> are toxic predicted as non toxic</p>
<p>Which side is larger tells you which type of mistake the one split is making more often.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate stump</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">stump</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">cm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0      0.824     0.700     0.757        20
           1      0.939     0.968     0.953        95

    accuracy                          0.922       115
   macro avg      0.881     0.834     0.855       115
weighted avg      0.919     0.922     0.919       115
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[14,  6],
       [ 3, 92]], dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="admonition-exercise-1-3 admonition">
<p class="admonition-title">⏰ <strong>Exercise 1.3</strong></p>
<p>Refit the stump with <code class="docutils literal notranslate"><span class="pre">criterion=&quot;entropy&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">max_depth=1</span></code>, then print the root rule again. Compare precision, recall, F1, and the confusion matrix to the Gini stump.</p>
</div>
<p>Now, let’s visualize the rule.
The tree plot below shows the root node with its split, the Gini impurity at each node, the sample counts, and the class distribution. Filled colors hint at the majority class in each leaf.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize stump</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">stump</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feat_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non_toxic&quot;</span><span class="p">,</span><span class="s2">&quot;toxic&quot;</span><span class="p">],</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">impurity</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/aa580231161c4f63823ebb434ef1e0bf044aca624b6258121483da790dd5199a.png" src="_images/aa580231161c4f63823ebb434ef1e0bf044aca624b6258121483da790dd5199a.png" />
</div>
</div>
<p>We can also visualize <code class="docutils literal notranslate"><span class="pre">max_depth=2</span></code> to see the difference:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stump2</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;gini&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">stump2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">stump2</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feat_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non_toxic&quot;</span><span class="p">,</span><span class="s2">&quot;toxic&quot;</span><span class="p">],</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">impurity</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6bb4dc11fb5888c4a5e8867363dba28d9eadf1d5a4950624aa7f243f8bbf05e1.png" src="_images/6bb4dc11fb5888c4a5e8867363dba28d9eadf1d5a4950624aa7f243f8bbf05e1.png" />
</div>
</div>
</section>
<hr class="docutils" />
<section id="grow-deeper-and-control-overfitting">
<h3>1.4 Grow deeper and control overfitting<a class="headerlink" href="#grow-deeper-and-control-overfitting" title="Permalink to this heading">#</a></h3>
<p>Trees can fit noise if we let them grow without limits. We control growth using a few simple knobs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: limit the number of levels</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>: a node needs at least this many samples to split</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>: each leaf must have at least this many samples</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fit_eval_tree</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span>
        <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_leaf</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">clf</span><span class="p">,</span> <span class="n">acc</span>

<span class="n">depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>  <span class="c1"># None means grow until pure or exhausted</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">fit_eval_tree</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">min_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">],</span> <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="mi">3</span><span class="p">)})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>max_depth</th>
      <th>Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.922</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0.957</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0.948</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0.948</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0.948</td>
    </tr>
    <tr>
      <th>5</th>
      <td>None</td>
      <td>0.930</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here, we hold <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span> <span class="pre">=</span> <span class="pre">3</span></code> and vary <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>. This shows the classic underfit to overfit trend.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">],</span> <span class="n">scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;max_depth&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy (test)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Tree depth vs test accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4e552473274e3e204efaa01f85a459fdb32cebdfb57ee306c38bd1f9db2730b5.png" src="_images/4e552473274e3e204efaa01f85a459fdb32cebdfb57ee306c38bd1f9db2730b5.png" />
</div>
</div>
<div class="admonition-takeaway admonition">
<p class="admonition-title">Takeaway</p>
<p>Shallow trees underfit. Very deep trees often overfit. Start small, add depth only if validation improves.</p>
</div>
<p>Now, let’s try sweep leaf size at several depths.</p>
<p>We will try a small grid. This lets you see <strong>both</strong> knobs together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fit_acc_leaves</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span>
        <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_leaf</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">acc_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
    <span class="n">n_leaves</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">get_n_leaves</span><span class="p">()</span>  <span class="c1"># simple and reliable</span>
    <span class="k">return</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">n_leaves</span>

<span class="n">leaf_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
<span class="n">depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

<span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">leaf</span> <span class="ow">in</span> <span class="n">leaf_sizes</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
        <span class="n">acc</span><span class="p">,</span> <span class="n">leaves</span> <span class="o">=</span> <span class="n">fit_acc_leaves</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">min_leaf</span><span class="o">=</span><span class="n">leaf</span><span class="p">)</span>
        <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">:</span> <span class="n">leaf</span><span class="p">,</span>
            <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">),</span>
            <span class="s2">&quot;acc_test&quot;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span>
            <span class="s2">&quot;n_leaves&quot;</span><span class="p">:</span> <span class="n">leaves</span>
        <span class="p">})</span>

<span class="n">df_grid</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">,</span><span class="s2">&quot;max_depth&quot;</span><span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_grid</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>min_samples_leaf</th>
      <th>max_depth</th>
      <th>acc_test</th>
      <th>n_leaves</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0.921739</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>0.956522</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>0.947826</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>4</td>
      <td>0.947826</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>5</td>
      <td>0.947826</td>
      <td>18</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>None</td>
      <td>0.921739</td>
      <td>34</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3</td>
      <td>1</td>
      <td>0.921739</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>3</td>
      <td>2</td>
      <td>0.956522</td>
      <td>4</td>
    </tr>
    <tr>
      <th>8</th>
      <td>3</td>
      <td>3</td>
      <td>0.947826</td>
      <td>8</td>
    </tr>
    <tr>
      <th>9</th>
      <td>3</td>
      <td>4</td>
      <td>0.947826</td>
      <td>12</td>
    </tr>
    <tr>
      <th>10</th>
      <td>3</td>
      <td>5</td>
      <td>0.947826</td>
      <td>17</td>
    </tr>
    <tr>
      <th>11</th>
      <td>3</td>
      <td>None</td>
      <td>0.930435</td>
      <td>25</td>
    </tr>
    <tr>
      <th>12</th>
      <td>5</td>
      <td>1</td>
      <td>0.921739</td>
      <td>2</td>
    </tr>
    <tr>
      <th>13</th>
      <td>5</td>
      <td>2</td>
      <td>0.956522</td>
      <td>4</td>
    </tr>
    <tr>
      <th>14</th>
      <td>5</td>
      <td>3</td>
      <td>0.939130</td>
      <td>7</td>
    </tr>
    <tr>
      <th>15</th>
      <td>5</td>
      <td>4</td>
      <td>0.939130</td>
      <td>12</td>
    </tr>
    <tr>
      <th>16</th>
      <td>5</td>
      <td>5</td>
      <td>0.939130</td>
      <td>15</td>
    </tr>
    <tr>
      <th>17</th>
      <td>5</td>
      <td>None</td>
      <td>0.921739</td>
      <td>20</td>
    </tr>
    <tr>
      <th>18</th>
      <td>10</td>
      <td>1</td>
      <td>0.921739</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19</th>
      <td>10</td>
      <td>2</td>
      <td>0.956522</td>
      <td>4</td>
    </tr>
    <tr>
      <th>20</th>
      <td>10</td>
      <td>3</td>
      <td>0.956522</td>
      <td>6</td>
    </tr>
    <tr>
      <th>21</th>
      <td>10</td>
      <td>4</td>
      <td>0.956522</td>
      <td>9</td>
    </tr>
    <tr>
      <th>22</th>
      <td>10</td>
      <td>5</td>
      <td>0.947826</td>
      <td>11</td>
    </tr>
    <tr>
      <th>23</th>
      <td>10</td>
      <td>None</td>
      <td>0.947826</td>
      <td>13</td>
    </tr>
    <tr>
      <th>24</th>
      <td>20</td>
      <td>1</td>
      <td>0.921739</td>
      <td>2</td>
    </tr>
    <tr>
      <th>25</th>
      <td>20</td>
      <td>2</td>
      <td>0.939130</td>
      <td>4</td>
    </tr>
    <tr>
      <th>26</th>
      <td>20</td>
      <td>3</td>
      <td>0.939130</td>
      <td>6</td>
    </tr>
    <tr>
      <th>27</th>
      <td>20</td>
      <td>4</td>
      <td>0.939130</td>
      <td>8</td>
    </tr>
    <tr>
      <th>28</th>
      <td>20</td>
      <td>5</td>
      <td>0.939130</td>
      <td>9</td>
    </tr>
    <tr>
      <th>29</th>
      <td>20</td>
      <td>None</td>
      <td>0.939130</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now, we plot test accuracy vs depth for each leaf size.</p>
<p>Higher min_samples_leaf tends to smooth the curves and reduce the train minus test gap.</p>
<div class="admonition-hyperparamter admonition">
<p class="admonition-title">Hyperparamter</p>
<p>Higher <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> tends to smooth the curves and reduce the train minus test gap.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">leaf</span> <span class="ow">in</span> <span class="n">leaf_sizes</span><span class="p">:</span>
    <span class="n">sub</span> <span class="o">=</span> <span class="n">df_grid</span><span class="p">[</span><span class="n">df_grid</span><span class="p">[</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">]</span><span class="o">==</span><span class="n">leaf</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sub</span><span class="p">[</span><span class="s2">&quot;max_depth&quot;</span><span class="p">],</span> <span class="n">sub</span><span class="p">[</span><span class="s2">&quot;acc_test&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;leaf=</span><span class="si">{</span><span class="n">leaf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;max_depth&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy (test)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Depth vs test accuracy at different min_samples_leaf&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/743ce9d0c419885007d3dda811d3964124e12e7d102625687c40ee3c7a8bd132.png" src="_images/743ce9d0c419885007d3dda811d3964124e12e7d102625687c40ee3c7a8bd132.png" />
</div>
</div>
<p>Finally, let’s look at what happen if we fix depth and vary leaf size:</p>
<p>Pick a moderate depth (<code class="docutils literal notranslate"><span class="pre">4</span></code>), then look at how leaf size alone affects accuracy and model size.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fixed_depth</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">leaf</span> <span class="ow">in</span> <span class="n">leaf_sizes</span><span class="p">:</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span>
        <span class="n">max_depth</span><span class="o">=</span><span class="n">fixed_depth</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">leaf</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">:</span> <span class="n">leaf</span><span class="p">,</span>
        <span class="s2">&quot;acc_train&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span>
        <span class="s2">&quot;acc_test&quot;</span><span class="p">:</span>  <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span>  <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span>
        <span class="s2">&quot;n_nodes&quot;</span><span class="p">:</span>   <span class="n">clf</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">node_count</span><span class="p">,</span>
        <span class="s2">&quot;n_leaves&quot;</span><span class="p">:</span>  <span class="n">clf</span><span class="o">.</span><span class="n">get_n_leaves</span><span class="p">(),</span>
    <span class="p">})</span>

<span class="n">df_leaf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_leaf</span><span class="p">[[</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">,</span><span class="s2">&quot;acc_train&quot;</span><span class="p">,</span><span class="s2">&quot;acc_test&quot;</span><span class="p">,</span><span class="s2">&quot;n_nodes&quot;</span><span class="p">,</span><span class="s2">&quot;n_leaves&quot;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>min_samples_leaf</th>
      <th>acc_train</th>
      <th>acc_test</th>
      <th>n_nodes</th>
      <th>n_leaves</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.950000</td>
      <td>0.947826</td>
      <td>25</td>
      <td>13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>0.945652</td>
      <td>0.947826</td>
      <td>23</td>
      <td>12</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>0.945652</td>
      <td>0.939130</td>
      <td>23</td>
      <td>12</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10</td>
      <td>0.934783</td>
      <td>0.956522</td>
      <td>17</td>
      <td>9</td>
    </tr>
    <tr>
      <th>4</th>
      <td>20</td>
      <td>0.923913</td>
      <td>0.939130</td>
      <td>15</td>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_leaf</span><span class="p">[</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">],</span> <span class="n">df_leaf</span><span class="p">[</span><span class="s2">&quot;acc_train&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_leaf</span><span class="p">[</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">],</span> <span class="n">df_leaf</span><span class="p">[</span><span class="s2">&quot;acc_test&quot;</span><span class="p">],</span>  <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Effect of min_samples_leaf at max_depth=</span><span class="si">{</span><span class="n">fixed_depth</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6471731df3ec38f1ca199cc6b093b39a7459c59549ed5dcb50bb67aa3fdcf160.png" src="_images/6471731df3ec38f1ca199cc6b093b39a7459c59549ed5dcb50bb67aa3fdcf160.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_leaf</span><span class="p">[</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">],</span> <span class="n">df_leaf</span><span class="p">[</span><span class="s2">&quot;n_leaves&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of leaves&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model size vs min_samples_leaf at max_depth=</span><span class="si">{</span><span class="n">fixed_depth</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5a472a3b14c4d8073cc8670d06edcb7613c5e6d23dc48e8b969f2ee4ab29e93e.png" src="_images/5a472a3b14c4d8073cc8670d06edcb7613c5e6d23dc48e8b969f2ee4ab29e93e.png" />
</div>
</div>
<div class="admonition-underfitting-vs-overfitting admonition">
<p class="admonition-title">Underfitting vs. Overfitting</p>
<p>Higher <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> tends to smooth the curves and reduce the train minus test gap.</p>
<ul class="simple">
<li><p><strong>Underfitting</strong><br />
Happens when the model is too simple to capture meaningful patterns.<br />
Signs:</p>
<ul>
<li><p>Both training and test accuracy are low.</p></li>
<li><p>The decision boundary looks crude.</p></li>
<li><p>Increasing model capacity (like depth) improves results.</p></li>
</ul>
</li>
<li><p><strong>Overfitting</strong><br />
Happens when the model is too complex and memorizes noise in the training set.<br />
Signs:</p>
<ul>
<li><p>Training accuracy is very high (often near 100%).</p></li>
<li><p>Test accuracy lags behind.</p></li>
<li><p>Model has many small leaves with very few samples.</p></li>
<li><p>Predictions fluctuate wildly for minor changes in input.</p></li>
</ul>
</li>
</ul>
<p>The goal is <strong>good generalization</strong>: high performance on unseen data, not just on the training set.</p>
</div>
</section>
<hr class="docutils" />
<section id="model-based-importance-gini-importance">
<h3>1.5 Model-based importance: Gini importance<a class="headerlink" href="#model-based-importance-gini-importance" title="Permalink to this heading">#</a></h3>
<p>As we learned in lecture 6, ML models not only make predictions but also provide insight into which features were most useful.</p>
<p>There are two main ways we can measure this: <strong>Gini importance</strong> (model-based) and <strong>permutation importance</strong> (data-based). Both give us different perspectives on feature relevance.</p>
<p>When fitting a tree, each split reduces impurity (measured by Gini or entropy). A feature’s importance is computed as:</p>
<ul class="simple">
<li><p>The total decrease in impurity that results from splits on that feature</p></li>
<li><p>Normalized so that all features sum to <code class="docutils literal notranslate"><span class="pre">1</span></code></p></li>
</ul>
<p>This is fast and built-in, but it reflects <strong>how the model used the features</strong> during training. It may overstate the importance of high-cardinality or correlated features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">imp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">tree_clf</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">feat_names</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">imp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MolWt       0.601322
LogP        0.291825
TPSA        0.085734
NumRings    0.021119
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">imp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Gini importance (tree)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d97352fa4900520aa698dfac8cd7d491a68a482811d35b278978f67dd5a5cdd9.png" src="_images/d97352fa4900520aa698dfac8cd7d491a68a482811d35b278978f67dd5a5cdd9.png" />
</div>
</div>
<p>This bar chart above ranks features by how much they reduced impurity in the training process. The top feature is the one the tree found most useful for splitting. However, keep in mind this is internal to the model and may not reflect true predictive power on unseen data.</p>
</section>
<hr class="docutils" />
<section id="data-based-importance-permutation-importance">
<h3>1.6 Data-based importance: Permutation importance<a class="headerlink" href="#data-based-importance-permutation-importance" title="Permalink to this heading">#</a></h3>
<p>Permutation importance takes a different approach. Instead of looking inside the model, it asks: What happens if I scramble a feature’s values on the test set? If accuracy drops, that feature was important. If accuracy stays the same, the model did not really depend on it.</p>
<p>Steps:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Shuffle one feature column at a time in the test set.</p></li>
<li><p>Measure the drop in accuracy.</p></li>
<li><p>Repeat many times and average to reduce randomness.</p></li>
</ol>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">perm</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
    <span class="n">tree_clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
<span class="n">perm_ser</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">perm</span><span class="o">.</span><span class="n">importances_mean</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">feat_names</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>
<span class="n">perm_ser</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Permutation importance (test)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/905c4888f5d7e34b47b0df172b5232dbb2fb5222c835aadad04d30f8996ed59f.png" src="_images/905c4888f5d7e34b47b0df172b5232dbb2fb5222c835aadad04d30f8996ed59f.png" />
</div>
</div>
<p>Here, the bars show how much accuracy falls when each feature is disrupted. This provides a more honest reflection of <strong>predictive value on unseen data</strong>. Features that looked strong in Gini importance may shrink here if they were just splitting on quirks of the training set.</p>
<div class="admonition-exercise-1-6 admonition">
<p class="admonition-title">⏰ <strong>Exercise 1.6</strong></p>
<p>Compute permutation importance on the test set with <code class="docutils literal notranslate"><span class="pre">scoring=&quot;roc_auc&quot;</span></code> and again with <code class="docutils literal notranslate"><span class="pre">scoring=&quot;f1&quot;</span></code>.
Any difference?</p>
</div>
<p>When we compare the two methods, we will see the difference is:
Gini importance (tree-based):</p>
<blockquote>
<div><p>Easy to compute.
Biased toward features with many possible split points.
Reflects training behavior, not necessarily generalization.</p>
</div></blockquote>
<p>Permutation importance (test-based):</p>
<blockquote>
<div><p>More computationally expensive (requires multiple shuffles).
Directly tied to model performance on new data.
Can reveal when the model “thought” a feature was important but it doesn’t hold up in practice.</p>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="regression-trees-on-melting-point">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">2. Regression trees on Melting Point</a><a class="headerlink" href="#regression-trees-on-melting-point" title="Permalink to this heading">#</a></h2>
<p>So far we used trees for <strong>classification</strong>. Now we switch to a <strong>regression target</strong>: the <strong>melting point</strong> of molecules. The mechanics are similar, but instead of predicting a discrete class, the tree predicts a continuous value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_reg</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">,</span> <span class="s2">&quot;Melting Point&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">Xr</span> <span class="o">=</span> <span class="n">df_reg</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>
<span class="n">yr</span> <span class="o">=</span> <span class="n">df_reg</span><span class="p">[</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">]</span>

<span class="n">Xr_train</span><span class="p">,</span> <span class="n">Xr_test</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">,</span> <span class="n">yr_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">Xr</span><span class="p">,</span> <span class="n">yr</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">Xr_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">yr_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(       MolWt    LogP  TPSA  NumRings
 68   226.703  3.6870  26.3       1.0
 231  282.295  2.5255  52.6       3.0,
 68     152.1
 231    169.4
 63     247.3
 Name: Melting Point, dtype: float64)
</pre></div>
</div>
</div>
</div>
<p>Just like before, we can grow a stump (·max_depth=1·) to see a single split.
Instead of class impurity, the split criterion is reduction in variance of the target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reg_stump</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">reg_stump</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_train</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Root feature:&quot;</span><span class="p">,</span> <span class="n">Xr_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">reg_stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Root threshold:&quot;</span><span class="p">,</span> <span class="n">reg_stump</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Root feature: MolWt
Root threshold: 245.61299896240234
</pre></div>
</div>
</div>
</div>
<div class="admonition-what-can-we-learn-from-root-feature-output admonition">
<p class="admonition-title">What can we learn from Root Feature output?</p>
<p>This tells us the first cut is on <code class="docutils literal notranslate"><span class="pre">MolW</span></code>. Samples with weight below ~246 g/mol are grouped separately from heavier ones.</p>
</div>
<p>Let’s vary max_depth and track R² on the test set.
Remember:</p>
<blockquote>
<div><p>R² = 1 means perfect prediction,
R² = 0 means the model is no better than the mean.</p>
</div></blockquote>
<p>Below, we pick <code class="docutils literal notranslate"><span class="pre">depth</span> <span class="pre">=</span> <span class="pre">3</span></code>, <code class="docutils literal notranslate"><span class="pre">leaf</span> <span class="pre">size</span> <span class="pre">=</span> <span class="pre">5</span></code>. This is a good trade-off.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate shallow vs deeper</span>
<span class="n">depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">r2s</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_train</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">)</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xr_test</span><span class="p">)</span>
    <span class="n">r2s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">))</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">],</span> <span class="s2">&quot;R2_test&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">r2s</span><span class="p">,</span><span class="mi">3</span><span class="p">)})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>max_depth</th>
      <th>R2_test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.398</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0.659</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0.810</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0.809</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6</td>
      <td>0.777</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8</td>
      <td>0.765</td>
    </tr>
    <tr>
      <th>6</th>
      <td>None</td>
      <td>0.761</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">],</span> <span class="n">r2s</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;max_depth&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;R2 on test&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Regression tree depth vs R2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c5661ebfc4cadde53b3ff0a7e18365bddab508258708dd35f2cc32b9c38a496c.png" src="_images/c5661ebfc4cadde53b3ff0a7e18365bddab508258708dd35f2cc32b9c38a496c.png" />
</div>
</div>
<p>This mirrors the classification case: shallow trees underfit, very deep trees overfit.</p>
<p>Points close to the dashed line = good predictions. Scatter away from the line = errors. Here, predictions track well but show some spread at high melting points.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Diagnostics for a chosen depth</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_train</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xr_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE=</span><span class="si">{</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE=</span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R2=</span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Parity</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">yr_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yhat</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">max</span><span class="p">(</span><span class="n">yr_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">yhat</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Parity plot: tree regressor&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Residuals</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">yr_test</span> <span class="o">-</span> <span class="n">yhat</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Residual&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Residual plot: tree regressor&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MSE=566.158
MAE=17.574
R2=0.810
</pre></div>
</div>
<img alt="_images/f62cc97ed134118806294d09625d0b211bea946974f801ee412d75c06f6d5cc0.png" src="_images/f62cc97ed134118806294d09625d0b211bea946974f801ee412d75c06f6d5cc0.png" />
<img alt="_images/3f81a2f4998614863fb8eb97c86cd1125a55c104371756972907bae7b2ed5fee.png" src="_images/3f81a2f4998614863fb8eb97c86cd1125a55c104371756972907bae7b2ed5fee.png" />
</div>
</div>
<p>Similar to the example we see on the linear regression, residuals (true – predicted) should scatter around zero. If you see patterns (e.g., always underpredicting high values), the model may be biased. Here, residuals are fairly centered but not perfectly homoscedastic.</p>
<div class="admonition-exercise-2 admonition">
<p class="admonition-title">⏰ <strong>Exercise 2</strong></p>
<p>Train two regression trees with <code class="docutils literal notranslate"><span class="pre">max_depth=6</span></code> using <code class="docutils literal notranslate"><span class="pre">min_samples_leaf=5</span></code>. Report R² and MAE for both and show the two parity plots.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize a small regression tree</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">Xr_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">impurity</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">proportion</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7b02105994e78600c1bec9a9479d0cdf3e8537968711c7421947cb0a830ce525.png" src="_images/7b02105994e78600c1bec9a9479d0cdf3e8537968711c7421947cb0a830ce525.png" />
</div>
</div>
<div class="admonition-regression-tree-vs-classifier-tree admonition">
<p class="admonition-title">Regression tree vs classifier tree</p>
<p>A regression tree is structured the same as a classifier tree, but each leaf stores an <em>average target value</em> instead of a class distribution.</p>
</div>
</section>
<hr class="docutils" />
<section id="random-forest-bagging-many-trees">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">3. Random Forest: bagging many trees</a><a class="headerlink" href="#random-forest-bagging-many-trees" title="Permalink to this heading">#</a></h2>
<p>Decision trees are intuitive but unstable: a small change in data can produce a very different tree. To make trees more reliable and accurate, we use <strong>ensembles</strong> — groups of models working together. The most widely used ensemble of trees is the <strong>Random Forest</strong>.</p>
<p>Eseentially, a random forest grows <strong>many decision trees</strong>, each trained on a slightly different view of the data, and then combines their predictions:</p>
<ul class="simple">
<li><p><strong>Bootstrap sampling (bagging)</strong>:<br />
Each tree sees a different random subset of the training rows, sampled <em>with replacement</em>. About one-third of rows are left out for that tree (these are the <strong>out-of-bag samples</strong>).</p></li>
<li><p><strong>Feature subsampling</strong>:<br />
At each split, the tree does not see all features — only a random subset, controlled by <code class="docutils literal notranslate"><span class="pre">max_features</span></code>. This prevents trees from always picking the same strong predictor and encourages diversity.</p></li>
</ul>
<p>Each tree may be a weak learner, but when you <strong>average many diverse trees</strong>, the variance cancels out. This makes forests much more stable and accurate than single trees, especially on noisy data.</p>
<hr class="docutils" />
<p>Here are some helpful aspect of forests:</p>
<ul class="simple">
<li><p><strong>Single deep tree</strong> → low bias, high variance (overfit easily).</p></li>
<li><p><strong>Forest of many deep trees</strong> → still low bias, but variance shrinks when you average.</p></li>
<li><p><strong>Built-in validation</strong>: out-of-bag samples allow you to estimate performance without needing a separate validation set.</p></li>
</ul>
<p>In practice, random forests are a strong default: robust, interpretable at the feature level, and requiring little parameter tuning.</p>
<section id="classification-forest-on-toxicity">
<h3>3.1 Classification forest on toxicity<a class="headerlink" href="#classification-forest-on-toxicity" title="Permalink to this heading">#</a></h3>
<p>We now build a forest to classify molecules as toxic vs non-toxic.<br />
We set:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators=300</span></code>: number of trees.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_features=&quot;sqrt&quot;</span></code>: common heuristic for classification.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf=3</span></code>: prevent leaves with only 1 or 2 samples.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rf_clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">max_features</span><span class="o">=</span><span class="s2">&quot;sqrt&quot;</span><span class="p">,</span>
    <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>          <span class="c1"># enable OOB estimation, if you dont specify, the default RF will not give you oob</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>
<span class="n">rf_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;OOB score:&quot;</span><span class="p">,</span> <span class="n">rf_clf</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy:&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OOB score: 0.9282608695652174
Test accuracy: 0.9478260869565217
</pre></div>
</div>
</div>
</div>
<p>Here, <strong>Out-of-Bag (OOB) Score</strong> gives an internal validation accuracy, while <strong>test accuracy</strong> confirms performance on held-out data.</p>
<div class="admonition-how-the-oob-score-is-calculated admonition">
<p class="admonition-title">How the OOB score is calculated</p>
<ol class="arabic simple">
<li><p>For each training point, collect predictions only from the trees that did <strong>not</strong> see that point during training (its out-of-bag trees).</p></li>
<li><p>Aggregate those predictions (majority vote for classification, mean for regression).</p></li>
<li><p>Compare aggregated predictions against the true labels.</p></li>
<li><p>The accuracy (or R² for regression) across all training samples is the <strong>OOB score</strong>.</p></li>
</ol>
</div>
<p>Forests average over many trees, so feature importance is more reliable than from a single tree. We can view both Gini importance and permutation importance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">imp_rf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">rf_clf</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">feat_names</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>
<span class="n">imp_rf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Random Forest Gini importance&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">perm_rf</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span><span class="n">rf_clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">perm_rf</span><span class="o">.</span><span class="n">importances_mean</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">feat_names</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Random Forest permutation importance (test)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c31a4fde0f5627e5186d2438ed551bc7a93cddd7d5aa6ef22f9020a167b3daba.png" src="_images/c31a4fde0f5627e5186d2438ed551bc7a93cddd7d5aa6ef22f9020a167b3daba.png" />
<img alt="_images/fd9d84145f84cbd6a863ec3fb427d1ee435d1e10515b55ef1dc503de776a92e6.png" src="_images/fd9d84145f84cbd6a863ec3fb427d1ee435d1e10515b55ef1dc503de776a92e6.png" />
</div>
</div>
</section>
<section id="regression-forest-on-melting-point">
<h3>3.2 Regression forest on Melting Point<a class="headerlink" href="#regression-forest-on-melting-point" title="Permalink to this heading">#</a></h3>
<p>Next we apply the same idea for regression. The forest predicts a continuous value (melting point) by averaging predictions from many regression trees.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reload mp dataset so X and y are updated</span>
<span class="n">df_reg_mp</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">,</span> <span class="s2">&quot;Melting Point&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">Xr_mp</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>
<span class="n">yr_mp</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">]</span>

<span class="n">Xr_mp_train</span><span class="p">,</span> <span class="n">Xr_mp_test</span><span class="p">,</span> <span class="n">yr_mp_train</span><span class="p">,</span> <span class="n">yr_mp_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">Xr_mp</span><span class="p">,</span> <span class="n">yr_mp</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="c1"># Random Forest (mp-specific)</span>
<span class="n">rf_reg_mp</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_features</span><span class="o">=</span><span class="s2">&quot;sqrt&quot;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>
<span class="n">rf_reg_mp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_mp_train</span><span class="p">,</span> <span class="n">yr_mp_train</span><span class="p">)</span>

<span class="n">yhat_rf_mp</span> <span class="o">=</span> <span class="n">rf_reg_mp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xr_mp_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Random Forest (mp)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test R2: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">yr_mp_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat_rf_mp</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test MAE: </span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yr_mp_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat_rf_mp</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Lasso baseline (mp-specific), fixed alpha=0.1 with scaling</span>
<span class="n">lasso_reg_mp</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">lasso_reg_mp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_mp_train</span><span class="p">,</span> <span class="n">yr_mp_train</span><span class="p">)</span>

<span class="n">yhat_lasso_mp</span> <span class="o">=</span> <span class="n">lasso_reg_mp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xr_mp_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Lasso (mp, alpha=0.1)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test R2: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">yr_mp_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat_lasso_mp</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test MAE: </span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yr_mp_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat_lasso_mp</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest (mp)
Test R2: 0.730
Test MAE: 18.062

Lasso (mp, alpha=0.1)
Test R2: 0.771
Test MAE: 16.952
</pre></div>
</div>
</div>
</div>
<p>Parity and feature importance plots help check performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Parity plot for mp RF ---</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yr_mp_test</span><span class="p">,</span> <span class="n">yhat_rf_mp</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">yr_mp_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yhat_rf_mp</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">max</span><span class="p">(</span><span class="n">yr_mp_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">yhat_rf_mp</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True Melting Point&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted Melting Point&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Parity plot: Random Forest regressor (mp)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># --- Feature importance for mp RF ---</span>
<span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">rf_reg_mp</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">Xr_mp_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">sort_values</span><span class="p">()</span> \
    <span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Random Forest importance (mp regression)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Importance&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4998a59fc443323c306236ebff1ea5f6c735114e9aed476d9fc42f0905d237cb.png" src="_images/4998a59fc443323c306236ebff1ea5f6c735114e9aed476d9fc42f0905d237cb.png" />
<img alt="_images/c7acfdefd31895809c3779801ec81bf2dd38a76b4ebeb5433abc9080fd768092.png" src="_images/c7acfdefd31895809c3779801ec81bf2dd38a76b4ebeb5433abc9080fd768092.png" />
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="ensembles">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">4. Ensembles</a><a class="headerlink" href="#ensembles" title="Permalink to this heading">#</a></h2>
<p>Ensembles combine multiple models to improve stability and accuracy. Here we expand on trees with forests, simple averaging, voting, and boosting, and add <strong>visual comparisons</strong> to show their differences.</p>
<hr class="docutils" />
<section id="experiment-single-tree-vs-random-forest">
<h3>4.1 Experiment: single tree vs random forest<a class="headerlink" href="#experiment-single-tree-vs-random-forest" title="Permalink to this heading">#</a></h3>
<p>We repeat training several times with different random seeds for the train/test split. For each split:</p>
<ul class="simple">
<li><p>Fit a single unpruned tree.</p></li>
<li><p>Fit a random forest with 300 trees.</p></li>
<li><p>Record the test R² for both.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="mi">77</span><span class="p">]</span>
<span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
    <span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Xr</span><span class="p">,</span> <span class="n">yr</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
    <span class="n">r2_t</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">))</span>
    <span class="n">r2_f</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">))</span>
    <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">seed</span><span class="p">,</span> <span class="s2">&quot;Tree_R2&quot;</span><span class="p">:</span> <span class="n">r2_t</span><span class="p">,</span> <span class="s2">&quot;Forest_R2&quot;</span><span class="p">:</span> <span class="n">r2_f</span><span class="p">})</span>

<span class="n">df_cmp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">df_cmp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>seed</th>
      <th>Tree_R2</th>
      <th>Forest_R2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.710</td>
      <td>0.801</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7</td>
      <td>0.670</td>
      <td>0.794</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21</td>
      <td>0.771</td>
      <td>0.792</td>
    </tr>
    <tr>
      <th>3</th>
      <td>42</td>
      <td>0.747</td>
      <td>0.824</td>
    </tr>
    <tr>
      <th>4</th>
      <td>77</td>
      <td>0.768</td>
      <td>0.814</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_cmp</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">],</span> <span class="n">df_cmp</span><span class="p">[</span><span class="s2">&quot;Tree_R2&quot;</span><span class="p">],</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Tree&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_cmp</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">],</span> <span class="n">df_cmp</span><span class="p">[</span><span class="s2">&quot;Forest_R2&quot;</span><span class="p">],</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Forest&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;random_state&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;R2 on test&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Stability across splits&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/506bca3e8108d41270239c3758a2fb5d03fe77813bcf40ba11b7dff42172246a.png" src="_images/506bca3e8108d41270239c3758a2fb5d03fe77813bcf40ba11b7dff42172246a.png" />
</div>
</div>
<div class="admonition-why-forests-are-often-a-safe-and-strong-default-model admonition">
<p class="admonition-title">Why forests are often a safe and strong default model</p>
<ul class="simple">
<li><p><strong>Single tree</strong>: R² jumps up and down depending on the seed. Sometimes the tree performs decently, sometimes it collapses.</p></li>
<li><p><strong>Random forest</strong>: R² is consistently higher and more stable. By averaging across 300 trees trained on different bootstrap samples and feature subsets, the forest cancels out randomness.<br />
Forests trade a bit of interpretability for much more reliability.</p></li>
</ul>
</div>
</section>
<hr class="docutils" />
<section id="simple-ensembles-by-model-averaging">
<h3>4.2 Simple Ensembles by Model Averaging<a class="headerlink" href="#simple-ensembles-by-model-averaging" title="Permalink to this heading">#</a></h3>
<p>Random forests are powerful, but ensembling can be simpler. Even just <strong>averaging two different models</strong> can improve performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_train</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">)</span>
<span class="n">lin</span>  <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_train</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">)</span>

<span class="n">pred_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xr_test</span><span class="p">)</span>
<span class="n">pred_lin</span>  <span class="o">=</span> <span class="n">lin</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xr_test</span><span class="p">)</span>
<span class="n">pred_avg</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_tree</span> <span class="o">+</span> <span class="n">pred_lin</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>

<span class="n">df_avg</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;True&quot;</span><span class="p">:</span> <span class="n">yr_test</span><span class="p">,</span>
    <span class="s2">&quot;Tree&quot;</span><span class="p">:</span> <span class="n">pred_tree</span><span class="p">,</span>
    <span class="s2">&quot;Linear&quot;</span><span class="p">:</span> <span class="n">pred_lin</span><span class="p">,</span>
    <span class="s2">&quot;Average&quot;</span><span class="p">:</span> <span class="n">pred_avg</span>
<span class="p">})</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">df_avg</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>True</th>
      <th>Tree</th>
      <th>Linear</th>
      <th>Average</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>153</th>
      <td>130.4</td>
      <td>121.423000</td>
      <td>116.903234</td>
      <td>119.163117</td>
    </tr>
    <tr>
      <th>118</th>
      <td>91.5</td>
      <td>94.747826</td>
      <td>93.587419</td>
      <td>94.167622</td>
    </tr>
    <tr>
      <th>245</th>
      <td>158.9</td>
      <td>167.670370</td>
      <td>165.901961</td>
      <td>166.786166</td>
    </tr>
    <tr>
      <th>408</th>
      <td>75.0</td>
      <td>83.256790</td>
      <td>80.402677</td>
      <td>81.829734</td>
    </tr>
    <tr>
      <th>278</th>
      <td>176.1</td>
      <td>136.764865</td>
      <td>138.856393</td>
      <td>137.810629</td>
    </tr>
    <tr>
      <th>185</th>
      <td>123.8</td>
      <td>108.482258</td>
      <td>109.010862</td>
      <td>108.746560</td>
    </tr>
    <tr>
      <th>234</th>
      <td>154.3</td>
      <td>159.203571</td>
      <td>153.651410</td>
      <td>156.427490</td>
    </tr>
    <tr>
      <th>29</th>
      <td>200.3</td>
      <td>178.918750</td>
      <td>184.189243</td>
      <td>181.553997</td>
    </tr>
    <tr>
      <th>82</th>
      <td>88.1</td>
      <td>83.256790</td>
      <td>87.838467</td>
      <td>85.547628</td>
    </tr>
    <tr>
      <th>158</th>
      <td>82.6</td>
      <td>121.423000</td>
      <td>119.893550</td>
      <td>120.658275</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tree R2:&quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">pred_tree</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Linear R2:&quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">pred_lin</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Averaged R2:&quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">pred_avg</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tree R2: 0.8514902671757174
Linear R2: 0.8741026174988968
Averaged R2: 0.869699219889096
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">pred_tree</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Tree&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">pred_lin</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Linear&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">pred_avg</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Average&quot;</span><span class="p">)</span>
<span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">yr_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">pred_tree</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">pred_lin</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">max</span><span class="p">(</span><span class="n">yr_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">pred_tree</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">pred_lin</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Parity plot: Tree vs Linear vs Average&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5336108562edb5e5dcbd60fa065a99b6aefafac060fa939cadf3bbf0b7fc39cc.png" src="_images/5336108562edb5e5dcbd60fa065a99b6aefafac060fa939cadf3bbf0b7fc39cc.png" />
</div>
</div>
<div class="admonition-difference admonition">
<p class="admonition-title">Difference</p>
<ul class="simple">
<li><p><strong>Tree</strong>: captures nonlinear shapes but may overfit.</p></li>
<li><p><strong>Linear</strong>: very stable but may underfit.</p></li>
<li><p><strong>Average</strong>: balances the two, smoother than tree, more flexible than linear regression.</p></li>
</ul>
</div>
</section>
<hr class="docutils" />
<section id="simple-ensembles-by-voting">
<h3>4.3 Simple Ensembles by Voting<a class="headerlink" href="#simple-ensembles-by-voting" title="Permalink to this heading">#</a></h3>
<p>Voting is most common for classification. Each model votes for a class.</p>
<ul class="simple">
<li><p><strong>Hard voting</strong>: majority wins.</p></li>
<li><p><strong>Soft voting</strong>: average predicted probabilities.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">VotingClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>


<span class="n">vote_clf_soft</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;lr2&quot;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">11000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;rf&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;rf2&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">],</span>
    <span class="n">voting</span><span class="o">=</span><span class="s2">&quot;soft&quot;</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Soft Voting classifier accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">vote_clf_soft</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>


<span class="n">vote_clf_hard</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;lr2&quot;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">11000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;rf&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;rf2&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">],</span>
    <span class="n">voting</span><span class="o">=</span><span class="s2">&quot;hard&quot;</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hard Voting classifier accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">vote_clf_hard</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Soft Voting classifier accuracy: 0.9652173913043478
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hard Voting classifier accuracy: 0.9565217391304348
</pre></div>
</div>
</div>
</div>
<p>Compare voting against individual models:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc_lr</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="n">acc_rf</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Model&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;LogReg&quot;</span><span class="p">,</span> <span class="s2">&quot;RandomForest&quot;</span><span class="p">,</span> <span class="s2">&quot;Voting-Hard&quot;</span><span class="p">,</span> <span class="s2">&quot;Voting-Soft&quot;</span><span class="p">],</span>
    <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">acc_lr</span><span class="p">,</span> <span class="n">acc_rf</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">vote_clf_hard</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">vote_clf_soft</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))]</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>LogReg</td>
      <td>0.956522</td>
    </tr>
    <tr>
      <th>1</th>
      <td>RandomForest</td>
      <td>0.939130</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Voting-Hard</td>
      <td>0.956522</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Voting-Soft</td>
      <td>0.965217</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="admonition-difference admonition">
<p class="admonition-title">Difference</p>
<ul class="simple">
<li><p><strong>Individual models</strong>: Logistic regression handles linear patterns, SVM picks margins, random forest handles nonlinear rules.</p></li>
<li><p><strong>Voting ensemble</strong>: combines their strengths, reducing the chance of one weak model dominating.</p></li>
</ul>
</div>
</section>
<hr class="docutils" />
<section id="optional-topic-boosting-a-different-ensemble-structure">
<h3>4.4 (Optional Topic) Boosting: a different ensemble structure<a class="headerlink" href="#optional-topic-boosting-a-different-ensemble-structure" title="Permalink to this heading">#</a></h3>
<p>Boosting is sequential: each tree corrects the mistakes of the last. Sometimes it can be stronger than bagging, but needs careful tuning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="n">gb_reg</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_train</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">)</span>

<span class="n">yhat_gb</span> <span class="o">=</span> <span class="n">gb_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xr_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient Boosting R2: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat_gb</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient Boosting MAE: </span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat_gb</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Gradient Boosting R2: 0.856
Gradient Boosting MAE: 16.17
</pre></div>
</div>
</div>
</div>
<p>Compare <strong>Random Forest vs Gradient Boosting</strong> directly:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rf_reg</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_train</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">)</span>
<span class="n">yhat_rf</span> <span class="o">=</span> <span class="n">rf_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xr_test</span><span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Model&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;RandomForest&quot;</span><span class="p">,</span> <span class="s2">&quot;GradientBoosting&quot;</span><span class="p">],</span>
    <span class="s2">&quot;R2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">r2_score</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">yhat_rf</span><span class="p">),</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">yhat_gb</span><span class="p">)],</span>
    <span class="s2">&quot;MAE&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">yhat_rf</span><span class="p">),</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">yhat_gb</span><span class="p">)]</span>
<span class="p">})</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>R2</th>
      <th>MAE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>RandomForest</td>
      <td>0.826</td>
      <td>16.777</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GradientBoosting</td>
      <td>0.856</td>
      <td>16.172</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">yhat_rf</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;RandomForest&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yr_test</span><span class="p">,</span> <span class="n">yhat_gb</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;GradientBoosting&quot;</span><span class="p">)</span>
<span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">yr_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yhat_rf</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yhat_gb</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">max</span><span class="p">(</span><span class="n">yr_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">yhat_rf</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">yhat_gb</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Parity plot: RF vs GB&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3291f6ac9c1a590c202a22144ebf1d7fe0d31be8b43638b1daf782ee32d5a5c8.png" src="_images/3291f6ac9c1a590c202a22144ebf1d7fe0d31be8b43638b1daf782ee32d5a5c8.png" />
</div>
</div>
<div class="admonition-compare admonition">
<p class="admonition-title">Compare</p>
<ul class="simple">
<li><p><strong>Random forest</strong>: reduces variance by averaging many deep trees. Stable and easy to tune.</p></li>
<li><p><strong>Boosting</strong>: reduces bias by sequentially correcting mistakes. Often achieves higher accuracy but requires careful parameter tuning.</p></li>
</ul>
</div>
</section>
</section>
<hr class="docutils" />
<section id="end-to-end-recipe-for-random-forest">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">5. End-to-end recipe for random forest</a><a class="headerlink" href="#end-to-end-recipe-for-random-forest" title="Permalink to this heading">#</a></h2>
<p>Now, let’s put everything we learn for trees and forests together. Below is a standard workflow for toxicity with a forest. Similar to what we learned from last lecture but handled with RF model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1) Data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[</span><span class="s2">&quot;Toxicity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="c1"># 2) Model</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="s2">&quot;sqrt&quot;</span><span class="p">,</span>
    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 3) Evaluate</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;OOB score: </span><span class="si">{</span><span class="n">rf</span><span class="o">.</span><span class="n">oob_score_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC: </span><span class="si">{</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_proba</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OOB score: 0.939
Accuracy: 0.922
AUC: 0.955
</pre></div>
</div>
</div>
</div>
<p>In addition to just fit model with trainset using either default or pre-defined <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> and <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>, as we learned from last lecture, a more solid way will be search/tune for possible combinations of hyperparamters during the cross validation.</p>
<p>As you see below, it will take longer time to run (since it surveys 2 x 2 x 2 = 8 combinations in total and is more computationally expensive) but result in better performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">classification_report</span>

<span class="c1"># Data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[</span><span class="s2">&quot;Toxicity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="c1"># KFold CV search</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
    <span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">rf</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">best_rf</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best params:&quot;</span><span class="p">,</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best CV AUC: </span><span class="si">{</span><span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Test evaluation</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">best_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">best_rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC: </span><span class="si">{</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_proba</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best params: {&#39;max_depth&#39;: None, &#39;min_samples_leaf&#39;: 3, &#39;n_estimators&#39;: 500}
Best CV AUC: 0.972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.948
AUC: 0.982
              precision    recall  f1-score   support

           0      0.850     0.850     0.850        20
           1      0.968     0.968     0.968        95

    accuracy                          0.948       115
   macro avg      0.909     0.909     0.909       115
weighted avg      0.948     0.948     0.948       115
</pre></div>
</div>
</div>
</div>
<p>Additional plots demonstrating the performance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Confusion matrix and ROC</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Pred&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">fraction</span><span class="o">=</span><span class="mf">0.046</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.04</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thr</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;FPR&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;TPR&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5f249c91188fa5629834b0b752fdc0ec6a715206e28fa1e49a4604516a646e0d.png" src="_images/5f249c91188fa5629834b0b752fdc0ec6a715206e28fa1e49a4604516a646e0d.png" />
<img alt="_images/cdbd7af692f6733a6937cbf88414dbb543a447b8092b25a1ebae95b50edf048c.png" src="_images/cdbd7af692f6733a6937cbf88414dbb543a447b8092b25a1ebae95b50edf048c.png" />
</div>
</div>
</section>
<hr class="docutils" />
<section id="quick-reference">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">6. Quick reference</a><a class="headerlink" href="#quick-reference" title="Permalink to this heading">#</a></h2>
<div class="admonition-common-options admonition">
<p class="admonition-title">Common options</p>
<ul class="simple">
<li><p>DecisionTreeClassifier/Regressor: <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>, <code class="docutils literal notranslate"><span class="pre">criterion</span></code>, <code class="docutils literal notranslate"><span class="pre">random_state</span></code></p></li>
<li><p>RandomForestClassifier/Regressor: add <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>, <code class="docutils literal notranslate"><span class="pre">max_features</span></code>, <code class="docutils literal notranslate"><span class="pre">oob_score</span></code>, <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code></p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> for built-in importance and <code class="docutils literal notranslate"><span class="pre">permutation_importance</span></code> for model-agnostic view</p></li>
</ul>
</div>
<div class="admonition-when-to-use admonition">
<p class="admonition-title">When to use</p>
<ul class="simple">
<li><p>Tree: simple rules, quick to interpret on small depth</p></li>
<li><p>Forest: stronger accuracy, more stable, less sensitive to a single split</p></li>
</ul>
</div>
</section>
<hr class="docutils" />
<section id="in-class-activities">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">7. In-class activities</a><a class="headerlink" href="#in-class-activities" title="Permalink to this heading">#</a></h2>
<section id="tree-vs-forest-on-log-solubility">
<h3>7.1 Tree vs Forest on log-solubility<a class="headerlink" href="#tree-vs-forest-on-log-solubility" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Create <code class="docutils literal notranslate"><span class="pre">y_log</span> <span class="pre">=</span> <span class="pre">log10(Solubility_mol_per_L</span> <span class="pre">+</span> <span class="pre">1e-6)</span></code></p></li>
<li><p>Use features <code class="docutils literal notranslate"><span class="pre">[MolWt,</span> <span class="pre">LogP,</span> <span class="pre">TPSA,</span> <span class="pre">NumRings]</span></code></p></li>
<li><p>Train a <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor(max_depth=4,</span> <span class="pre">min_samples_leaf=5)</span></code> and a <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor(n_estimators=300,</span> <span class="pre">min_samples_leaf=5)</span></code></p></li>
<li><p>Report test <strong>R2</strong> for both and draw both parity plots</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TO DO</span>
</pre></div>
</div>
</section>
<section id="pruning-with-min-samples-leaf">
<h3>7.2 Pruning with <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code><a class="headerlink" href="#pruning-with-min-samples-leaf" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">max_depth=None</span></code> for <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> on toxicity</p></li>
<li><p>Sweep <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> in <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">5,</span> <span class="pre">8,</span> <span class="pre">12,</span> <span class="pre">20]</span></code></p></li>
<li><p>Plot test <strong>accuracy</strong> vs <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TO DO</span>
</pre></div>
</div>
</section>
<section id="toxicity-prediction">
<h3>7.3 Toxicity prediction<a class="headerlink" href="#toxicity-prediction" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Train a <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier(max_depth=2)</span></code> on toxicity</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">plot_tree</span></code> to draw it and write down the two split rules in plain language</p></li>
</ul>
<p>Optional:</p>
<ul class="simple">
<li><p>Train <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> with <code class="docutils literal notranslate"><span class="pre">oob_score=True</span></code> on toxicity</p></li>
<li><p>Compare OOB score to test accuracy over seeds <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">7,</span> <span class="pre">21,</span> <span class="pre">42]</span></code></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TO DO</span>
</pre></div>
</div>
</section>
<section id="feature-importance-agreement">
<h3>7.4 Feature importance agreement<a class="headerlink" href="#feature-importance-agreement" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>On melting point, compute forest <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> and <code class="docutils literal notranslate"><span class="pre">permutation_importance</span></code></p></li>
<li><p>Plot both and comment where they agree or disagree</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TO DO</span>
</pre></div>
</div>
</section>
<section id="hyperparameter-search-with-cross-validation">
<h3>7.5 Hyperparameter search with cross validation<a class="headerlink" href="#hyperparameter-search-with-cross-validation" title="Permalink to this heading">#</a></h3>
<p>Use <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> on <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> for toxicity</p>
<p>Split once into train and test as usual, but perform 5-fold CV only on the training fold</p>
<p>Search over:</p>
<p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>: [200, 400]</p>
<p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: [None, 6, 10]</p>
<p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>: [1, 2, 3, 5]</p>
<p><code class="docutils literal notranslate"><span class="pre">max_features</span></code>: [“sqrt”, 0.8]</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">scoring=&quot;roc_auc&quot;</span></code> for the CV score</p>
<p>After the search, refit the best model on the full training data</p>
<p>Report: **<strong>best params</strong>, <strong>CV AUC</strong>, <strong>test Accuracy</strong> and <strong>test AUC</strong></p>
<p>Plot ROC curve for the final model</p>
<p>Hint: This may take more than 30 s to run since it searches for quite a few hyperparameters</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TO DO</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="solutions">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">8. Solutions</a><a class="headerlink" href="#solutions" title="Permalink to this heading">#</a></h2>
<section id="q1">
<h3>Q1<a class="headerlink" href="#q1" title="Permalink to this heading">#</a></h3>
<p>Goal: predict log-solubility and compare a small tree to a forest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create target: log10(solubility + 1e-6) to avoid log(0)</span>
<span class="c1"># If your dataframe already has a numeric solubility column named &#39;Solubility_mol_per_L&#39;, reuse it.</span>
<span class="n">df_sol</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df_sol</span><span class="p">[</span><span class="s2">&quot;y_log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">df_sol</span><span class="p">[</span><span class="s2">&quot;Solubility_mol_per_L&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>

<span class="n">Xs</span> <span class="o">=</span> <span class="n">df_sol</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">df_sol</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">Xs</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;y_log&quot;</span><span class="p">]</span>

<span class="n">Xs_train</span><span class="p">,</span> <span class="n">Xs_test</span><span class="p">,</span> <span class="n">ys_train</span><span class="p">,</span> <span class="n">ys_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Models</span>
<span class="n">tree_sol</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">ys_train</span><span class="p">)</span>
<span class="n">rf_sol</span>   <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">ys_train</span><span class="p">)</span>

<span class="c1"># Scores</span>
<span class="n">yhat_tree</span> <span class="o">=</span> <span class="n">tree_sol</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">)</span>
<span class="n">yhat_rf</span>   <span class="o">=</span> <span class="n">rf_sol</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tree R2:   </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">ys_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat_tree</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Forest R2: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">ys_test</span><span class="p">,</span><span class="w"> </span><span class="n">yhat_rf</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tree R2:   0.918
Forest R2: 0.947
</pre></div>
</div>
</div>
</div>
<p>Parity plots for both models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parity for tree</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">ys_test</span><span class="p">,</span> <span class="n">yhat_tree</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">ys_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yhat_tree</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">max</span><span class="p">(</span><span class="n">ys_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">yhat_tree</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Parity plot: Tree on log-solubility&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Parity for forest</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">ys_test</span><span class="p">,</span> <span class="n">yhat_rf</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">ys_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yhat_rf</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">max</span><span class="p">(</span><span class="n">ys_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">yhat_rf</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Parity plot: Forest on log-solubility&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b4021e6de044e5d599ba82ec37d6c784ddadf6c1a733065e77e39e704bf5fe05.png" src="_images/b4021e6de044e5d599ba82ec37d6c784ddadf6c1a733065e77e39e704bf5fe05.png" />
<img alt="_images/cc267a463f51070cd50c51502be4acb69e55de9546c7323d9a0259c1f2decec1.png" src="_images/cc267a463f51070cd50c51502be4acb69e55de9546c7323d9a0259c1f2decec1.png" />
</div>
</div>
</section>
<hr class="docutils" />
<section id="q2">
<h3>Q2<a class="headerlink" href="#q2" title="Permalink to this heading">#</a></h3>
<p>Fix <code class="docutils literal notranslate"><span class="pre">max_depth=None</span></code> for a classifier on toxicity and sweep leaf size.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">leaf_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
<span class="n">accs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">leaf</span> <span class="ow">in</span> <span class="n">leaf_grid</span><span class="p">:</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">leaf</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">:</span> <span class="n">leaf_grid</span><span class="p">,</span> <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">accs</span><span class="p">,</span> <span class="mi">3</span><span class="p">)})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>min_samples_leaf</th>
      <th>Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.922</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0.930</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0.930</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>0.922</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8</td>
      <td>0.957</td>
    </tr>
    <tr>
      <th>5</th>
      <td>12</td>
      <td>0.939</td>
    </tr>
    <tr>
      <th>6</th>
      <td>20</td>
      <td>0.939</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">leaf_grid</span><span class="p">,</span> <span class="n">accs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy (test)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Pruning with min_samples_leaf&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/76d16245111186a97dfdcac57d98f856f44e09747188819fb45da0ad4671dc0d.png" src="_images/76d16245111186a97dfdcac57d98f856f44e09747188819fb45da0ad4671dc0d.png" />
</div>
</div>
<p>Hint for interpretation: very small leaves may overfit while very large leaves may underfit.</p>
</section>
<hr class="docutils" />
<section id="q3">
<h3>Q3<a class="headerlink" href="#q3" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seeds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">42</span><span class="p">]</span>
<span class="n">rows_oob</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">seeds</span><span class="p">:</span>
    <span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="s2">&quot;sqrt&quot;</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
    <span class="n">acc_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">))</span>
    <span class="n">rows_oob</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span> <span class="s2">&quot;OOB&quot;</span><span class="p">:</span> <span class="n">rf</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">,</span> <span class="s2">&quot;TestAcc&quot;</span><span class="p">:</span> <span class="n">acc_test</span><span class="p">})</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows_oob</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>seed</th>
      <th>OOB</th>
      <th>TestAcc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0.920</td>
      <td>0.965</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7</td>
      <td>0.933</td>
      <td>0.904</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21</td>
      <td>0.937</td>
      <td>0.957</td>
    </tr>
    <tr>
      <th>3</th>
      <td>42</td>
      <td>0.928</td>
      <td>0.939</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_oob</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows_oob</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_oob</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">],</span> <span class="n">df_oob</span><span class="p">[</span><span class="s2">&quot;OOB&quot;</span><span class="p">],</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;OOB&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_oob</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">],</span> <span class="n">df_oob</span><span class="p">[</span><span class="s2">&quot;TestAcc&quot;</span><span class="p">],</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;random_state&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;OOB vs Test accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d1a06ecd1d8a9de4eb127f647518b9745e044997e072d4c32883457a44fd0106.png" src="_images/d1a06ecd1d8a9de4eb127f647518b9745e044997e072d4c32883457a44fd0106.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">small_tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">small_tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feat_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non_toxic&quot;</span><span class="p">,</span><span class="s2">&quot;toxic&quot;</span><span class="p">],</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Small Decision Tree (max_depth=2)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Extract split rules programmatically for the top two levels</span>
<span class="n">feat_idx</span> <span class="o">=</span> <span class="n">small_tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span>
<span class="n">thresh</span> <span class="o">=</span> <span class="n">small_tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span>
<span class="n">left</span> <span class="o">=</span> <span class="n">small_tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span>
<span class="n">right</span> <span class="o">=</span> <span class="n">small_tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span>

<span class="k">def</span><span class="w"> </span><span class="nf">node_rule</span><span class="p">(</span><span class="n">node_id</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">feat_idx</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">thresh</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feat_names</span><span class="p">[</span><span class="n">f</span><span class="p">]</span><span class="si">}</span><span class="s2"> &lt;= </span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> ?&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Root rule:&quot;</span><span class="p">,</span> <span class="n">node_rule</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Left child rule:&quot;</span><span class="p">,</span> <span class="n">node_rule</span><span class="p">(</span><span class="n">left</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="n">left</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;Left child is a leaf&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Right child rule:&quot;</span><span class="p">,</span> <span class="n">node_rule</span><span class="p">(</span><span class="n">right</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="n">right</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;Right child is a leaf&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/397c83587ba0bf5616c9688e0c3be798f9ad8d7af89161a3f187145702bc8bc0.png" src="_images/397c83587ba0bf5616c9688e0c3be798f9ad8d7af89161a3f187145702bc8bc0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Root rule: MolWt &lt;= 134.200 ?
Left child rule: LogP &lt;= 2.538 ?
Right child rule: LogP &lt;= 1.248 ?
</pre></div>
</div>
</div>
</div>
<p>Expect OOB to track test accuracy closely. Small differences are normal.</p>
</section>
<hr class="docutils" />
<section id="q4">
<h3>Q4<a class="headerlink" href="#q4" title="Permalink to this heading">#</a></h3>
<p>Compare built-in importance to permutation importance for a random forest regressor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rf_imp</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="s2">&quot;sqrt&quot;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xr_train</span><span class="p">,</span> <span class="n">yr_train</span><span class="p">)</span>

<span class="c1"># Built-in importance</span>
<span class="n">imp_series</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">rf_imp</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">Xr_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>

<span class="c1"># Permutation importance on test</span>
<span class="n">perm_r</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
    <span class="n">rf_imp</span><span class="p">,</span> <span class="n">Xr_test</span><span class="p">,</span> <span class="n">yr_test</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;r2&quot;</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
<span class="n">perm_series</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">perm_r</span><span class="o">.</span><span class="n">importances_mean</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">Xr_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>

<span class="c1"># Plots</span>
<span class="n">imp_series</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Random Forest feature_importances_ (regression)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">perm_series</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Permutation importance on test (regression)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Built_in&quot;</span><span class="p">:</span> <span class="n">imp_series</span><span class="p">,</span> <span class="s2">&quot;Permutation&quot;</span><span class="p">:</span> <span class="n">perm_series</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d7e4c6ad5775ba61b5f849cb5ad7bfe5cba69cd5db3b4377f4cad43f6420d570.png" src="_images/d7e4c6ad5775ba61b5f849cb5ad7bfe5cba69cd5db3b4377f4cad43f6420d570.png" />
<img alt="_images/8c3f5264489fea1b411d06192d89254bc5eb1489938d39d314957f11e425b258.png" src="_images/8c3f5264489fea1b411d06192d89254bc5eb1489938d39d314957f11e425b258.png" />
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Built_in</th>
      <th>Permutation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LogP</th>
      <td>0.135308</td>
      <td>0.039454</td>
    </tr>
    <tr>
      <th>MolWt</th>
      <td>0.617161</td>
      <td>0.839382</td>
    </tr>
    <tr>
      <th>NumRings</th>
      <td>0.177916</td>
      <td>0.025688</td>
    </tr>
    <tr>
      <th>TPSA</th>
      <td>0.069615</td>
      <td>0.017808</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Look for agreement on the top features. Disagreements can signal correlation or overfitting in the training trees.</p>
</section>
<hr class="docutils" />
<section id="q5">
<h3>Q5<a class="headerlink" href="#q5" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/C_H_oxidation_dataset.csv&quot;</span>
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">desc</span> <span class="o">=</span> <span class="n">df_raw</span><span class="p">[</span><span class="s2">&quot;SMILES&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">calc_descriptors</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_raw</span><span class="p">,</span> <span class="n">desc</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># 2) Build classification frame and clean</span>
<span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;toxic&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;non_toxic&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">df_clf</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">,</span> <span class="s2">&quot;Toxicity&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">df_clf</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[</span><span class="n">df_clf</span><span class="p">[</span><span class="s2">&quot;Toxicity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">label_map</span><span class="o">.</span><span class="n">keys</span><span class="p">())]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_clf</span><span class="p">[</span><span class="s2">&quot;Toxicity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Guard against degenerate stratify cases</span>
<span class="k">assert</span> <span class="n">y</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;Need both classes for stratified split&quot;</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="c1"># 3) CV setup and grid</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">400</span><span class="p">],</span>
    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
    <span class="s2">&quot;max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;sqrt&quot;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">rf_base</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">rf_base</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># 4) Fit and report</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best params:&quot;</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best CV AUC: </span><span class="si">{</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">rf_best</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_estimator_</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">rf_best</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">rf_best</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test AUC: </span><span class="si">{</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_proba</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 5) ROC curve</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thr</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;FPR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;TPR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC curve - RF with CV-tuned hyperparameters&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best params: {&#39;max_depth&#39;: 6, &#39;max_features&#39;: &#39;sqrt&#39;, &#39;min_samples_leaf&#39;: 2, &#39;n_estimators&#39;: 200}
Best CV AUC: 0.980
Test Accuracy: 0.922
Test AUC: 0.959
</pre></div>
</div>
<img alt="_images/4fda940410ac9b6487bd9445d234c9fc9c28063e632249aabfac69d2b9452c8e.png" src="_images/4fda940410ac9b6487bd9445d234c9fc9c28063e632249aabfac69d2b9452c8e.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="lecture-06.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 6 - Cross-Validation</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture-08.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 8 - Neural Networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-goals">Learning goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">0. Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree">1. Decision tree</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-data-and-build-descriptors">1.1 Load data and build descriptors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-decision-tree">1.2 What is a decision tree</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tiny-classification-example-one-split">1.3 Tiny classification example: one split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grow-deeper-and-control-overfitting">1.4 Grow deeper and control overfitting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-based-importance-gini-importance">1.5 Model-based importance: Gini importance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-based-importance-permutation-importance">1.6 Data-based importance: Permutation importance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-trees-on-melting-point">2. Regression trees on Melting Point</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-bagging-many-trees">3. Random Forest: bagging many trees</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-forest-on-toxicity">3.1 Classification forest on toxicity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-forest-on-melting-point">3.2 Regression forest on Melting Point</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ensembles">4. Ensembles</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-single-tree-vs-random-forest">4.1 Experiment: single tree vs random forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-ensembles-by-model-averaging">4.2 Simple Ensembles by Model Averaging</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-ensembles-by-voting">4.3 Simple Ensembles by Voting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-topic-boosting-a-different-ensemble-structure">4.4 (Optional Topic) Boosting: a different ensemble structure</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#end-to-end-recipe-for-random-forest">5. End-to-end recipe for random forest</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-reference">6. Quick reference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-class-activities">7. In-class activities</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tree-vs-forest-on-log-solubility">7.1 Tree vs Forest on log-solubility</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pruning-with-min-samples-leaf">7.2 Pruning with <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#toxicity-prediction">7.3 Toxicity prediction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-importance-agreement">7.4 Feature importance agreement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-search-with-cross-validation">7.5 Hyperparameter search with cross validation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions">8. Solutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q1">Q1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q2">Q2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q3">Q3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q4">Q4</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q5">Q5</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>