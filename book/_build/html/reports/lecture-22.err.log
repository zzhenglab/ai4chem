Traceback (most recent call last):
  File "c:\users\52377\appdata\local\programs\python\python38\lib\site-packages\jupyter_core\utils\__init__.py", line 154, in wrapped
    asyncio.get_running_loop()
RuntimeError: no running event loop

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\52377\appdata\local\programs\python\python38\lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "c:\users\52377\appdata\local\programs\python\python38\lib\site-packages\nbclient\client.py", line 1305, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "c:\users\52377\appdata\local\programs\python\python38\lib\site-packages\jupyter_core\utils\__init__.py", line 158, in wrapped
    return loop.run_until_complete(inner)
  File "c:\users\52377\appdata\local\programs\python\python38\lib\asyncio\base_events.py", line 616, in run_until_complete
    return future.result()
  File "c:\users\52377\appdata\local\programs\python\python38\lib\site-packages\nbclient\client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "c:\users\52377\appdata\local\programs\python\python38\lib\site-packages\nbclient\client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "c:\users\52377\appdata\local\programs\python\python38\lib\site-packages\nbclient\client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import base64


# Function to encode the image
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


# Path to your image
image_path = "NiPc_MOF_wiki.png"

# Getting the Base64 string
base64_image = encode_image(image_path)


response = client.responses.create(
    model="gpt-4.1",
    input=[
        {
            "role": "user",
            "content": [
                { "type": "input_text", "text": "what's reaction condition in this image?" },
                {
                    "type": "input_image",
                    "image_url": f"data:image/jpeg;base64,{base64_image}",
                },
            ],
        }
    ],
)

print(response.output_text)
------------------


[1;31m---------------------------------------------------------------------------[0m
[1;31mAttributeError[0m                            Traceback (most recent call last)
Cell [1;32mIn[20], line 17[0m
[0;32m     13[0m [38;5;66;03m# Getting the Base64 string[39;00m
[0;32m     14[0m base64_image [38;5;241m=[39m encode_image(image_path)
[1;32m---> 17[0m response [38;5;241m=[39m [43mclient[49m[38;5;241;43m.[39;49m[43mresponses[49m[38;5;241m.[39mcreate(
[0;32m     18[0m     model[38;5;241m=[39m[38;5;124m"[39m[38;5;124mgpt-4.1[39m[38;5;124m"[39m,
[0;32m     19[0m     [38;5;28minput[39m[38;5;241m=[39m[
[0;32m     20[0m         {
[0;32m     21[0m             [38;5;124m"[39m[38;5;124mrole[39m[38;5;124m"[39m: [38;5;124m"[39m[38;5;124muser[39m[38;5;124m"[39m,
[0;32m     22[0m             [38;5;124m"[39m[38;5;124mcontent[39m[38;5;124m"[39m: [
[0;32m     23[0m                 { [38;5;124m"[39m[38;5;124mtype[39m[38;5;124m"[39m: [38;5;124m"[39m[38;5;124minput_text[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124mtext[39m[38;5;124m"[39m: [38;5;124m"[39m[38;5;124mwhat[39m[38;5;124m'[39m[38;5;124ms reaction condition in this image?[39m[38;5;124m"[39m },
[0;32m     24[0m                 {
[0;32m     25[0m                     [38;5;124m"[39m[38;5;124mtype[39m[38;5;124m"[39m: [38;5;124m"[39m[38;5;124minput_image[39m[38;5;124m"[39m,
[0;32m     26[0m                     [38;5;124m"[39m[38;5;124mimage_url[39m[38;5;124m"[39m: [38;5;124mf[39m[38;5;124m"[39m[38;5;124mdata:image/jpeg;base64,[39m[38;5;132;01m{[39;00mbase64_image[38;5;132;01m}[39;00m[38;5;124m"[39m,
[0;32m     27[0m                 },
[0;32m     28[0m             ],
[0;32m     29[0m         }
[0;32m     30[0m     ],
[0;32m     31[0m )
[0;32m     33[0m [38;5;28mprint[39m(response[38;5;241m.[39moutput_text)

[1;31mAttributeError[0m: 'OpenAI' object has no attribute 'responses'

