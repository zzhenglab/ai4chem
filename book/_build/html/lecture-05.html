
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Lecture 5 - Regression and Classification &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lecture-05';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Lecture 6 - Cross-Validation" href="lecture-06.html" />
    <link rel="prev" title="Lecture 4 - Chemical Structure Identifier" href="lecture-04.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to CHEM 5080: AI for Chemistry
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-01.html">Lecture 1 - Python Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-02.html">Lecture 2 - Pandas and Plotting</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-03.html">Lecture 3 - SMILES and RDKit</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-04.html">Lecture 4 - Chemical Structure Identifier</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lecture 5 - Regression and Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-06.html">Lecture 6 - Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-07.html">Lecture 7 - Decision Trees and Random Forests</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-08.html">Lecture 8 - Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-09.html">Lecture 9 - Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-10.html">Lecture 10 - Property &amp; Reaction Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-11.html">Lecture 11 - Dimension Reduction for Data Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-12.html">Lecture 12 - Self-Supervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-13.html">Lecture 13 - De novo Molecule Generation</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Flecture-05.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/lecture-05.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 5 - Regression and Classification</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-goals">Learning goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-supervised-learning">1. What is supervised learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preview-and-descriptor-engineering">2. Data preview and descriptor engineering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-workflow-on-melting-point">3. Regression workflow on melting point</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-and-test-split">3.1 Train and test split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-the-data-and-train">3.2 Splitting the data and train</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-split-choice-affects-accuracy">3.3 How split choice affects accuracy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-curves">3.4 Learning curves</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-lasso-and-ridge">3.5 Regularization: Lasso and Ridge</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#another-regression-target-solubility-in-log-space">4. Another regression target: solubility in log space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-classification-toxicity">5. Binary classification: toxicity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-regression-to-classes-melting-point-bins">6. From regression to classes: melting point bins</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#macro-averaging">Macro Averaging</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-reference">8. Quick reference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">9. Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-class-activity">10. In-class activity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-two-features">10.1 Linear Regression with two features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-across-splits">10.2 Ridge across splits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pka-regression-two-ways">10.3 pKa regression two ways</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pka-to-classification">10.4 pKa to classification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">10. In-class activity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">10.1 Linear Regression with two features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">10.2 Ridge across splits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">10.3 pKa regression two ways</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">10.4 pKa to classification</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-5-regression-and-classification">
<h1>Lecture 5 - Regression and Classification<a class="headerlink" href="#lecture-5-regression-and-classification" title="Link to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#learning-goals" id="id6">Learning goals</a></p></li>
<li><p><a class="reference internal" href="#what-is-supervised-learning" id="id7">1. What is supervised learning</a></p></li>
<li><p><a class="reference internal" href="#data-preview-and-descriptor-engineering" id="id8">2. Data preview and descriptor engineering</a></p></li>
<li><p><a class="reference internal" href="#regression-workflow-on-melting-point" id="id9">3. Regression workflow on melting point</a></p></li>
<li><p><a class="reference internal" href="#another-regression-target-solubility-in-log-space" id="id10">4. Another regression target: solubility in log space</a></p></li>
<li><p><a class="reference internal" href="#binary-classification-toxicity" id="id11">5. Binary classification: toxicity</a></p></li>
<li><p><a class="reference internal" href="#from-regression-to-classes-melting-point-bins" id="id12">6. From regression to classes: melting point bins</a></p></li>
<li><p><a class="reference internal" href="#quick-reference" id="id13">8. Quick reference</a></p></li>
<li><p><a class="reference internal" href="#glossary" id="id14">9. Glossary</a></p></li>
<li><p><a class="reference internal" href="#in-class-activity" id="id15">10. In-class activity</a></p></li>
<li><p><a class="reference internal" href="#id1" id="id16">10. In-class activity</a></p></li>
</ul>
</nav>
<section id="learning-goals">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Learning goals</a><a class="headerlink" href="#learning-goals" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Tell classification from regression by the target type.</p></li>
<li><p>Load small chemistry-like datasets with SMILES and simple text features.</p></li>
<li><p>Make train, validation, and test splits.</p></li>
<li><p>Fit a simple regression model and a simple classification model.</p></li>
<li><p>Read and compare common metrics in each case.
<a class="reference external" href="https://colab.research.google.com/drive/1UYUb5xw7lxDQrZYjJPixfILLrhFCYBlb?usp=sharing"><img alt="Colab" src="https://img.shields.io/badge/Open-Colab-orange" /></a></p></li>
</ul>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Commented out IPython magic to ensure Python compatibility.</span>
<span class="c1"># 0. Setup</span>
<span class="o">%</span><span class="k">pip</span> install scikit-learn pandas matplotlib

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">rdkit</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chem</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">rdkit.Chem</span><span class="w"> </span><span class="kn">import</span> <span class="n">Draw</span><span class="p">,</span> <span class="n">Descriptors</span><span class="p">,</span> <span class="n">Crippen</span><span class="p">,</span> <span class="n">rdMolDescriptors</span><span class="p">,</span> <span class="n">AllChem</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="o">%</span><span class="k">pip</span> install rdkit
        <span class="kn">from</span><span class="w"> </span><span class="nn">rdkit</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chem</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">rdkit.Chem</span><span class="w"> </span><span class="kn">import</span> <span class="n">Draw</span><span class="p">,</span> <span class="n">Descriptors</span><span class="p">,</span> <span class="n">Crippen</span><span class="p">,</span> <span class="n">rdMolDescriptors</span><span class="p">,</span> <span class="n">AllChem</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RDKit is not available in this environment. Drawing and descriptors will be skipped.&quot;</span><span class="p">)</span>
        <span class="n">Chem</span> <span class="o">=</span> <span class="kc">None</span>


<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;X does not have valid feature names&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;X has feature names&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: scikit-learn in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (1.7.1)
Requirement already satisfied: pandas in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (2.3.1)
Requirement already satisfied: matplotlib in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (3.10.3)
Requirement already satisfied: numpy&gt;=1.22.0 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from scikit-learn) (2.3.2)
Requirement already satisfied: scipy&gt;=1.8.0 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from scikit-learn) (1.16.1)
Requirement already satisfied: joblib&gt;=1.2.0 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from scikit-learn) (1.5.2)
Requirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from scikit-learn) (3.6.0)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from pandas) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from pandas) (2025.2)
Requirement already satisfied: contourpy&gt;=1.0.1 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from matplotlib) (1.3.3)
Requirement already satisfied: cycler&gt;=0.10 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from matplotlib) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from matplotlib) (4.59.0)
Requirement already satisfied: kiwisolver&gt;=1.3.1 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from matplotlib) (1.4.8)
Requirement already satisfied: packaging&gt;=20.0 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from matplotlib) (25.0)
Requirement already satisfied: pillow&gt;=8 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from matplotlib) (11.3.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from matplotlib) (3.2.3)
Requirement already satisfied: six&gt;=1.5 in c:\users\52377\appdata\local\programs\python\python313\lib\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[notice] A new release of pip is available: 25.1.1 -&gt; 25.2
[notice] To update, run: python.exe -m pip install --upgrade pip
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="what-is-supervised-learning">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">1. What is supervised learning</a><a class="headerlink" href="#what-is-supervised-learning" title="Link to this heading">#</a></h2>
<div class="admonition-definition admonition">
<p class="admonition-title">Definition</p>
<ul class="simple">
<li><p><strong>Inputs</strong> <code class="docutils literal notranslate"><span class="pre">X</span></code> are the observed features for each sample.</p></li>
<li><p><strong>Target</strong> <code class="docutils literal notranslate"><span class="pre">y</span></code> is the quantity you want to predict.</p></li>
<li><p><strong>Regression</strong> predicts a number. Example: a boiling point <code class="docutils literal notranslate"><span class="pre">300</span> <span class="pre">F</span></code>.</p></li>
<li><p><strong>Classification</strong> predicts a category. Example: <code class="docutils literal notranslate"><span class="pre">high</span></code> solubility vs <code class="docutils literal notranslate"><span class="pre">low</span></code> solubility.</p></li>
</ul>
</div>
<p>Rule of thumb:</p>
<ul class="simple">
<li><p>If <strong>y</strong> is real-valued, use regression.</p></li>
<li><p>If <strong>y</strong> is a class label, use classification.</p></li>
</ul>
</section>
<section id="data-preview-and-descriptor-engineering">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">2. Data preview and descriptor engineering</a><a class="headerlink" href="#data-preview-and-descriptor-engineering" title="Link to this heading">#</a></h2>
<p>We will read a small CSV from a public repository and compute a handful of molecular descriptors from SMILES. These lightweight features are enough to practice the full workflow.</p>
<div class="admonition-tip admonition">
<p class="admonition-title">Tip</p>
<p>Descriptors such as <strong>molecular weight</strong>, <strong>logP</strong>, <strong>TPSA</strong>, and <strong>ring count</strong> are simple to compute and often serve as a first baseline for structure-property relationships.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Quick peek at the two datasets</span>
<span class="n">df_oxidation_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/zzhenglab/ai4chem/main/book/_data/C_H_oxidation_dataset.csv&quot;</span><span class="p">)</span>
<span class="n">df_oxidation_raw</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Compound Name</th>
      <th>CAS</th>
      <th>SMILES</th>
      <th>Solubility_mol_per_L</th>
      <th>pKa</th>
      <th>Toxicity</th>
      <th>Melting Point</th>
      <th>Reactivity</th>
      <th>Oxidation Site</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3,4-dihydro-1H-isochromene</td>
      <td>493-05-0</td>
      <td>c1ccc2c(c1)CCOC2</td>
      <td>0.103906</td>
      <td>5.80</td>
      <td>non_toxic</td>
      <td>65.8</td>
      <td>1</td>
      <td>8,10</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9H-fluorene</td>
      <td>86-73-7</td>
      <td>c1ccc2c(c1)Cc1ccccc1-2</td>
      <td>0.010460</td>
      <td>5.82</td>
      <td>toxic</td>
      <td>90.0</td>
      <td>1</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1,2,3,4-tetrahydronaphthalene</td>
      <td>119-64-2</td>
      <td>c1ccc2c(c1)CCCC2</td>
      <td>0.020589</td>
      <td>5.74</td>
      <td>toxic</td>
      <td>69.4</td>
      <td>1</td>
      <td>7,10</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ethylbenzene</td>
      <td>100-41-4</td>
      <td>CCc1ccccc1</td>
      <td>0.048107</td>
      <td>5.87</td>
      <td>non_toxic</td>
      <td>65.0</td>
      <td>1</td>
      <td>1,2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>cyclohexene</td>
      <td>110-83-8</td>
      <td>C1=CCCCC1</td>
      <td>0.060688</td>
      <td>5.66</td>
      <td>non_toxic</td>
      <td>96.4</td>
      <td>1</td>
      <td>3,6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>570</th>
      <td>2-naphthalen-2-ylpropan-2-amine</td>
      <td>90299-04-0</td>
      <td>CC(C)(N)c1ccc2ccccc2c1</td>
      <td>0.018990</td>
      <td>10.04</td>
      <td>toxic</td>
      <td>121.5</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>571</th>
      <td>1-bromo-4-(methylamino)anthracene-9,10-dione</td>
      <td>128-93-8</td>
      <td>CNc1ccc(Br)c2c1C(=O)c1ccccc1C2=O</td>
      <td>0.021590</td>
      <td>7.81</td>
      <td>toxic</td>
      <td>154.0</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>572</th>
      <td>1-[6-(dimethylamino)naphthalen-2-yl]prop-2-en-...</td>
      <td>86636-92-2</td>
      <td>C=CC(=O)c1ccc2cc(N(C)C)ccc2c1</td>
      <td>0.017866</td>
      <td>8.58</td>
      <td>toxic</td>
      <td>128.3</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>573</th>
      <td>1,2-dimethoxy-12-methyl-[1,3]benzodioxolo[5,6-...</td>
      <td>34316-15-9</td>
      <td>COc1ccc2c(c[n+](C)c3c4cc5c(cc4ccc23)OCO5)c1OC</td>
      <td>0.016210</td>
      <td>5.54</td>
      <td>toxic</td>
      <td>215.6</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>574</th>
      <td>dimethyl anthracene-1,8-dicarboxylate</td>
      <td>93655-34-6</td>
      <td>COC(=O)c1cccc2cc3cccc(C(=O)OC)c3cc12</td>
      <td>0.016761</td>
      <td>5.43</td>
      <td>toxic</td>
      <td>175.3</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
  </tbody>
</table>
<p>575 rows × 9 columns</p>
</div></div></div>
</div>
<div class="admonition-think-pair-share admonition">
<p class="admonition-title">Think-pair-share</p>
<p>⏰
<strong>Exercise 1.1</strong></p>
<p>Which column(s) can be target <strong>y</strong>?</p>
<p>Which are regression tasks and which are classification tasks?</p>
</div>
<p>Recall from last week that we can use SMILES to introduce additional descriptors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">calc_descriptors</span><span class="p">(</span><span class="n">smiles</span><span class="p">):</span>
    <span class="n">mol</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mol</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span>
            <span class="s2">&quot;MolWt&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;LogP&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;TPSA&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;NumRings&quot;</span><span class="p">:</span> <span class="kc">None</span>
        <span class="p">})</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span>
        <span class="s2">&quot;MolWt&quot;</span><span class="p">:</span> <span class="n">Descriptors</span><span class="o">.</span><span class="n">MolWt</span><span class="p">(</span><span class="n">mol</span><span class="p">),</span>                    <span class="c1"># molecular weight</span>
        <span class="s2">&quot;LogP&quot;</span><span class="p">:</span> <span class="n">Crippen</span><span class="o">.</span><span class="n">MolLogP</span><span class="p">(</span><span class="n">mol</span><span class="p">),</span>                       <span class="c1"># octanol-water logP</span>
        <span class="s2">&quot;TPSA&quot;</span><span class="p">:</span> <span class="n">rdMolDescriptors</span><span class="o">.</span><span class="n">CalcTPSA</span><span class="p">(</span><span class="n">mol</span><span class="p">),</span>             <span class="c1"># topological polar surface area</span>
        <span class="s2">&quot;NumRings&quot;</span><span class="p">:</span> <span class="n">rdMolDescriptors</span><span class="o">.</span><span class="n">CalcNumRings</span><span class="p">(</span><span class="n">mol</span><span class="p">)</span>      <span class="c1"># number of rings</span>
    <span class="p">})</span>

<span class="c1"># Apply the function to the SMILES column</span>
<span class="n">desc_df</span> <span class="o">=</span> <span class="n">df_oxidation_raw</span><span class="p">[</span><span class="s2">&quot;SMILES&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">calc_descriptors</span><span class="p">)</span>

<span class="c1"># Concatenate new descriptor columns to original DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_oxidation_raw</span><span class="p">,</span> <span class="n">desc_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Compound Name</th>
      <th>CAS</th>
      <th>SMILES</th>
      <th>Solubility_mol_per_L</th>
      <th>pKa</th>
      <th>Toxicity</th>
      <th>Melting Point</th>
      <th>Reactivity</th>
      <th>Oxidation Site</th>
      <th>MolWt</th>
      <th>LogP</th>
      <th>TPSA</th>
      <th>NumRings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3,4-dihydro-1H-isochromene</td>
      <td>493-05-0</td>
      <td>c1ccc2c(c1)CCOC2</td>
      <td>0.103906</td>
      <td>5.80</td>
      <td>non_toxic</td>
      <td>65.8</td>
      <td>1</td>
      <td>8,10</td>
      <td>134.178</td>
      <td>1.7593</td>
      <td>9.23</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9H-fluorene</td>
      <td>86-73-7</td>
      <td>c1ccc2c(c1)Cc1ccccc1-2</td>
      <td>0.010460</td>
      <td>5.82</td>
      <td>toxic</td>
      <td>90.0</td>
      <td>1</td>
      <td>7</td>
      <td>166.223</td>
      <td>3.2578</td>
      <td>0.00</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1,2,3,4-tetrahydronaphthalene</td>
      <td>119-64-2</td>
      <td>c1ccc2c(c1)CCCC2</td>
      <td>0.020589</td>
      <td>5.74</td>
      <td>toxic</td>
      <td>69.4</td>
      <td>1</td>
      <td>7,10</td>
      <td>132.206</td>
      <td>2.5654</td>
      <td>0.00</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ethylbenzene</td>
      <td>100-41-4</td>
      <td>CCc1ccccc1</td>
      <td>0.048107</td>
      <td>5.87</td>
      <td>non_toxic</td>
      <td>65.0</td>
      <td>1</td>
      <td>1,2</td>
      <td>106.168</td>
      <td>2.2490</td>
      <td>0.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>cyclohexene</td>
      <td>110-83-8</td>
      <td>C1=CCCCC1</td>
      <td>0.060688</td>
      <td>5.66</td>
      <td>non_toxic</td>
      <td>96.4</td>
      <td>1</td>
      <td>3,6</td>
      <td>82.146</td>
      <td>2.1166</td>
      <td>0.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>570</th>
      <td>2-naphthalen-2-ylpropan-2-amine</td>
      <td>90299-04-0</td>
      <td>CC(C)(N)c1ccc2ccccc2c1</td>
      <td>0.018990</td>
      <td>10.04</td>
      <td>toxic</td>
      <td>121.5</td>
      <td>-1</td>
      <td>-1</td>
      <td>185.270</td>
      <td>3.0336</td>
      <td>26.02</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>571</th>
      <td>1-bromo-4-(methylamino)anthracene-9,10-dione</td>
      <td>128-93-8</td>
      <td>CNc1ccc(Br)c2c1C(=O)c1ccccc1C2=O</td>
      <td>0.021590</td>
      <td>7.81</td>
      <td>toxic</td>
      <td>154.0</td>
      <td>-1</td>
      <td>-1</td>
      <td>316.154</td>
      <td>3.2662</td>
      <td>46.17</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>572</th>
      <td>1-[6-(dimethylamino)naphthalen-2-yl]prop-2-en-...</td>
      <td>86636-92-2</td>
      <td>C=CC(=O)c1ccc2cc(N(C)C)ccc2c1</td>
      <td>0.017866</td>
      <td>8.58</td>
      <td>toxic</td>
      <td>128.3</td>
      <td>-1</td>
      <td>-1</td>
      <td>225.291</td>
      <td>3.2745</td>
      <td>20.31</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>573</th>
      <td>1,2-dimethoxy-12-methyl-[1,3]benzodioxolo[5,6-...</td>
      <td>34316-15-9</td>
      <td>COc1ccc2c(c[n+](C)c3c4cc5c(cc4ccc23)OCO5)c1OC</td>
      <td>0.016210</td>
      <td>5.54</td>
      <td>toxic</td>
      <td>215.6</td>
      <td>-1</td>
      <td>-1</td>
      <td>348.378</td>
      <td>3.7166</td>
      <td>40.80</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>574</th>
      <td>dimethyl anthracene-1,8-dicarboxylate</td>
      <td>93655-34-6</td>
      <td>COC(=O)c1cccc2cc3cccc(C(=O)OC)c3cc12</td>
      <td>0.016761</td>
      <td>5.43</td>
      <td>toxic</td>
      <td>175.3</td>
      <td>-1</td>
      <td>-1</td>
      <td>294.306</td>
      <td>3.5662</td>
      <td>52.60</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
<p>575 rows × 13 columns</p>
</div></div></div>
</div>
</section>
<hr class="docutils" />
<section id="regression-workflow-on-melting-point">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">3. Regression workflow on melting point</a><a class="headerlink" href="#regression-workflow-on-melting-point" title="Link to this heading">#</a></h2>
<p>We start with a single property, the <strong>Melting Point</strong>, and use four descriptors as features.</p>
<p>Now let’s first look at regression, we will focus one property prediction at a time. first create a new df”””</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_reg_mp</span> <span class="o">=</span><span class="n">df</span><span class="p">[[</span><span class="s2">&quot;Compound Name&quot;</span><span class="p">,</span> <span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">,</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">]]</span>
<span class="n">df_reg_mp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Compound Name</th>
      <th>MolWt</th>
      <th>LogP</th>
      <th>TPSA</th>
      <th>NumRings</th>
      <th>Melting Point</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3,4-dihydro-1H-isochromene</td>
      <td>134.178</td>
      <td>1.7593</td>
      <td>9.23</td>
      <td>2.0</td>
      <td>65.8</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9H-fluorene</td>
      <td>166.223</td>
      <td>3.2578</td>
      <td>0.00</td>
      <td>3.0</td>
      <td>90.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1,2,3,4-tetrahydronaphthalene</td>
      <td>132.206</td>
      <td>2.5654</td>
      <td>0.00</td>
      <td>2.0</td>
      <td>69.4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ethylbenzene</td>
      <td>106.168</td>
      <td>2.2490</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>65.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>cyclohexene</td>
      <td>82.146</td>
      <td>2.1166</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>96.4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>570</th>
      <td>2-naphthalen-2-ylpropan-2-amine</td>
      <td>185.270</td>
      <td>3.0336</td>
      <td>26.02</td>
      <td>2.0</td>
      <td>121.5</td>
    </tr>
    <tr>
      <th>571</th>
      <td>1-bromo-4-(methylamino)anthracene-9,10-dione</td>
      <td>316.154</td>
      <td>3.2662</td>
      <td>46.17</td>
      <td>3.0</td>
      <td>154.0</td>
    </tr>
    <tr>
      <th>572</th>
      <td>1-[6-(dimethylamino)naphthalen-2-yl]prop-2-en-...</td>
      <td>225.291</td>
      <td>3.2745</td>
      <td>20.31</td>
      <td>2.0</td>
      <td>128.3</td>
    </tr>
    <tr>
      <th>573</th>
      <td>1,2-dimethoxy-12-methyl-[1,3]benzodioxolo[5,6-...</td>
      <td>348.378</td>
      <td>3.7166</td>
      <td>40.80</td>
      <td>5.0</td>
      <td>215.6</td>
    </tr>
    <tr>
      <th>574</th>
      <td>dimethyl anthracene-1,8-dicarboxylate</td>
      <td>294.306</td>
      <td>3.5662</td>
      <td>52.60</td>
      <td>3.0</td>
      <td>175.3</td>
    </tr>
  </tbody>
</table>
<p>575 rows × 6 columns</p>
</div></div></div>
</div>
<section id="train-and-test-split">
<h3>3.1 Train and test split<a class="headerlink" href="#train-and-test-split" title="Link to this heading">#</a></h3>
<div class="admonition-why-split admonition">
<p class="admonition-title">Why split?</p>
<p>We test on <strong>held-out</strong> data to estimate generalization. A common split is 80 percent train, 20 percent test with a fixed <code class="docutils literal notranslate"><span class="pre">random_state</span></code> for reproducibility.</p>
</div>
</section>
<section id="splitting-the-data-and-train">
<h3>3.2 Splitting the data and train<a class="headerlink" href="#splitting-the-data-and-train" title="Link to this heading">#</a></h3>
<p>Before training, we need to separate the input features (<code class="docutils literal notranslate"><span class="pre">X</span></code>) from the target (<code class="docutils literal notranslate"><span class="pre">y</span></code>). Then we split into training and test sets to evaluate how well the model generalizes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Define X (features) and y (target)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">]</span>

<span class="c1"># Split into train (80%) and test (20%) sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span>

<span class="n">X_train</span>

<span class="n">y_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>68     152.1
231    169.4
63     247.3
436    160.0
60     127.8
       ...  
71     126.6
106    125.3
270    207.8
435    157.9
102     57.5
Name: Melting Point, Length: 460, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="admonition-visual-check admonition">
<p class="admonition-title">Visual check</p>
<p>Scatter the training and test points for one descriptor vs the target to see coverage. This is a quick check for weird splits or narrow ranges.</p>
</div>
<p>Since we have 575 rows in total, we splited it into 460 train + 115 test and these are shuffled.</p>
<p>It’s often useful to check how the training and test sets are distributed. Here we’ll do a scatter plot of one descriptor (say <code class="docutils literal notranslate"><span class="pre">MolWt</span></code>) against the target (<code class="docutils literal notranslate"><span class="pre">Melting</span> <span class="pre">Point</span></code>) and color by train/test.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Plot training vs test data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">],</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">],</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Molecular Weight (MolWt)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Train vs Test Data Split&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/015c424d4fe957baf8c665a4b237c367c10e6296db16a1e97eb169c77ffa0c7c.png" src="_images/015c424d4fe957baf8c665a4b237c367c10e6296db16a1e97eb169c77ffa0c7c.png" />
</div>
</div>
<p>Blue points are the training set and red points are the test set. We can see that the split looks balanced and the test set covers a different range of values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize model</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># Fit to training data</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict on test set</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate performance</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MSE: 374.56773278929023
MAE: 15.316390819320326
R2: 0.8741026174988968
</pre></div>
</div>
</div>
</div>
<p>Below are metrics, with formulas:</p>
<ul>
<li><p><strong>Mean Squared Error (MSE):</strong><br />
<span class="math notranslate nohighlight">\(
\text{MSE} = \frac{1}{n}\sum_{i=1}^{n} (y_i - \hat{y}_i)^2
  \)</span></p>
<p>Squared differences; penalizes large errors heavily.</p>
</li>
<li><p><strong>Mean Absolute Error (MAE):</strong><br />
<span class="math notranslate nohighlight">\(
\text{MAE} = \frac{1}{n}\sum_{i=1}^{n} |y_i - \hat{y}_i|
 \)</span><br />
Easier to interpret; average magnitude of errors.</p></li>
<li><p><strong>R² (Coefficient of Determination):</strong><br />
<span class="math notranslate nohighlight">\(
R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}
 \)</span><br />
Measures proportion of variance explained by the model.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( R^2 = 1 \)</span> : perfect prediction</p></li>
<li><p><span class="math notranslate nohighlight">\( R^2 = 0 \)</span> : model is no better than mean</p></li>
<li><p><span class="math notranslate nohighlight">\( R^2 &lt; 0 \)</span> : worse than predicting the average</p></li>
</ul>
</li>
</ul>
<p>⏰
<strong>Exercise 2.1</strong></p>
<p>Change the test_size=0.2 to 0.1 and random_state=42 to 7 to see any difference in resulting MSE, MAE and R2.</p>
<p>Now you can use <code class="docutils literal notranslate"><span class="pre">reg</span></code> to make predictions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Single new data point with 2 features</span>
<span class="n">X_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">135</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">9.2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span> <span class="c1"># [&quot;MolWt&quot;, &quot;LogP&quot;, &quot;TPSA&quot;, &quot;NumRings&quot;]]</span>
<span class="n">y_new_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted value:&quot;</span><span class="p">,</span> <span class="n">y_new_pred</span><span class="p">)</span>

<span class="n">Xs_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">135</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">9.2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">301</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">17.7</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">65</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span> <span class="c1"># [&quot;MolWt&quot;, &quot;LogP&quot;, &quot;TPSA&quot;, &quot;NumRings&quot;]]</span>
<span class="n">ys_new_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xs_new</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted value:&quot;</span><span class="p">,</span> <span class="n">ys_new_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted value: [86.80836978]
Predicted value: [ 86.80836978 169.99905967  53.35729424]
</pre></div>
</div>
</div>
</div>
<div class="admonition-diagnostic-plots admonition">
<p class="admonition-title">Diagnostic plots</p>
<p>A residual plot should look centered around zero without obvious patterns. A parity plot compares predicted to true values and should line up near the 45 degree line.</p>
</div>
<p>After training, we compare the predicted outputs with the true labels from the test set.</p>
<p>This allows us to verify how close the model’s predictions are to the actual values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Residual plot</span>
<span class="n">resid</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">resid</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Residual plot – Regression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Parity plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Parity plot – Regression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3ee6a751a8396e06e9dba7677ac055bb9b433a5e635232cf617ac6c7d7b1f8dc.png" src="_images/3ee6a751a8396e06e9dba7677ac055bb9b433a5e635232cf617ac6c7d7b1f8dc.png" />
<img alt="_images/76d2aca67e937a7bf2559fd45c6caea234724489baa01f7519402292f32b830d.png" src="_images/76d2aca67e937a7bf2559fd45c6caea234724489baa01f7519402292f32b830d.png" />
</div>
</div>
</section>
<section id="how-split-choice-affects-accuracy">
<h3>3.3 How split choice affects accuracy<a class="headerlink" href="#how-split-choice-affects-accuracy" title="Link to this heading">#</a></h3>
<p>Besides, we can examine how different splitting strategies influence the accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.20</span><span class="p">,</span> <span class="mf">0.30</span><span class="p">]</span>
<span class="n">seeds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>  <span class="c1"># more seeds = smoother distributions</span>

<span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">test_sizes</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">seeds</span><span class="p">:</span>
        <span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
        <span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">)</span>
        <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;test_size&quot;</span><span class="p">:</span> <span class="n">t</span><span class="p">,</span>
            <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span>
            <span class="s2">&quot;MSE&quot;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">),</span>
            <span class="s2">&quot;MAE&quot;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">),</span>
            <span class="s2">&quot;R2&quot;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">),</span>
            <span class="s2">&quot;n_train&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_tr</span><span class="p">),</span>
            <span class="s2">&quot;n_test&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_te</span><span class="p">),</span>
        <span class="p">})</span>

<span class="n">df_splits</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>

<span class="c1"># Summary table</span>
<span class="n">summary</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_splits</span>
           <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;test_size&quot;</span><span class="p">)</span>
           <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">MSE_mean</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;MSE&quot;</span><span class="p">,</span><span class="s2">&quot;mean&quot;</span><span class="p">),</span> <span class="n">MSE_std</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;MSE&quot;</span><span class="p">,</span><span class="s2">&quot;std&quot;</span><span class="p">),</span>
                <span class="n">MAE_mean</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;MAE&quot;</span><span class="p">,</span><span class="s2">&quot;mean&quot;</span><span class="p">),</span> <span class="n">MAE_std</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;MAE&quot;</span><span class="p">,</span><span class="s2">&quot;std&quot;</span><span class="p">),</span>
                <span class="n">R2_mean</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;R2&quot;</span><span class="p">,</span><span class="s2">&quot;mean&quot;</span><span class="p">),</span>   <span class="n">R2_std</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;R2&quot;</span><span class="p">,</span><span class="s2">&quot;std&quot;</span><span class="p">),</span>
                <span class="n">n_train_mean</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;n_train&quot;</span><span class="p">,</span><span class="s2">&quot;mean&quot;</span><span class="p">),</span> <span class="n">n_test_mean</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;n_test&quot;</span><span class="p">,</span><span class="s2">&quot;mean&quot;</span><span class="p">))</span>
           <span class="o">.</span><span class="n">reset_index</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Effect of split on accuracy&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">summary</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>

<span class="c1"># Simple R2 scatter by test_size to visualize spread</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">test_sizes</span><span class="p">:</span>
    <span class="n">vals</span> <span class="o">=</span> <span class="n">df_splits</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_splits</span><span class="p">[</span><span class="s2">&quot;test_size&quot;</span><span class="p">]</span><span class="o">==</span><span class="n">t</span><span class="p">,</span> <span class="s2">&quot;R2&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">vals</span><span class="p">),</span> <span class="n">vals</span><span class="p">,</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;test_size=</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;test_size&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;R2 on test&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;R2 across many random splits&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># One-shot comparison matching your exercise idea</span>
<span class="k">for</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">seed</span> <span class="ow">in</span> <span class="p">[(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">42</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">42</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)]:</span>
    <span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test_size=</span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2">, seed=</span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s2"> -&gt; &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;MSE=</span><span class="si">{</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">y_hat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;MAE=</span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">y_hat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;R2=</span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">y_hat</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Effect of split on accuracy
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>test_size</th>
      <th>MSE_mean</th>
      <th>MSE_std</th>
      <th>MAE_mean</th>
      <th>MAE_std</th>
      <th>R2_mean</th>
      <th>R2_std</th>
      <th>n_train_mean</th>
      <th>n_test_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.1</td>
      <td>389.5968</td>
      <td>75.9762</td>
      <td>15.5954</td>
      <td>1.7249</td>
      <td>0.8338</td>
      <td>0.0559</td>
      <td>517.0</td>
      <td>58.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.2</td>
      <td>400.1363</td>
      <td>47.3691</td>
      <td>15.8006</td>
      <td>1.0476</td>
      <td>0.8433</td>
      <td>0.0363</td>
      <td>460.0</td>
      <td>115.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.3</td>
      <td>401.9008</td>
      <td>42.3394</td>
      <td>15.8713</td>
      <td>0.8514</td>
      <td>0.8412</td>
      <td>0.0268</td>
      <td>402.0</td>
      <td>173.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/18e55716e86451063c7bf7edaad8c1423cbd2bb0f27f45241279957b8c5ecccd.png" src="_images/18e55716e86451063c7bf7edaad8c1423cbd2bb0f27f45241279957b8c5ecccd.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>test_size=0.2, seed=15 -&gt; MSE=415.498, MAE=16.380, R2=0.805
test_size=0.2, seed=42 -&gt; MSE=374.568, MAE=15.316, R2=0.874
test_size=0.1, seed=42 -&gt; MSE=324.998, MAE=13.861, R2=0.872
test_size=0.1, seed=7 -&gt; MSE=361.085, MAE=15.025, R2=0.893
</pre></div>
</div>
</div>
</div>
<div class="admonition-reproducibility admonition">
<p class="admonition-title">Reproducibility</p>
<p><code class="docutils literal notranslate"><span class="pre">random_state</span></code> fixes the shuffle used by <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code>. Same seed gives the same split so your metrics are stable from run to run.</p>
</div>
</section>
<section id="learning-curves">
<h3>3.4 Learning curves<a class="headerlink" href="#learning-curves" title="Link to this heading">#</a></h3>
<p>A random <code class="docutils literal notranslate"><span class="pre">seed</span></code> is simply a number provided to a random number generator to ensure that it produces the same sequence of “random” results each time.</p>
<p>For example, functions such as <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> shuffle the dataset before dividing it into training and testing sets. If you do not specify a <code class="docutils literal notranslate"><span class="pre">random_state</span></code> (the seed), every run may produce a slightly different split. This variation can lead to different accuracy values across runs.</p>
<p><strong>Same seed → same split → same results</strong></p>
<p><strong>Different seed → different split → possibly different accuracy</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">learning_curve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">seeds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">train_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="c1"># Storage for test scores</span>
<span class="n">test_scores_r2_all</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_scores_mae_all</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seeds</span><span class="p">:</span>
    <span class="c1"># Fixed train-test split per seed</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># R²</span>
    <span class="n">train_sizes_abs</span><span class="p">,</span> <span class="n">train_scores_r2</span><span class="p">,</span> <span class="n">test_scores_r2</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">LinearRegression</span><span class="p">(),</span> 
        <span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
        <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">,</span> 
        <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;r2&quot;</span><span class="p">,</span> 
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">test_scores_r2_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores_r2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># MAE</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">train_scores_mae</span><span class="p">,</span> <span class="n">test_scores_mae</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">LinearRegression</span><span class="p">(),</span> 
        <span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
        <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">,</span> 
        <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_absolute_error&quot;</span><span class="p">,</span> 
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">test_scores_mae_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">test_scores_mae</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Convert to arrays</span>
<span class="n">test_scores_r2_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_scores_r2_all</span><span class="p">)</span>
<span class="n">test_scores_mae_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_scores_mae_all</span><span class="p">)</span>

<span class="c1"># Mean and std across seeds</span>
<span class="n">test_mean_r2</span> <span class="o">=</span> <span class="n">test_scores_r2_all</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_std_r2</span>  <span class="o">=</span> <span class="n">test_scores_r2_all</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_mean_mae</span> <span class="o">=</span> <span class="n">test_scores_mae_all</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_std_mae</span>  <span class="o">=</span> <span class="n">test_scores_mae_all</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot R²</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">,</span> <span class="n">test_mean_r2</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test R2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">,</span> <span class="n">test_mean_r2</span> <span class="o">-</span> <span class="n">test_std_r2</span><span class="p">,</span> <span class="n">test_mean_r2</span> <span class="o">+</span> <span class="n">test_std_r2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Training set size&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;R2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Test R2 across seeds&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot MAE</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">,</span> <span class="n">test_mean_mae</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test MAE&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">,</span> <span class="n">test_mean_mae</span> <span class="o">-</span> <span class="n">test_std_mae</span><span class="p">,</span> <span class="n">test_mean_mae</span> <span class="o">+</span> <span class="n">test_std_mae</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Training set size&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;MAE&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Test MAE across seeds&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4a43da0582501151adb7e9e5958739744d9cff9fdeaa2ad12d68f65db863da01.png" src="_images/4a43da0582501151adb7e9e5958739744d9cff9fdeaa2ad12d68f65db863da01.png" />
<img alt="_images/2cf4c6ba2077299bffd41e623e8a50c7a0baea5def4db4c3169414443960aef4.png" src="_images/2cf4c6ba2077299bffd41e623e8a50c7a0baea5def4db4c3169414443960aef4.png" />
</div>
</div>
</section>
<section id="regularization-lasso-and-ridge">
<h3>3.5 Regularization: Lasso and Ridge<a class="headerlink" href="#regularization-lasso-and-ridge" title="Link to this heading">#</a></h3>
<p>Now, instead of using <strong>Linear Regression</strong>, we can also experiment with other models such as <strong>Lasso Regression</strong>. These alternatives add regularization, which helps prevent overfitting by penalizing overly complex models.</p>
<p>So, how does <code class="docutils literal notranslate"><span class="pre">.fit(X,</span> <span class="pre">y)</span></code> work?</p>
<p>When you call <code class="docutils literal notranslate"><span class="pre">model.fit(X,</span> <span class="pre">y)</span></code>, the following steps occur:</p>
<ol class="arabic simple">
<li><p><strong>Model receives the data</strong></p>
<ul class="simple">
<li><p><strong>X</strong>: the feature matrix (input variables).</p></li>
<li><p><strong>y</strong>: the target values (labels you want the model to predict).</p></li>
</ul>
</li>
<li><p><strong>Optimization process</strong></p>
<ul class="simple">
<li><p><strong>Linear Regression</strong>: finds the line, plane, or hyperplane that minimizes the <strong>Mean Squared Error (MSE)</strong> between predictions and true values.</p></li>
<li><p><strong>Ridge Regression</strong>: minimizes MSE but adds an <strong>L2 penalty</strong> (squares of the coefficients) to shrink coefficients and control variance.</p></li>
<li><p><strong>Lasso Regression</strong>: minimizes MSE but adds an <strong>L1 penalty</strong> (absolute values of the coefficients), which can drive some coefficients exactly to zero, effectively performing <strong>feature selection</strong>.</p></li>
</ul>
</li>
</ol>
<p>This optimization is usually solved through iterative algorithms that adjust coefficients until the cost function reaches its minimum.</p>
<p>Now, instead of linear regression, we can also try other, such as lasso regression.</p>
<div class="admonition-losses admonition">
<p class="admonition-title">Losses</p>
<ul class="simple">
<li><p><strong>Linear</strong><br />
<span class="math notranslate nohighlight">\(
\hat{y} = w^\top x + b,\quad
\mathrm{Loss} = \frac{1}{n}\sum (y_i - \hat{y}_i)^2
\)</span></p></li>
<li><p><strong>Lasso</strong><br />
<span class="math notranslate nohighlight">\(
\mathrm{Loss} = \frac{1}{n}\sum (y_i - \hat{y}_i)^2 + \alpha \sum_j \lvert w_j \rvert
\)</span></p></li>
<li><p><strong>Ridge</strong><br />
<span class="math notranslate nohighlight">\(
\mathrm{Loss} = \frac{1}{n}\sum (y_i - \hat{y}_i)^2 + \alpha \sum_j w_j^2
\)</span></p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize model (you can adjust alpha to control regularization strength)</span>
<span class="n">reg_lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Fit to training data</span>
<span class="n">reg_lasso</span> <span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict on test set</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg_lasso</span> <span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate performance</span>
<span class="n">mse_lasso</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">mae_lasso</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">r2_lasso</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Lasso regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Linear regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>For Lasso regression:
MSE: 329.0917965850995
MAE: 14.76860034615641
R2: 0.8788521790542615
--------------
For Linear regression:
MSE: 374.56773278929023
MAE: 15.316390819320326
R2: 0.8741026174988968
</pre></div>
</div>
</div>
</div>
<p>You can see here that, in fact, <strong>Lasso Regression performs slightly better Linear Regression</strong> in this particular example. You can also try changing alpha to 0.1, 1.0, 100 to see any difference.</p>
<p>The prediction rule for Linear Regression is:</p>
<div class="math notranslate nohighlight">
\[
\hat{y} = w_1x_1 + w_2x_2 + \dots + w_px_p + b
\]</div>
<p>We will also look at <strong>Ridge Regression</strong>, which adds an L2 penalty to the loss function:</p>
<div class="math notranslate nohighlight">
\[
\text{Loss} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2 + \alpha \sum_{j=1}^p w_j^2
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="c1"># Initialize model (tune alpha for regularization strength)</span>
<span class="n">reg_ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># Fit to training data</span>
<span class="n">reg_ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict on test set</span>
<span class="n">y_pred_ridge</span> <span class="o">=</span> <span class="n">reg_ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate performance</span>
<span class="n">mse_ridge</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>
<span class="n">mae_ridge</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>
<span class="n">r2_ridge</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Ridge regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Linear regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>For Ridge regression:
MSE: 329.1771333969961
MAE: 14.763612712404358
R2: 0.8788207642061401
--------------
For Linear regression:
MSE: 374.56773278929023
MAE: 15.316390819320326
R2: 0.8741026174988968
</pre></div>
</div>
</div>
</div>
<p>We can see here that the models have very similar performance.</p>
<p>Now, what about predicting actual values such as <strong>solubility</strong>?</p>
</section>
</section>
<hr class="docutils" />
<section id="another-regression-target-solubility-in-log-space">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">4. Another regression target: solubility in log space</a><a class="headerlink" href="#another-regression-target-solubility-in-log-space" title="Link to this heading">#</a></h2>
<p>Let’s try doing the same process by defining the following molecular descriptors as our input features (<strong>X</strong>):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">molwt</span></code> (molecular weight)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logp</span></code> (partition coefficient)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tpsa</span></code> (topological polar surface area)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numrings</span></code> (number of rings)</p></li>
</ul>
<p>Our target (<strong>y</strong>) will be the <strong>solubility</strong> column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Select features (X) and target (y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Solubility_mol_per_L&quot;</span><span class="p">]</span>

<span class="c1"># 2. Train/test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># 3. Linear Regression</span>
<span class="n">reg_linear</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg_linear</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_linear</span> <span class="o">=</span> <span class="n">reg_linear</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_linear</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">)</span>
<span class="n">mae_linear</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">)</span>
<span class="n">r2_linear</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Linear regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse_linear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae_linear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_linear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------&quot;</span><span class="p">)</span>

<span class="c1"># 4. Ridge Regression</span>
<span class="n">reg_ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">reg_ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_ridge</span> <span class="o">=</span> <span class="n">reg_ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_ridge</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>
<span class="n">mae_ridge</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>
<span class="n">r2_ridge</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Ridge regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------&quot;</span><span class="p">)</span>

<span class="c1"># 5. Lasso Regression</span>
<span class="n">reg_lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>  <span class="c1"># alpha can be tuned</span>
<span class="n">reg_lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_lasso</span> <span class="o">=</span> <span class="n">reg_lasso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_lasso</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">)</span>
<span class="n">mae_lasso</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">)</span>
<span class="n">r2_lasso</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Lasso regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>For Linear regression:
MSE: 5445.949091807626
MAE: 48.59778162610549
R2: -22609.207680755866
--------------
For Ridge regression:
MSE: 5421.63548777009
MAE: 48.477509550010666
R2: -22508.2637263617
--------------
For Lasso regression:
MSE: 5445.22668533266
MAE: 48.591949745715986
R2: -22606.208431193747
--------------
</pre></div>
</div>
</div>
</div>
<p>The results here are very poor, with a strongly negative <span class="math notranslate nohighlight">\(R^2\)</span> value.</p>
<div class="admonition-stabilize-with-logs admonition">
<p class="admonition-title">Stabilize with logs</p>
<p>Targets like solubility are commonly modeled as <code class="docutils literal notranslate"><span class="pre">logS</span></code>. Taking logs reduces the influence of extreme values and can improve fit quality.</p>
</div>
<p>So instead of fitting the solubility values directly, we transform them using:</p>
<div class="math notranslate nohighlight">
\[
y' = \log_{10}(\text{Solubility})
\]</div>
<p>This way, we predict <span class="math notranslate nohighlight">\(y'\)</span> (log-scaled solubility) rather than the raw solubility.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Select features (X) and target (y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span>

<span class="c1">######################### ##################### #####################</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Solubility_mol_per_L&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>  <span class="c1"># avoid log(0)</span>
<span class="c1">######################### all other code stay the same #####################</span>


<span class="c1"># 2. Train/test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># 3. Linear Regression</span>
<span class="n">reg_linear</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg_linear</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_linear</span> <span class="o">=</span> <span class="n">reg_linear</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_linear</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">)</span>
<span class="n">mae_linear</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">)</span>
<span class="n">r2_linear</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Linear regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse_linear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae_linear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_linear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------&quot;</span><span class="p">)</span>

<span class="c1"># 4. Ridge Regression</span>
<span class="n">reg_ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">reg_ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_ridge</span> <span class="o">=</span> <span class="n">reg_ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_ridge</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>
<span class="n">mae_ridge</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>
<span class="n">r2_ridge</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Ridge regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_ridge</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------&quot;</span><span class="p">)</span>

<span class="c1"># 5. Lasso Regression</span>
<span class="n">reg_lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>  <span class="c1"># alpha can be tuned</span>
<span class="n">reg_lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_lasso</span> <span class="o">=</span> <span class="n">reg_lasso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_lasso</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">)</span>
<span class="n">mae_lasso</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">)</span>
<span class="n">r2_lasso</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For Lasso regression:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mae_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_lasso</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>For Linear regression:
MSE: 0.018391458540756016
MAE: 0.11527716464692483
R2: 0.9596775333018726
--------------
For Ridge regression:
MSE: 0.01841119336512683
MAE: 0.11530263164973817
R2: 0.9596342655644758
--------------
For Lasso regression:
MSE: 0.01879606817208987
MAE: 0.11631355339741077
R2: 0.95879044442042
--------------
</pre></div>
</div>
</div>
</div>
<p>Now, much better, right? Now, what happen if instead transforming <code class="docutils literal notranslate"><span class="pre">y</span></code>, you actually transforming <code class="docutils literal notranslate"><span class="pre">x</span></code>? Try it by yourself after class.</p>
</section>
<hr class="docutils" />
<section id="binary-classification-toxicity">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">5. Binary classification: toxicity</a><a class="headerlink" href="#binary-classification-toxicity" title="Link to this heading">#</a></h2>
<p>We turn to a yes or no outcome, using the same four descriptors. Logistic Regression outputs probabilities. A threshold converts those into class predictions.</p>
<p>We will build a binary classifier for <strong>Toxicity</strong> using the pre-built table:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_clf_tox</span> <span class="o">=</span><span class="n">df</span><span class="p">[[</span><span class="s2">&quot;Compound Name&quot;</span><span class="p">,</span> <span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">,</span><span class="s2">&quot;Toxicity&quot;</span><span class="p">]]</span>
<span class="n">df_clf_tox</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Compound Name</th>
      <th>MolWt</th>
      <th>LogP</th>
      <th>TPSA</th>
      <th>NumRings</th>
      <th>Toxicity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3,4-dihydro-1H-isochromene</td>
      <td>134.178</td>
      <td>1.7593</td>
      <td>9.23</td>
      <td>2.0</td>
      <td>non_toxic</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9H-fluorene</td>
      <td>166.223</td>
      <td>3.2578</td>
      <td>0.00</td>
      <td>3.0</td>
      <td>toxic</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1,2,3,4-tetrahydronaphthalene</td>
      <td>132.206</td>
      <td>2.5654</td>
      <td>0.00</td>
      <td>2.0</td>
      <td>toxic</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ethylbenzene</td>
      <td>106.168</td>
      <td>2.2490</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>non_toxic</td>
    </tr>
    <tr>
      <th>4</th>
      <td>cyclohexene</td>
      <td>82.146</td>
      <td>2.1166</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>non_toxic</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>570</th>
      <td>2-naphthalen-2-ylpropan-2-amine</td>
      <td>185.270</td>
      <td>3.0336</td>
      <td>26.02</td>
      <td>2.0</td>
      <td>toxic</td>
    </tr>
    <tr>
      <th>571</th>
      <td>1-bromo-4-(methylamino)anthracene-9,10-dione</td>
      <td>316.154</td>
      <td>3.2662</td>
      <td>46.17</td>
      <td>3.0</td>
      <td>toxic</td>
    </tr>
    <tr>
      <th>572</th>
      <td>1-[6-(dimethylamino)naphthalen-2-yl]prop-2-en-...</td>
      <td>225.291</td>
      <td>3.2745</td>
      <td>20.31</td>
      <td>2.0</td>
      <td>toxic</td>
    </tr>
    <tr>
      <th>573</th>
      <td>1,2-dimethoxy-12-methyl-[1,3]benzodioxolo[5,6-...</td>
      <td>348.378</td>
      <td>3.7166</td>
      <td>40.80</td>
      <td>5.0</td>
      <td>toxic</td>
    </tr>
    <tr>
      <th>574</th>
      <td>dimethyl anthracene-1,8-dicarboxylate</td>
      <td>294.306</td>
      <td>3.5662</td>
      <td>52.60</td>
      <td>3.0</td>
      <td>toxic</td>
    </tr>
  </tbody>
</table>
<p>575 rows × 6 columns</p>
</div></div></div>
</div>
<div class="admonition-encoding admonition">
<p class="admonition-title">Encoding</p>
<p>Map text labels to numbers so that the model can learn from them. Keep an eye on class balance.</p>
</div>
<p>We will perform the following steps:</p>
<ol class="arabic simple">
<li><p><strong>Map labels to numeric values</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">toxic</span></code> → 1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">non_toxic</span></code> → 0</p></li>
</ul>
</li>
<li><p><strong>Select features for training</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MolWt</span></code> (Molecular Weight)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LogP</span></code> (Partition Coefficient)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TPSA</span></code> (Topological Polar Surface Area)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NumRings</span></code> (Number of Rings)</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Label encode</span>
<span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;toxic&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;non_toxic&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_clf_tox</span><span class="p">[</span><span class="s2">&quot;Toxicity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Feature matrix</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_clf_tox</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Just to be sure there are no infinities</span>
<span class="n">mask_finite</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">mask_finite</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask_finite</span><span class="p">]</span>

<span class="n">X</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([[134.178 ,   1.7593,   9.23  ,   2.    ],
        [166.223 ,   3.2578,   0.    ,   3.    ],
        [132.206 ,   2.5654,   0.    ,   2.    ]]),
 0    0
 1    1
 2    1
 3    0
 4    0
 5    0
 6    0
 7    0
 8    1
 9    1
 Name: Toxicity, dtype: int64)
</pre></div>
</div>
</div>
</div>
<p>When splitting the data into training and test sets, we will use <strong>stratification</strong>.</p>
<div class="admonition-why-stratification admonition">
<p class="admonition-title">Why stratification</p>
<p>Stratification ensures that the proportion of labels (toxic vs non-toxic) remains approximately the same in both the training and test sets. This prevents issues where one split might have many more examples of one class than the other, which could bias model evaluation.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train shape:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot; Test shape:&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train class balance:&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="s2">&quot; 1 = toxic&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test class balance:&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train shape: (460, 4)  Test shape: (115, 4)
Train class balance: 0.824  1 = toxic
Test class balance: 0.826
</pre></div>
</div>
</div>
</div>
<p>The name <strong>LogisticRegression</strong> can be a bit misleading. Even though it contains the word <em>regression</em>, it is <strong>not</strong> used for predicting continuous values.</p>
<div class="admonition-difference admonition">
<p class="admonition-title">Difference</p>
<p>Logistic Regression → for classification (e.g., spam vs. not spam, toxic vs. not toxic). It outputs probabilities between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>. A threshold (commonly <code class="docutils literal notranslate"><span class="pre">0.5</span></code>) is then applied to assign class labels.</p>
<p>Linear Regression → for regression (predicting continuous numbers, like prices, scores, or temperatures).</p>
</div>
<p>Remember:
Logistic Regression is for classification. It models probability of class 1. Linear Regression is for continuous targets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predictions and probabilities</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># probability of toxic = 1</span>
<span class="n">y_pred</span><span class="p">,</span>  <span class="n">y_proba</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,
        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,
        0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,
        1, 1, 1, 0, 1]),
 array([0.97365623, 0.99999446, 0.07947364, 0.99928262, 0.9980891 ,
        0.99988607, 0.38729989, 0.28314806, 0.98259664, 0.91109118,
        1.        , 0.46860548, 0.98970303, 0.99999986, 1.        ,
        0.99999072, 0.19727375, 0.60960733, 0.99975052, 0.99999458,
        0.99998644, 0.99999999, 0.99971597, 1.        , 0.99875073,
        0.99896006, 0.99643232, 0.99999997, 0.99982699, 0.54794482,
        0.25983303, 0.99996567, 0.99016699, 0.99951395, 0.99997992,
        0.9945712 , 0.68033858, 0.07968061, 0.99462357, 0.99898643,
        0.99837874, 0.19580904, 0.99981472, 0.99845553, 0.99826431,
        0.99744605, 0.99966762, 0.99993185, 0.99999631, 0.00365372,
        0.97834833, 0.99973715, 0.94542293, 0.94609804, 0.17158234,
        0.41085072, 0.99978148, 0.97261689, 0.99824268, 0.93471006,
        0.9999994 , 0.99999999, 0.99580694, 0.45318977, 0.99849298,
        0.98080952, 0.98615126, 0.99925854, 0.99649529, 0.98067268,
        0.9999999 , 0.89617648, 0.99855409, 0.69051763, 0.99952057,
        0.80491169, 0.3276906 , 0.99779547, 0.11405811, 0.99999984,
        0.99992034, 0.94609804, 0.64932882, 0.99558584, 0.97095588,
        0.99935538, 0.04301283, 0.99995445, 0.13724395, 0.99999072,
        0.99994111, 0.99999647, 0.99997382, 0.41527923, 0.77149092,
        0.99999642, 0.99918537, 0.99998729, 0.12146176, 0.97989265,
        0.78881568, 0.99498407, 0.13724395, 0.99997757, 0.99999981,
        0.88004593, 0.9954273 , 0.34878879, 0.9999999 , 0.99999966,
        0.99956914, 0.99993736, 0.9999779 , 0.13220075, 0.99999716]))
</pre></div>
</div>
</div>
</div>
<div class="admonition-metrics-for-classification admonition">
<p class="admonition-title">Metrics for classification</p>
<p><strong>Accuracy</strong>: fraction of correct predictions.</p>
<div class="math notranslate nohighlight">
\[
\text{Accuracy} = \frac{TP + TN}{TP + FP + TN + FN}
\]</div>
<hr class="docutils" />
<p><strong>Precision</strong>: among predicted toxic, how many are truly toxic.</p>
<div class="math notranslate nohighlight">
\[
\text{Precision} = \frac{TP}{TP + FP}
\]</div>
<hr class="docutils" />
<p><strong>Recall</strong>: among truly toxic, how many we caught.</p>
<div class="math notranslate nohighlight">
\[
\text{Recall} = \frac{TP}{TP + FN}
\]</div>
<hr class="docutils" />
<p><strong>F1</strong>: harmonic mean of precision and recall.</p>
<div class="math notranslate nohighlight">
\[
\text{F1} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]</div>
<hr class="docutils" />
<p><strong>AUC</strong>: area under the ROC curve. Measures ranking of positives vs negatives over all thresholds.</p>
</div>
<p>Now we can exame metrics:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span>
    <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="p">)</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">rec</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy:  </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall:    </span><span class="si">{</span><span class="n">rec</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1:        </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC:       </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy:  0.957
Precision: 0.979
Recall:    0.968
F1:        0.974
AUC:       0.992
</pre></div>
</div>
</div>
</div>
<div class="admonition-confusion-matrix-and-roc admonition">
<p class="admonition-title">Confusion matrix and ROC</p>
<p>Inspect the mix of true vs predicted labels and visualize how sensitivity and specificity trade off across thresholds.</p>
</div>
<p>By default, most classifiers (such as Logistic Regression) use a threshold of <strong>0.5</strong>:</p>
<ul class="simple">
<li><p>If predicted probability ≥ 0.5 → class = 1 (toxic)</p></li>
<li><p>If predicted probability &lt; 0.5 → class = 0 (non-toxic)</p></li>
</ul>
<p>However, we can <strong>change the threshold</strong> depending on the problem:</p>
<ul class="simple">
<li><p>Lowering the threshold (e.g., 0.3) increases sensitivity (recall), catching more positives but with more false positives.</p></li>
<li><p>Raising the threshold (e.g., 0.7) increases precision, reducing false positives but possibly missing some true positives.</p></li>
</ul>
<p>This trade-off is important in real-world settings. For example:</p>
<ul class="simple">
<li><p>In medical screening, we may prefer higher recall (catch all possible cases).</p></li>
<li><p>In spam filtering, we may prefer higher precision (avoid marking valid emails as spam).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Confusion matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">fraction</span><span class="o">=</span><span class="mf">0.046</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.04</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># ROC curve</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thr</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.35</span>  <span class="c1"># try 0.3, 0.5, 0.7</span>
<span class="n">proba</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">proba</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;threshold: </span><span class="si">{</span><span class="n">threshold</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall: </span><span class="si">{</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1: </span><span class="si">{</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC: </span><span class="si">{</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">proba</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/95c5f1510071c152a296c1f9f4f4bb60a01240f7924bd4fdadc90d6091304c3c.png" src="_images/95c5f1510071c152a296c1f9f4f4bb60a01240f7924bd4fdadc90d6091304c3c.png" />
<img alt="_images/649e881bba15d5d21cbbd099ac4190a4b3e85275081058e7553e7bb2fbc55554.png" src="_images/649e881bba15d5d21cbbd099ac4190a4b3e85275081058e7553e7bb2fbc55554.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>threshold: 0.350
Accuracy: 0.965
Precision: 0.960
Recall: 1.000
F1: 0.979
AUC: 0.992
</pre></div>
</div>
</div>
</div>
<p>Depending on how you set the classification threshold, the evaluation metrics will change.</p>
<ul class="simple">
<li><p>If you use a <strong>threshold = 0.5</strong>, you will obtain exactly the same results as before (the default behavior).</p></li>
<li><p>Adjusting the threshold upward or downward will shift the balance between <strong>precision</strong> and <strong>recall</strong>, leading to different values for accuracy, F1 score, and other metrics.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Probabilities from your classifier</span>
<span class="n">proba</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Threshold values</span>
<span class="n">thresholds</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>

<span class="c1"># Store results</span>
<span class="n">accuracy</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">proba</span> <span class="o">&gt;=</span> <span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
    <span class="n">precision</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
    <span class="n">recall</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
    <span class="n">f1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>

<span class="c1"># Plot metrics vs thresholds</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thresholds</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thresholds</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Precision&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thresholds</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Recall&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thresholds</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;F1 Score&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Threshold&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Metrics at Different Thresholds&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/bb981d4b4479f95d40d4e5e47eb99d6da7e72bfc806108195eb9fa24964827f6.png" src="_images/bb981d4b4479f95d40d4e5e47eb99d6da7e72bfc806108195eb9fa24964827f6.png" />
</div>
</div>
</section>
<hr class="docutils" />
<section id="from-regression-to-classes-melting-point-bins">
<h2><a class="toc-backref" href="#id12" role="doc-backlink">6. From regression to classes: melting point bins</a><a class="headerlink" href="#from-regression-to-classes-melting-point-bins" title="Link to this heading">#</a></h2>
<p>Now, let’s think about this:
<strong>Can regression question be turning into classificiation?</strong></p>
<blockquote>
<div><p>Turning <code class="docutils literal notranslate"><span class="pre">Melting</span> <span class="pre">Point</span></code> Regression into a 3-Class Classification Task</p>
</div></blockquote>
<p>So far we treated melting point (MP) as a continuous variable and built regression models. Another approach is to discretize MP into categories and reframe the task as classification. This can be useful if we only need a decision (e.g., low vs. medium vs. high melting point) rather than an exact temperature.</p>
<p>We split melting points into three bins:</p>
<blockquote>
<div><p><strong>Class 0 (Low):</strong> MP ≤ 100 °C<br />
<strong>Class 1 (Medium):</strong> 100 &lt; MP ≤ 200 °C<br />
<strong>Class 2 (High):</strong> MP &gt; 200 °C</p>
</div></blockquote>
<p>This creates a categorical target suitable for classification models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Features: same as before</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Define categorical target</span>
<span class="n">mp</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span>
    <span class="n">mp</span><span class="p">,</span>
    <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="n">right</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_lowest</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">y3</span>

<span class="c1"># Train/test split with stratification (preserves class proportions)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span>  <span class="n">y_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([[226.703  ,   3.687  ,  26.3    ,   1.     ],
        [282.295  ,   2.5255 ,  52.6    ,   3.     ],
        [468.722  ,   7.5302 ,  43.37   ,   5.     ],
        ...,
        [277.106  ,   3.7688 ,  34.14   ,   3.     ],
        [215.061  ,   1.32648,  42.25   ,   2.     ],
        [134.222  ,   2.8114 ,   0.     ,   1.     ]], shape=(460, 4)),
 array([1, 1, 2, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 1,
        0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,
        1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,
        0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 0, 1,
        1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,
        1, 0, 1, 1, 0, 2, 2, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2,
        0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 1, 2, 1, 0, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,
        1, 0, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 1, 0, 2, 0, 0, 1,
        1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 2, 1,
        1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 2, 0, 0, 2, 1, 1,
        2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,
        1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 2, 1, 1, 1, 1, 2, 0, 2, 1, 1, 0, 1,
        2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 2,
        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1,
        1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 1, 2, 2,
        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0,
        0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 2,
        0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 0, 1, 0, 1, 0, 1, 2, 1,
        1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 2, 1, 0]))
</pre></div>
</div>
</div>
</div>
<div class="admonition-multinomial-logistic-regression admonition">
<p class="admonition-title">Multinomial logistic regression</p>
<p>The logistic model extends naturally to more than two classes. Scikit-learn handles this under the hood.</p>
</div>
<p>Now we can train a <strong>Logistic Regression</strong> model on the melting point classification task.</p>
<p>Logistic Regression is not limited to binary problems — it can be extended to handle <strong>multiple classes</strong>.</p>
<ul class="simple">
<li><p>In the <strong>multinomial</strong> setting, the model learns separate decision boundaries for each class.</p></li>
<li><p>Each class receives its own probability, and the model assigns the label with the highest probability.</p></li>
</ul>
<p>This allows us to predict whether a compound falls into <strong>low</strong>, <strong>medium</strong>, or <strong>high</strong> melting point categories.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf3</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">clf3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predictions</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">clf3</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  <span class="c1"># class probabilities</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">)</span>
<span class="n">rec</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">)</span>



<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy:  </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall:    </span><span class="si">{</span><span class="n">rec</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1:        </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy:  0.826
Precision: 0.795
Recall:    0.797
F1:        0.794
</pre></div>
</div>
</div>
</div>
<div class="admonition-averaging-choices admonition">
<p class="admonition-title">Averaging choices</p>
<p>For multiple classes there are different ways to average metrics across classes. <strong>Macro</strong> gives each class equal weight, <strong>micro</strong> aggregates counts, and <strong>weighted</strong> weights by class frequency.</p>
</div>
<p>Note: When moving from <strong>binary classification</strong> to <strong>multi-class classification</strong>, metrics like precision, recall, and F1 score cannot be defined in just one way.<br />
You need to decide <strong>how to average</strong> them across multiple classes. This is where strategies such as <strong>macro</strong>, <strong>micro</strong>, and <strong>weighted</strong> averaging come into play.</p>
<section id="macro-averaging">
<h3>Macro Averaging<a class="headerlink" href="#macro-averaging" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Compute the metric (precision, recall, or F1) <strong>for each class separately</strong>.</p></li>
<li><p>Take the <strong>simple, unweighted average</strong> across all classes.</p></li>
<li><p>Every class contributes equally, regardless of how many samples it has.</p></li>
</ul>
<p><strong>Example:</strong><br />
Suppose we have 3 classes:</p>
<ul class="simple">
<li><p>Class 0: 500 samples</p></li>
<li><p>Class 1: 100 samples</p></li>
<li><p>Class 2: 50 samples</p></li>
</ul>
<p>If the model performs very well on <strong>Class 0</strong> (the large class) but very poorly on <strong>Class 2</strong> (the small class), <strong>macro averaging</strong> will penalize the model.<br />
This is because each class’s F1 score contributes equally to the final average, even though the class sizes are different.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Confusion matrix (counts)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># 0: ≤100, 1: 100–200, 2: &gt;200</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.8</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix - MP classes&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>

<span class="c1"># Tick labels for bins</span>
<span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;≤100&quot;</span><span class="p">,</span> <span class="s2">&quot;100–200&quot;</span><span class="p">,</span> <span class="s2">&quot;&gt;200&quot;</span><span class="p">]</span>
<span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;≤100&quot;</span><span class="p">,</span> <span class="s2">&quot;100–200&quot;</span><span class="p">,</span> <span class="s2">&quot;&gt;200&quot;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">xticks</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">yticks</span><span class="p">)</span>

<span class="c1"># Annotations</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">fraction</span><span class="o">=</span><span class="mf">0.046</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.04</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Optional: normalized confusion matrix (row-wise)</span>
<span class="n">cm_norm</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.8</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm_norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix (Normalized)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">xticks</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">yticks</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cm_norm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">fraction</span><span class="o">=</span><span class="mf">0.046</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.04</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/dfd1feed8cc23b19e59d9972a530b71a26cc9beea4ff40095a05839230968bc5.png" src="_images/dfd1feed8cc23b19e59d9972a530b71a26cc9beea4ff40095a05839230968bc5.png" />
<img alt="_images/f8692feb29148def95edfd3095242ec8f921b798e83065ae09825fac90e7d16a.png" src="_images/f8692feb29148def95edfd3095242ec8f921b798e83065ae09825fac90e7d16a.png" />
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="quick-reference">
<h2><a class="toc-backref" href="#id13" role="doc-backlink">8. Quick reference</a><a class="headerlink" href="#quick-reference" title="Link to this heading">#</a></h2>
<div class="admonition-model-recipes admonition">
<p class="admonition-title">Model recipes</p>
<ul class="simple">
<li><p><strong>LinearRegression</strong>: <code class="docutils literal notranslate"><span class="pre">fit(X_train,</span> <span class="pre">y_train)</span></code> then <code class="docutils literal notranslate"><span class="pre">predict(X_test)</span></code></p></li>
<li><p><strong>Ridge(alpha=1.0)</strong>: same API as LinearRegression</p></li>
<li><p><strong>Lasso(alpha=…)</strong>: same API, can shrink some coefficients to zero</p></li>
<li><p><strong>LogisticRegression(max_iter=…)</strong>: <code class="docutils literal notranslate"><span class="pre">predict</span></code> for labels, <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> for probabilities</p></li>
</ul>
</div>
<div class="admonition-metrics-at-a-glance admonition">
<p class="admonition-title">Metrics at a glance</p>
<ul class="simple">
<li><p>Regression: <strong>MSE</strong>, <strong>MAE</strong>, <strong>R²</strong></p></li>
<li><p>Classification: <strong>Accuracy</strong>, <strong>Precision</strong>, <strong>Recall</strong>, <strong>F1</strong>, <strong>AUC</strong></p></li>
<li><p>Visuals: <strong>residual plot</strong>, <strong>parity plot</strong>, <strong>confusion matrix</strong>, <strong>ROC</strong></p></li>
</ul>
</div>
<div class="admonition-splits-and-seeds admonition">
<p class="admonition-title">Splits and seeds</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">train_test_split(X,</span> <span class="pre">y,</span> <span class="pre">test_size=0.2,</span> <span class="pre">random_state=42)</span></code></p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">stratify=y</span></code> for classification to maintain label balance</p></li>
</ul>
</div>
</section>
<hr class="docutils" />
<section id="glossary">
<h2><a class="toc-backref" href="#id14" role="doc-backlink">9. Glossary</a><a class="headerlink" href="#glossary" title="Link to this heading">#</a></h2>
<dl class="simple glossary">
<dt id="term-supervised-learning">supervised learning<a class="headerlink" href="#term-supervised-learning" title="Link to this term">#</a></dt><dd><p>A setup with features <code class="docutils literal notranslate"><span class="pre">X</span></code> and a labeled target <code class="docutils literal notranslate"><span class="pre">y</span></code> for each example.</p>
</dd>
<dt id="term-regression">regression<a class="headerlink" href="#term-regression" title="Link to this term">#</a></dt><dd><p>Predicting a continuous number, such as a melting point.</p>
</dd>
<dt id="term-classification">classification<a class="headerlink" href="#term-classification" title="Link to this term">#</a></dt><dd><p>Predicting a category, such as toxic vs non_toxic.</p>
</dd>
<dt id="term-descriptor">descriptor<a class="headerlink" href="#term-descriptor" title="Link to this term">#</a></dt><dd><p>A numeric feature computed from a molecule. Examples: molecular weight, logP, TPSA, ring count.</p>
</dd>
<dt id="term-train-test-split">train test split<a class="headerlink" href="#term-train-test-split" title="Link to this term">#</a></dt><dd><p>Partition the data into a part to fit the model and a separate part to estimate performance.</p>
</dd>
<dt id="term-regularization">regularization<a class="headerlink" href="#term-regularization" title="Link to this term">#</a></dt><dd><p>Penalty added to the loss to discourage large weights. Lasso uses L1, Ridge uses L2.</p>
</dd>
<dt id="term-residual">residual<a class="headerlink" href="#term-residual" title="Link to this term">#</a></dt><dd><p>The difference <code class="docutils literal notranslate"><span class="pre">y_true</span> <span class="pre">-</span> <span class="pre">y_pred</span></code> for a sample.</p>
</dd>
<dt id="term-ROC-AUC">ROC AUC<a class="headerlink" href="#term-ROC-AUC" title="Link to this term">#</a></dt><dd><p>Area under the ROC curve, a threshold independent ranking score for binary classification.</p>
</dd>
<dt id="term-macro-averaging">macro averaging<a class="headerlink" href="#term-macro-averaging" title="Link to this term">#</a></dt><dd><p>Average the metric per class, then take the unweighted mean across classes.</p>
</dd>
<dt id="term-parity-plot">parity plot<a class="headerlink" href="#term-parity-plot" title="Link to this term">#</a></dt><dd><p>Scatter of predicted vs true values. Ideal points lie on the diagonal.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="in-class-activity">
<h2><a class="toc-backref" href="#id15" role="doc-backlink">10. In-class activity</a><a class="headerlink" href="#in-class-activity" title="Link to this heading">#</a></h2>
<section id="linear-regression-with-two-features">
<h3>10.1 Linear Regression with two features<a class="headerlink" href="#linear-regression-with-two-features" title="Link to this heading">#</a></h3>
<p>Use only <code class="docutils literal notranslate"><span class="pre">MolWt</span></code> and <code class="docutils literal notranslate"><span class="pre">TPSA</span></code> to predict <strong>Melting Point</strong> with Linear Regression. Use a 90/10 split and report <strong>MSE</strong>, <strong>MAE</strong>, and <strong>R²</strong>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=...</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=...</span>
<span class="p">)</span>

<span class="o">...</span> <span class="c1">#TO DO</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R2:  </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="ridge-across-splits">
<h3>10.2 Ridge across splits<a class="headerlink" href="#ridge-across-splits" title="Link to this heading">#</a></h3>
<p>Train a Ridge model (<code class="docutils literal notranslate"><span class="pre">alpha=1.0</span></code>) for <strong>Melting Point</strong> using <code class="docutils literal notranslate"><span class="pre">MolWt,</span> <span class="pre">LogP,</span> <span class="pre">TPSA,</span> <span class="pre">NumRings</span></code>. Compare test <strong>R²</strong> for train sizes 60, 70, 80, 90 percent with <code class="docutils literal notranslate"><span class="pre">random_state=42</span></code>. Plot <strong>R²</strong> vs train percent.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">#TO DO</span>
<span class="n">y</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">#TO DO</span>

<span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>  <span class="c1"># corresponds to 60/40, 70/30, 80/20, 90/10</span>
<span class="n">r2_scores</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># empty, no need to modify</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=...</span> <span class="o">...</span> <span class="c1">#TO DO</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">r2_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Plot results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span><span class="mi">90</span><span class="p">],</span> <span class="n">r2_scores</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Train %&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;R² (test)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Effect of train/test split on Ridge Regression accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="pka-regression-two-ways">
<h3>10.3 pKa regression two ways<a class="headerlink" href="#pka-regression-two-ways" title="Link to this heading">#</a></h3>
<p>Build Ridge regression for <strong>pKa</strong> using the same four descriptors. Report <strong>R²</strong> and <strong>MSE</strong> for each.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span> <span class="c1">#TO DO</span>
</pre></div>
</div>
</section>
<section id="pka-to-classification">
<h3>10.4 pKa to classification<a class="headerlink" href="#pka-to-classification" title="Link to this heading">#</a></h3>
<p>Turn <strong>pKa</strong> into a binary label and train Logistic Regression with the same descriptors. Report Accuracy, Precision, Recall, F1, and AUC, and draw the ROC. You may pick either rule.</p>
<ul class="simple">
<li><p>Option A: acidic if pKa ≤ 7</p></li>
<li><p>Option B: median split on pKa</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span> <span class="c1">#TO DO</span>
</pre></div>
</div>
</section>
</section>
<section id="id1">
<h2><a class="toc-backref" href="#id16" role="doc-backlink">10. In-class activity</a><a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<section id="id2">
<h3>10.1 Linear Regression with two features<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>Use only <code class="docutils literal notranslate"><span class="pre">MolWt</span></code> and <code class="docutils literal notranslate"><span class="pre">TPSA</span></code> to predict <strong>Melting Point</strong> with Linear Regression. Use a 90/10 split and report <strong>MSE</strong>, <strong>MAE</strong>, and <strong>R²</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Q1 starter</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R2:  </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MSE: 401.424
MAE: 15.892
R2:  0.729
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h3>10.2 Ridge across splits<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>Train a Ridge model (<code class="docutils literal notranslate"><span class="pre">alpha=1.0</span></code>) for <strong>Melting Point</strong> using <code class="docutils literal notranslate"><span class="pre">MolWt,</span> <span class="pre">LogP,</span> <span class="pre">TPSA,</span> <span class="pre">NumRings</span></code>. Compare test <strong>R²</strong> for train sizes 60, 70, 80, 90 percent with <code class="docutils literal notranslate"><span class="pre">random_state=42</span></code>. Plot <strong>R²</strong> vs train percent.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_reg_mp</span><span class="p">[</span><span class="s2">&quot;Melting Point&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>  <span class="c1"># corresponds to 60/40, 70/30, 80/20, 90/10</span>
<span class="n">r2_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">r2_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Plot results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">60</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span><span class="mi">90</span><span class="p">],</span> <span class="n">r2_scores</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Train %&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;R² (test)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Effect of train/test split on Ridge Regression accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/63bcbf96d35d80048a2518cba6456bcfceafa3610d56c2630fd8e20a1971fa8b.png" src="_images/63bcbf96d35d80048a2518cba6456bcfceafa3610d56c2630fd8e20a1971fa8b.png" />
</div>
</div>
</section>
<section id="id4">
<h3>10.3 pKa regression two ways<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>Build Ridge regression for <strong>pKa</strong> and for <strong>exp(pKa)</strong> using the same four descriptors. Report <strong>R²</strong> and <strong>MSE</strong> for each.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Keep rows with a valid pKa</span>
<span class="n">df_pka</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">,</span> <span class="s2">&quot;pKa&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_pka</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_pka</span><span class="p">[</span><span class="s2">&quot;pKa&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test R2:  </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test MSE: </span><span class="si">{</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Parity plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True pKa&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted pKa&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Parity plot for pKa regression (Ridge)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test R2:  0.042
Test MSE: 1.478
</pre></div>
</div>
<img alt="_images/341b537ee6674ba5347efdfcdf06f8f902277ebf3a04c9e6077be3a8ce55ec33.png" src="_images/341b537ee6674ba5347efdfcdf06f8f902277ebf3a04c9e6077be3a8ce55ec33.png" />
</div>
</div>
</section>
<section id="id5">
<h3>10.4 pKa to classification<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>Turn <strong>pKa</strong> into a binary label and train Logistic Regression with the same descriptors. Report Accuracy, Precision, Recall, F1, and AUC, and draw the ROC. You may pick either rule.</p>
<ul class="simple">
<li><p>Option A: acidic if pKa ≤ 7</p></li>
<li><p>Option B: median split on pKa</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Clean pKa subset</span>
<span class="n">df_pka</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">,</span> <span class="s2">&quot;pKa&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_pka</span><span class="p">[[</span><span class="s2">&quot;MolWt&quot;</span><span class="p">,</span> <span class="s2">&quot;LogP&quot;</span><span class="p">,</span> <span class="s2">&quot;TPSA&quot;</span><span class="p">,</span> <span class="s2">&quot;NumRings&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">pka_vals</span> <span class="o">=</span> <span class="n">df_pka</span><span class="p">[</span><span class="s2">&quot;pKa&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># ---- Helper to run classification and plot ----</span>
<span class="k">def</span><span class="w"> </span><span class="nf">run_classification</span><span class="p">(</span><span class="n">y_cls</span><span class="p">,</span> <span class="n">rule_name</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y_cls</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_cls</span>
    <span class="p">)</span>

    <span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">y_proba</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="n">acc</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">prec</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">rec</span>  <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">f1</span>   <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">auc</span>  <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--- </span><span class="si">{</span><span class="n">rule_name</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy:  </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall:    </span><span class="si">{</span><span class="n">rec</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1:        </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC:       </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>

    <span class="c1"># ROC plot</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thr</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ROC Curve for pKa classification (</span><span class="si">{</span><span class="n">rule_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># ---- Rule A: acidic if pKa ≤ 7 ----</span>
<span class="n">y_cls_A</span> <span class="o">=</span> <span class="p">(</span><span class="n">pka_vals</span> <span class="o">&lt;=</span> <span class="mf">7.0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">run_classification</span><span class="p">(</span><span class="n">y_cls_A</span><span class="p">,</span> <span class="s2">&quot;Rule A (pKa ≤ 7 = acidic)&quot;</span><span class="p">)</span>

<span class="c1"># ---- Rule B: median split ----</span>
<span class="n">median_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">pka_vals</span><span class="p">)</span>
<span class="n">y_cls_B</span> <span class="o">=</span> <span class="p">(</span><span class="n">pka_vals</span> <span class="o">&lt;=</span> <span class="n">median_val</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">run_classification</span><span class="p">(</span><span class="n">y_cls_B</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Rule B (≤ median pKa = acidic, median=</span><span class="si">{</span><span class="n">median_val</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Rule A (pKa ≤ 7 = acidic) ---
Accuracy:  0.809
Precision: 0.814
Recall:    0.989
F1:        0.893
AUC:       0.779
</pre></div>
</div>
<img alt="_images/6282fc6f257136c9d552c82e59fbf32f493d10ef5091ead26909a1c03b688990.png" src="_images/6282fc6f257136c9d552c82e59fbf32f493d10ef5091ead26909a1c03b688990.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Rule B (≤ median pKa = acidic, median=5.90) ---
Accuracy:  0.704
Precision: 0.750
Recall:    0.621
F1:        0.679
AUC:       0.743
</pre></div>
</div>
<img alt="_images/89f5d32d6fe46c6b5295059a61d23f4bf486d26c34b4f6261f11e32fc28c57df.png" src="_images/89f5d32d6fe46c6b5295059a61d23f4bf486d26c34b4f6261f11e32fc28c57df.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="lecture-04.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 4 - Chemical Structure Identifier</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture-06.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 6 - Cross-Validation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-goals">Learning goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-supervised-learning">1. What is supervised learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preview-and-descriptor-engineering">2. Data preview and descriptor engineering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-workflow-on-melting-point">3. Regression workflow on melting point</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-and-test-split">3.1 Train and test split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-the-data-and-train">3.2 Splitting the data and train</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-split-choice-affects-accuracy">3.3 How split choice affects accuracy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-curves">3.4 Learning curves</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-lasso-and-ridge">3.5 Regularization: Lasso and Ridge</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#another-regression-target-solubility-in-log-space">4. Another regression target: solubility in log space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-classification-toxicity">5. Binary classification: toxicity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-regression-to-classes-melting-point-bins">6. From regression to classes: melting point bins</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#macro-averaging">Macro Averaging</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-reference">8. Quick reference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">9. Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-class-activity">10. In-class activity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-two-features">10.1 Linear Regression with two features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-across-splits">10.2 Ridge across splits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pka-regression-two-ways">10.3 pKa regression two ways</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pka-to-classification">10.4 pKa to classification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">10. In-class activity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">10.1 Linear Regression with two features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">10.2 Ridge across splits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">10.3 pKa regression two ways</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">10.4 pKa to classification</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>